var documenterSearchIndex = {"docs":
[{"location":"00_-_INTRO_-_Introduction_julia_ml/0003_-_Introduction_to_Julia.html","page":"0003 - Introduction to Julia","title":"0003 - Introduction to Julia","text":"TODO. Please refer to the videos.","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_Modules_packages_and_environments.html","page":"0006 - Modules packages and environments","title":"0006 - Modules packages and environments","text":"TODO. Please refer to the videos.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"EditURL = \"https://github.com/sylvaticus/SPMLJ/blob/main/lessonsSources/04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.jl\"","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"################################################################################\n###  Introduction to Scientific Programming and Machine Learning with Julia  ###\n###                                                                          ###\n### Run each script on a new clean Julia session                             ###\n### GitHub: https://github.com/sylvaticus/IntroSPMLJuliaCourse               ###\n### Licence (apply to all material of the course: scripts, videos, quizes,..)###\n### Creative Commons By Attribution (CC BY 4.0), Antonello Lobianco          ###\n################################################################################","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html#Neural-network-implementations","page":"0402 Implementing neural network models","title":"0402 - Neural network implementations","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html#Some-stuff-to-set-up-the-environment..","page":"0402 Implementing neural network models","title":"Some stuff to set-up the environment..","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"cd(@__DIR__)\nusing Pkg\nPkg.activate(\".\")\n# If using a Julia version different than 1.7 please uncomment and run the following line (the guarantee of reproducibility will however be lost)\n# Pkg.resolve()\nPkg.instantiate()\nusing Random\nRandom.seed!(123)\nENV[\"DATADEPS_ALWAYS_ACCEPT\"] = \"true\"","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"We will not run cross validation here to find the optimal hyper-parameters. The process will not be different than those we saw in the lesson on the Perceptron. Instead we focus on creating neural network models, train them based on data and evaluating their predictions. For feed-forward neural networks (both for classification and regression) we will use BetaML, while for Convolutional Neural Networks example we will use the Flux.jl package.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html#Feed-forward-neural-networks","page":"0402 Implementing neural network models","title":"Feed-forward neural networks","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html#Binary-classification","page":"0402 Implementing neural network models","title":"Binary classification","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"Data loading...","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"using BetaML, DelimitedFiles\ndata  = readdlm(joinpath(dirname(pathof(BetaML)),\"..\",\"test\",\"data\",\"binary2DData.csv\"),'\\t')\nnR   = size(data,1)\nidx  = shuffle(1:nR)\ndata = data[idx,:]\nX    = copy(data[:,[2,3]])\ny    = max.(0,convert(Array{Int64,1},copy(data[:,1]))) # Converting labels from {-1,1} to {0,1}\n((xtrain,xtest),(ytrain,ytest)) = partition([X,y],[0.7,0.3])","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html#Using-defaults-hidding-complexity","page":"0402 Implementing neural network models","title":"Using defaults - hidding complexity","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"Model definition...","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"l1   = DenseLayer(2,5,f=tanh)\nl2   = DenseLayer(5,5,f=relu)\nl3   = DenseLayer(5,1,f=sigmoid)\nmynn = buildNetwork([l1,l2,l3],squaredCost)","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"Training...","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"train!(mynn,xtrain,ytrain)\n\nŷtrain         = predict(mynn, xtrain) |> makeColVector .|> round .|> Int\nŷtest          = predict(mynn, xtest)  |> makeColVector .|> round .|> Int\ntrainAccuracy  = accuracy(ŷtrain,ytrain)\ntestAccuracy   = accuracy(ŷtest,ytest)","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html#Specifying-all-options","page":"0402 Implementing neural network models","title":"Specifying all options","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"Model definition...","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"l1   = DenseLayer(2,5,f=tanh, df= dtanh,rng=copy(FIXEDRNG))\nl2   = DenseLayer(5,5,f=relu,df=drelu,rng=copy(FIXEDRNG))\nl3   = DenseLayer(5,1,f=sigmoid,df=dsigmoid,rng=copy(FIXEDRNG))\nmynn = buildNetwork([l1,l2,l3],squaredCost,dcf=dSquaredCost,name=\"A classification task\") # or crossEntropy / dCrossEntropy","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"Training...","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"function myOwnTrainingInfo(nn,x,y;n,nBatches,epochs,verbosity,nEpoch,nBatch)\n    if verbosity == NONE\n        return false # doesn't stop the training\n    end\n    nMsgDict = Dict(LOW => 0, STD => 10,HIGH => 100, FULL => n)\n    nMsgs = nMsgDict[verbosity]\n    batchSize = size(x,1)\n    if verbosity == FULL || ( nBatch == nBatches && ( nEpoch == 1  || nEpoch % ceil(epochs/nMsgs) == 0))\n\n       ϵ = loss(nn,x,y)\n       println(\"MY Training.. \\t avg ϵ on (Epoch $nEpoch Batch $nBatch): \\t $(ϵ)\")\n    end\n    return false\n end\ntrain!(mynn,xtrain,ytrain,epochs=300,batchSize=6,sequential=true,verbosity=STD,cb=myOwnTrainingInfo,optAlg=ADAM(η=t -> 0.001, λ=1.0, β₁=0.9, β₂=0.999, ϵ=1e-8),rng=copy(FIXEDRNG))\n\nŷtrain         = predict(mynn, xtrain) |> makeColVector .|> round .|> Int\nŷtest          = predict(mynn, xtest)  |> makeColVector .|> round .|> Int\ntrainAccuracy  = accuracy(ŷtrain,ytrain)\ntestAccuracy   = accuracy(ŷtest,ytest)","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html#Multinomial-classification","page":"0402 Implementing neural network models","title":"Multinomial classification","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"We want to determine the plant specie given some bothanic measures of the flower","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"iris     = readdlm(joinpath(dirname(Base.find_package(\"BetaML\")),\"..\",\"test\",\"data\",\"iris.csv\"),',',skipstart=1)\niris     = iris[shuffle(axes(iris, 1)), :] # Shuffle the records, as they aren't by default\nx        = convert(Array{Float64,2}, iris[:,1:4])\ny        = map(x->Dict(\"setosa\" => 1, \"versicolor\" => 2, \"virginica\" =>3)[x],iris[:, 5]) # Convert the target column to numbers\n\n((xtrain,xtest),(ytrain,ytest)) = partition([x,y],[0.8,0.2],shuffle=false)\n\nytrain_oh = oneHotEncoder(ytrain) # Convert to One-hot representation (e.g. 2 => [0 1 0], 3 => [0 0 1])","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"Define the Artificial Neural Network model","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"l1   = DenseLayer(4,10,f=relu) # Activation function is ReLU\nl2   = DenseLayer(10,3)        # Activation function is identity by default\nl3   = VectorFunctionLayer(3,f=softmax) # Add a (parameterless) layer whose activation function (softMax in this case) is defined to all its nodes at once\nmynn = buildNetwork([l1,l2,l3],crossEntropy,name=\"Multinomial logistic regression Model Sepal\") # Build the NN and use the squared cost (aka MSE) as error function (crossEntropy could also be used)","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"Training it (default to ADAM)","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"res = train!(mynn,scale(xtrain),ytrain_oh,batchSize=6) # Use optAlg=SGD() to use Stochastic Gradient Descent instead","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"Test it","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"ŷtrain        = predict(mynn,scale(xtrain))   # Note the scaling function\nŷtest         = predict(mynn,scale(xtest))\ntrainAccuracy = accuracy(ŷtrain,ytrain)\ntestAccuracy  = accuracy(ŷtest,ytest,tol=1,ignoreLabels=false)\n\ncm = ConfusionMatrix(ŷtrain,ytrain, labels=[\"setosa\", \"versicolor\", \"virginica\"])\nprintln(cm)","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html#Regression","page":"0402 Implementing neural network models","title":"Regression","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"Data Loading and processing..","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"using Pipe, HTTP, CSV, Plots, DataFrames\nurlData = \"https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt\"\ndata = @pipe HTTP.get(urlData).body |> CSV.File(_, delim='\\t') |> DataFrame\nsex_oh = oneHotEncoder(data.SEX)\nX = hcat(data.AGE, Matrix(data[:,3:10]),sex_oh)\ny = data.Y\n(xtrain,xval),(ytrain,yval) = partition([X,y],[0.8,0.2])","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"Model definition...","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"l1   = DenseLayer(11,20,f=relu)\nl2   = DenseLayer(20,20,f=relu)\nl3   = DenseLayer(20,1,f=relu) # y is positive\nmynn = buildNetwork([l1,l2,l3],squaredCost)","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"Training...","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"trainingLogs = train!(mynn,scale(xtrain),ytrain,batchSize=6,epochs=600)\n\nŷtrain   = predict(mynn, scale(xtrain)) |> makeColVector\nŷval     = predict(mynn, scale(xval))  |> makeColVector\ntrainRME = meanRelError(ŷtrain,ytrain,normRec=false)\ntestRME  = meanRelError(ŷval,yval,normRec=false)\nplot(trainingLogs.ϵ_epochs[10:end])\nscatter(yval,ŷval,xlabel=\"obs\",ylabel=\"est\",legend=nothing)","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html#Convolutional-neural-networks","page":"0402 Implementing neural network models","title":"Convolutional neural networks","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"using LinearAlgebra, Statistics,Flux, MLDatasets, Plots\n\nx_train, y_train = MLDatasets.MNIST.traindata(dir = \"data/MNIST\")\nx_train          = permutedims(x_train,(2,1,3)) # For correct img axis\nx_train          = convert(Array{Float32,3},x_train)\nx_train          = reshape(x_train,(28,28,1,60000))\ny_train          = Flux.onehotbatch(y_train, 0:9)\ntrain_data       = Flux.Data.DataLoader((x_train, y_train), batchsize=128)\nx_test, y_test   = MLDatasets.MNIST.testdata(dir = \"data/MNIST\")\nx_test           = permutedims(x_test,(2,1,3)) # For correct img axis\nx_test           = convert(Array{Float32,3},x_test)\nx_test           = reshape(x_test,(28,28,1,10000))\ny_test           = Flux.onehotbatch(y_test, 0:9)\n\nmodel = Chain(\n    # 28x28 => 14x14\n    Conv((5, 5), 1=>8, pad=2, stride=2, relu),\n    # 14x14 => 7x7\n    Conv((3, 3), 8=>16, pad=1, stride=2, relu),\n    # 7x7 => 4x4\n    Conv((3, 3), 16=>32, pad=1, stride=2, relu),\n    # 4x4 => 2x2\n    Conv((3, 3), 32=>32, pad=1, stride=2, relu),\n    # Average pooling on each width x height feature map\n    GlobalMeanPool(),\n    Flux.flatten,\n    Dense(32, 10),\n    Flux.softmax\n)\n\nmyaccuracy(ŷ, y) = (mean(Flux.onecold(ŷ) .== Flux.onecold(y)))\nmyloss(x, y)     = Flux.crossentropy(model(x), y)\n\nopt = Flux.ADAM()\nps  = Flux.params(model)\nnumber_epochs = 4\n\nFlux.@epochs number_epochs Flux.train!(myloss, ps, train_data, opt)\n\nŷtrain =   model(x_train)\nŷtest  =   model(x_test)\nmyaccuracy(ŷtrain, y_train)\nmyaccuracy(ŷtest, y_test)\n\nplot(Gray.(x_train[:,:,1,2]))\ncm = ConfusionMatrix(Flux.onecold(ŷtest) .-1 ,Flux.onecold(y_test) .-1)\nprintln(cm)","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"View this file on Github.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0402_Implementing_neural_network_models.html","page":"0402 Implementing neural network models","title":"0402 Implementing neural network models","text":"This page was generated using Literate.jl.","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"EditURL = \"https://github.com/sylvaticus/SPMLJ/blob/main/lessonsSources/03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.jl\"","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"################################################################################\n###  Introduction to Scientific Programming and Machine Learning with Julia  ###\n###                                                                          ###\n### Run each script on a new clean Julia session                             ###\n### GitHub: https://github.com/sylvaticus/IntroSPMLJuliaCourse               ###\n### Licence (apply to all material of the course: scripts, videos, quizes,..)###\n### Creative Commons By Attribution (CC BY 4.0), Antonello Lobianco          ###\n################################################################################","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html#The-Perceptron-algorithm-for-linear-classification","page":"0302-perceptron","title":"0302 - The Perceptron algorithm for linear classification","text":"","category":"section"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html#Some-stuff-to-set-up-the-environment..","page":"0302-perceptron","title":"Some stuff to set-up the environment..","text":"","category":"section"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"cd(@__DIR__)\nusing Pkg\nPkg.activate(\".\")","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"If using a Julia version different than 1.7 please uncomment and run the following line (the guarantee of reproducibility will however be lost) Pkg.resolve()","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"Pkg.instantiate()\nusing Random\nRandom.seed!(123)","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html#Perceptron-elementary-operations","page":"0302-perceptron","title":"Perceptron elementary operations","text":"","category":"section"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"using StatsPlots\nfunction plot2DClassifierWithData(X,y,θ;d1=1,d2=2,origin=false,pid=1)\n    colors = [y == -1 ? \"red\" : \"green\" for y in y]\n    labels = [y == -1 ? \"-1\" : \"+1\" for y in y]\n    minD1,maxD1 = extrema(X[:,d1])\n    minD2,maxD2 = extrema(X[:,d2])\n    myplot = scatter(X[:,d1],X[:,d2], colour=colors, title=\"Linear classifier in 2D\",xlabel=\"Dimx: $d1\", ylabel=\"Dimy: $d2\", group=labels)\n    constTerm = 0.0\n    if !origin\n        d1 += 1\n        d2 += 1\n        constTerm = -θ[1]/θ[d2]\n    end\n    d2Class(x) = constTerm -x * θ[d1]/θ[d2]\n    if θ[d2] == 0\n        vline!([0], color= \"blue\",label=\"\",linewidth=5)\n    else\n        plot!(d2Class,min(θ[d1],minD1),max(maxD1,θ[d1]), color= \"blue\",label=\"\",linewidth=5)\n    end\n    plot!([0,θ[d1]],[0,θ[d2]],arrow=true,color=:black,linewidth=2,label=\"\")\n    display(myplot)\n    savefig(\"currentPlot$(pid).svg\");\nend\nisClassificationError(θ,y,x) =  y * (θ' * x) <= eps()\nperceptronUpdate(θ,y,x)      = return θ .+ y .* x\n\nX = [ 2 4\n     -6 1]\ny = [-1,-1]\nθ₀ = [0,0]\nθ = θ₀\n\nϵ = isClassificationError(θ,y[1],X[1,:])\nθ = perceptronUpdate(θ,y[1],X[1,:])\nplot2DClassifierWithData(X,y,θ,origin=true,pid=1)","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"(Image: )","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"ϵ = isClassificationError(θ,y[1],X[1,:])\nϵ = isClassificationError(θ,y[2],X[2,:])\nθ = perceptronUpdate(θ,y[2],X[2,:])\nplot2DClassifierWithData(X,y,θ,origin=true,pid=2)","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"(Image: )","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"ϵ = isClassificationError(θ,y[2],X[2,:])\nϵ = isClassificationError(θ,y[1],X[1,:])\n\nX = [ 2 4\n     1 -2]\nθ = θ₀\n\nϵ = isClassificationError(θ,y[1],X[1,:])\nθ = perceptronUpdate(θ,y[1],X[1,:])\nplot2DClassifierWithData(X,y,θ, origin=true,pid=3)","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"(Image: )","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"ϵ = isClassificationError(θ,y[1],X[1,:])\nϵ = isClassificationError(θ,y[2],X[2,:])\nθ = perceptronUpdate(θ,y[2],X[2,:])\nplot2DClassifierWithData(X,y,θ, origin=true,pid=4)","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"(Image: )","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"ϵ = isClassificationError(θ,y[1],X[1,:])\nϵ = isClassificationError(θ,y[2],X[2,:])\nθ = perceptronUpdate(θ,y[2],X[2,:])\nplot2DClassifierWithData(X,y,θ,origin=true,pid=5)","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"(Image: )","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"ϵ = isClassificationError(θ,y[1],X[1,:])\nϵ = isClassificationError(θ,y[2],X[2,:])\nθ\n\nX = [ 2 4\n     -2 2]\ny = [-1,1]\nθ = θ₀\nϵ = isClassificationError(θ,y[1],X[1,:])\nθ = perceptronUpdate(θ,y[1],X[1,:])\nplot2DClassifierWithData(X,y,θ, origin=true,pid=6)","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"(Image: )","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"ϵ = isClassificationError(θ,y[2],X[2,:])\nθ = perceptronUpdate(θ,y[2],X[2,:])\nplot2DClassifierWithData(X,y,θ,origin=true,pid=7)","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"(Image: )","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html#The-complete-algorithm","page":"0302-perceptron","title":"The complete algorithm","text":"","category":"section"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"function perceptronOrigin(X,y,epochs=1;verbose=false)\n    (nR,nD) = size(X)\n    local θ = zeros(nD)\n    for t in 1:epochs\n        for n in 1:nR\n            if verbose\n                println(\"$n: X[n,:] \\t θ: $θ\")\n            end\n            if isClassificationError(θ,y[n],X[n,:])\n                θ = perceptronUpdate(θ,y[n],X[n,:])\n                if verbose\n                    println(\"**update! New theta: $θ\")\n                end\n            end\n        end\n    end\n    return θ\nend\nθopt =  perceptronOrigin(X,y,verbose=true)\nplot2DClassifierWithData(X,y,θopt, origin=true,pid=8)","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"(Image: )","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"using BetaML, DelimitedFiles\nbaseDir          = joinpath(dirname(pathof(BetaML)),\"..\",\"test\",\"data\")\nperceptronData   = readdlm(joinpath(dirname(pathof(BetaML)),\"..\",\"test\",\"data\",\"binary2DData.csv\"),'\\t')\n\nnR = size(perceptronData,1)\n\nidx = shuffle(1:nR)\nperceptronData = perceptronData[idx,:]\nX                = copy(perceptronData[:,[2,3]])\ny                = convert(Array{Int64,1},copy(perceptronData[:,1]))\nθopt             = perceptronOrigin(X,y,verbose=true)\n\nplot2DClassifierWithData(X,y,θopt, origin=true,pid=20)","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"(Image: )","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html#A-better-organisation","page":"0302-perceptron","title":"A better organisation","text":"","category":"section"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"Now we rewrite the perceptron algorithm setting all the parameters in a structure and using what could be a generic interface for any supervised model. This is the approach used by most ML libraries. We will see how to measure the classification error and as we are here we add the constant term with the constant addition to the data trick (note that editing every time the feature matrix is NOT efficient and we do it here only for simplicity. A better way is to explicitly model the perceptron model with a constant parameter.)","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"abstract type SupervisedModel end\nabstract type TrainingOptions end\n\nmutable struct Perceptron <: SupervisedModel\n    θ::Vector{Float64}\nend\n\nmutable struct PerceptronTrainingOptions <: TrainingOptions\n    epochs::Int64\n    verbose::Bool\n    shuffle::Bool\n    function PerceptronTrainingOptions(;epochs=1,verbose=false,shuffle=false)\n        return new(epochs,verbose,shuffle)\n    end\nend\n\n\nfunction predict(model::Perceptron,x::AbstractVector)\n    x = vcat(1.0,x)\n    x' * model.θ > eps() ? (return 1) : (return -1)\nend\n\nfunction predict(model::Perceptron,X::AbstractMatrix)\n    return [predict(model,r) for r in eachrow(X)]\nend\n\n\nfunction update!(model::Perceptron,X::Vector,y)\n    X       = vcat(1.0,X)\n    model.θ = model.θ .+ y .* X\n    return model.θ\nend\n\nfunction train!(model::Perceptron,X,y,ops=PerceptronTrainingOptions()::TrainingOptions)\n    epochs  = ops.epochs\n    verbose = ops.verbose\n    (nR,nD) = size(X)\n    nD += 1\n    for t in 1:epochs\n        errors = 0\n        if ops.shuffle   # more efficient !\n          idx = shuffle(1:nR)\n          X = X[idx,:]\n          y = y[idx]\n        end\n        for n in 1:nR\n            if verbose\n                println(\"$n: X[n,:] \\t θ: $(model.θ)\")\n            end\n            if  predict(model,X[n,:]) != y[n]\n                errors += 1\n                θ = update!(model,X[n,:],y[n])\n                if verbose\n                    println(\"**update! New theta: $(model.θ)\")\n                end\n            end\n        end\n        if verbose\n            println(\"Epoch $t errors: $errors\")\n        end\n    end\n    return model.θ\nend","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html#Testing-the-Perceptron-algorithm","page":"0302-perceptron","title":"Testing the Perceptron algorithm","text":"","category":"section"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"m   = Perceptron(zeros(size(X,2)+1))\nops = PerceptronTrainingOptions()\ntrain!(m,X,y,ops)\nplot2DClassifierWithData(X,y,m.θ,pid=9)","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"(Image: )","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"ŷ = predict(m,X)\ninSampleAccuracy = sum(y .== ŷ)/length(y)","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"Let's see if shuffling and increasing epochs we improve the accuracy....","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"ops = PerceptronTrainingOptions(verbose=false,epochs=5,shuffle=true)\nm   = Perceptron(zeros(size(X,2)+1))\ntrain!(m,X,y,ops)\nplot2DClassifierWithData(X,y,m.θ,pid=10)","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"(Image: )","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"ŷ = predict(m,X)\ninSampleAccuracy = sum(y .== ŷ)/length(y)","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html#Cross-validation-and-hyperparameters-optimisation","page":"0302-perceptron","title":"Cross-validation and hyperparameters optimisation","text":"","category":"section"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"Let's see now using separate training/validation We use the BetaML partition() function","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"((xtrain,xtest),(ytrain,ytest)) = partition([X,y],[0.6,0.4])\nm             = Perceptron(zeros(size(X,2)+1))\nops           = PerceptronTrainingOptions(epochs=5,shuffle=true)\ntrain!(m,xtrain,ytrain,ops)\nplot2DClassifierWithData(xtrain,ytrain,m.θ,pid=11)","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"(Image: )","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"ŷtrain = predict(m,xtrain)\ntrainAccuracy = accuracy(ŷtrain,ytrain)\nsum(ytrain  .== ŷtrain)/length(ytrain)\n# @edit accuracy(ŷtrain,ytrain)\nŷtest         = predict(m,xtest)\ntestAccuracy  = accuracy(ŷtest,ytest)\nplot2DClassifierWithData(xtest,ytest,m.θ,pid=12)","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"(Image: )","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"cfOut = ConfusionMatrix(ŷtest,ytest)\nprint(cfOut)","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"Lets use CrossValidation","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"((xtrain,xvalidation,xtest),(ytrain,yvalidation,ytest)) = partition([X,y],[0.6,0.2,0.2])\n# Very few records..... let's go back to using only two subsets but with CrossValidation\n((xtrain,xtest),(ytrain,ytest)) = partition([X,y],[0.6,0.4])\n\nsampler    = KFold(nSplits=10)\n\nops     = PerceptronTrainingOptions(epochs=10,shuffle=true)\n(acc,σ) = crossValidation([xtrain,ytrain],sampler) do trainData,valData,rng\n                (xtrain,ytrain) = trainData; (xval,yval) = valData\n                m               = Perceptron(zeros(size(xtrain,2)+1))\n                train!(m,xtrain,ytrain,ops)\n                ŷval         = predict(m,xval)\n                valAccuracy  = accuracy(ŷval,yval)\n                return valAccuracy\n            end\n\n\nepochsSet  = 1:10:301\nshuffleSet = [false,true]\n\nbestE       = 0\nbestShuffle = false\nbestAcc     = 0.0\n\nfor e in epochsSet, s in shuffleSet\n    global bestE, bestShuffle, bestAcc\n    local acc\n    local ops  = PerceptronTrainingOptions(epochs=e,shuffle=s)\n    (acc,_)    = crossValidation([xtrain,ytrain],sampler) do trainData,valData,rng\n                    (xtrain,ytrain) = trainData; (xval,yval) = valData\n                    m               = Perceptron(zeros(size(xtrain,2)+1))\n                    train!(m,xtrain,ytrain,ops)\n                    ŷval            = predict(m,xval)\n                    valAccuracy     = accuracy(ŷval,yval)\n                    return valAccuracy\n                end\n    if acc > bestAcc\n        bestAcc     = acc\n        bestE       = e\n        bestShuffle = s\n    end\nend\n\nbestAcc\nbestE\nbestShuffle\n\nops = PerceptronTrainingOptions(epochs=bestE,shuffle=bestShuffle)\nm   = Perceptron(zeros(size(xtest,2)+1))\ntrain!(m,xtrain,ytrain,ops)\nŷtest           = predict(m,xtest)\ntestAccuracy    = accuracy(ŷtest,ytest)\n\nplot2DClassifierWithData(xtest,ytest,m.θ,pid=13)","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"(Image: )","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"View this file on Github.","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0302-perceptron.html","page":"0302-perceptron","title":"0302-perceptron","text":"This page was generated using Literate.jl.","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0005_-_How_to_install_Julia_and_git.html","page":"0005 - How to install Julia and git","title":"0005 - How to install Julia and git","text":"TODO. Please refer to the videos.","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"EditURL = \"https://github.com/sylvaticus/SPMLJ/blob/main/lessonsSources/02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.jl\"","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"################################################################################\n###  Introduction to Scientific Programming and Machine Learning with Julia  ###\n###                                                                          ###\n### Run each script on a new clean Julia session                             ###\n### GitHub: https://github.com/sylvaticus/IntroSPMLJuliaCourse               ###\n### Licence (apply to all material of the course: scripts, videos, quizes,..)###\n### Creative Commons By Attribution (CC BY 4.0), Antonello Lobianco          ###\n################################################################################","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html#Further-Topics","page":"0202-further topics","title":"0202 - Further Topics","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html#Some-stuff-to-set-up-the-environment..","page":"0202-further topics","title":"Some stuff to set-up the environment..","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"cd(@__DIR__)\nusing Pkg\nPkg.activate(\".\")","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"If using a Julia version different than 1.7 please uncomment and run the following line (reproductibility guarantee will hower be lost) Pkg.resolve() Pkg.instantiate() # run this if you didn't in Segment 02.01","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"using Random\nRandom.seed!(123)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html#Plotting","page":"0202-further topics","title":"Plotting","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"Within the many possible packages to plot in Julia we use here the Plots package that allows at run time to choose the plot's backend. The defauld backend is gr (that, if you want to go back to it after you choosen another backend, you can activate with gr()). Other common backends are the Python MatplotLib (pyplot(), requiring package PyPlot) and Plotly (plotlyjs() from package PlotlyJS). Actually we use StatsPlots that just adds a set of convenient functionalities (in plots terminology called \"recipes\") on top of Plots.","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"using StatsPlots # no need to `using Plots` as `Plots` elements are reexported by StatsPlots","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"The basic idea is that we can draw different \"graphical elements\" in a Plot figure. The plot(.) function will first create a new figure, while plot!(.) will modify an existing plot (by drawing new elements on it, such as a new serie) taking the \"current\" plot as default if no plot object is passed as first argument.","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html#Plotting-functions","page":"0202-further topics","title":"Plotting functions","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"Let's start plotting a function. The FIRST TIME you invoke plot will take a while. This is the famous \"time to first plot\" problem due to the JIT compilation, but it refer only to the first plotting in a working session","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"plot(cos) # default [-5,+5] range","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"(Image: )","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"plot!(x->x^2, -2,2 ) # more explicit, with ranges","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"(Image: )","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"plot!(x->max(x,2), label=\"max function\", linestyle=:dot, color=:black, title=\"Chart title\", xlabel= \"X axis\", ylabel=\"Y axis\", legend=:topleft) # a bit of design","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"(Image: )","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"plot!(twinx(),x->20x,colour=RGB(20/255,120/255,13/255)) # secondary axis","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"(Image: )","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html#Plotting-data","page":"0202-further topics","title":"Plotting data","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"using DataFrames\nx = 11:15\ndata = DataFrame(a=[4,8,6,6,3], b=[2,4,5,8,6], c=[20,40,15,5,30])\nplot(x, Matrix(data)) # x, series (in column)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"(Image: )","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"@df data plot(x, :a, seriestype=:bar, legend=:topleft)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"(Image: )","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"plot!(x, data.b, seriestype=:line)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"(Image: )","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"scatter!(twinx(), x, data.c) # alias for `plot!(..., seriestype=:scatter)`","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"(Image: )","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html#Layouts-with-multiple-plots","page":"0202-further topics","title":"Layouts with multiple plots","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"l = @layout [a ; b c] # a,b,c, here are just placeholders, not related with the df column names..\np1 = plot(x, data.a)\np2 = scatter(x, data.b)\np3 = plot(x, data.c)\nplot(p1, p2, p3, layout = l)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"(Image: )","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html#Saving-the-plot..","page":"0202-further topics","title":"Saving the plot..","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"savefig(\"myplot.png\")\nsavefig(\"myplot.pdf\")\nsavefig(\"myplot.svg\")","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html#Probabilistic-analysis","page":"0202-further topics","title":"Probabilistic analysis","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"Julia has a very elegant package to deal with probability analysis, the Distributions package.","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"using Distributions","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"The idea is that we first create a Distribution object, of the distribution family and with the parameter required, and then we operate on it, for example to sample or to retrieve a quantile. The following table gives the distribution constructors for some of the most common distributions:","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"Discrete distr. Constructor Continuous distr. Constructor\nDiscrete uniform DiscreteUniform(lRange,uRange) Uniform Uniform(lRange,uRange)\nBernoulli Bernoulli(p) Exponential Exponential(rate)\nBinomial Binomial(n,p) Laplace Laplace(loc, scale)\nCategorical Categorical(ps) Normal Normal(μ,σ)\nMultinomial Multinomial(n, ps) Erlang Erlang(n,rate)\nGeometric Geometric(p) Cauchy Cauchy(μ, σ)\nHypergeometric Hypergeometric(nS, nF, nTrials) Chisq Chisq(df)\nPoisson Poisson(rate) T Dist TDist(df)\nNegative Binomial NegativeBinomial(nSucc,p) F Dist FDist(df1, df2)\n  Beta Dist Beta(shapeα,shapeβ)\n  Gamma Dist Gamma(shapeα,1/rateβ)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"d = Normal(10,3) # note that the parameter is the standard deviation, not the variance\n\nmean(d)\nvar(d)\nmedian(d)\nquantile(d,0.9)\ncdf(d,13.844)\npdf(d,0)\nsample = rand(d,1000)\nrand(d,10,2,3)\n\ndensity(sample)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"(Image: )","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"plot!(d)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"(Image: )","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"fit(Normal, sample) # using MLE","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html#Curve-fitting","page":"0202-further topics","title":"Curve fitting","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"LsqFit is a very flexible data fitting package for linear and nonlinear arbitrary functions (using least squares). Let's use it to fit a logistic growth curve (Verhulst model) of volumes for a forest stand.","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"using LsqFit\ndata = DataFrame(\n    age = 20:5:90,\n    vol = [64,112,170,231,293,352,408,459,505,546,582,613,640,663,683]\n) # Scots Pine, data from the UK Forestry Commission https://web.archive.org/web/20170119072737/http://forestry.gov.uk/pdf/FCBK048.pdf/$FILE/FCBK048.pdf\nplot(data.vol)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"(Image: )","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"logisticModel(age,parameters) = parameters[1]/(1+exp(-parameters[2] * (age-parameters[3]) ))\nlogisticModelVec(age,parameters) = logisticModel.(age,Ref(parameters))\n\ninitialParameters = [1000,0.02,50] #max growth; growth rate, mid age\nfitobject         = curve_fit(logisticModelVec, data.age, data.vol, initialParameters)\nfitparams         = fitobject.param\n\nfitobject.resid\nresiduals = logisticModelVec(data.age,fitparams) .- data.vol\nfitobject.resid == residuals\n\nsigma            = stderror(fitobject)\nconfidence_inter = confidence_interval(fitobject, 0.05) # 5% significance level\n\nx = 0:maximum(data.age)*1.5\nplot(x->logisticModel(x,fitparams),0,maximum(x), label= \"Fitted vols\", legend=:topleft)\nplot!(data.age, data.vol, seriestype=:scatter, label = \"Obs vols\")\nplot!(data.age, residuals, seriestype=:bar, label = \"Residuals\")","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"(Image: )","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html#Constrained-optimisation","page":"0202-further topics","title":"Constrained optimisation","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"JuMP is the leading library to express complex optimisation problems in a clear, mathematical friendly syntax, compute the information required by the solver engines to solve the optimisation problem, pass the problem to the aforementioned solver engines and retrieve the solutions.","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"JuMP has the same flexibility and expressivity of dedicated algeabric modelling languages as GAMS or AMPL but with the advantage of being a library within a much more general programming language, with larger community, development tools, language constructs and possibility to interface the specific \"optimisation component\" of a model with the rest of the model.","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"We will see how to specify the variables, the constraints and the objective function of an optimisation model, how to \"solve\" it and how to retrieve the optimal values","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html#A-linear-example:-the-classical-\"transport\"-problem","page":"0202-further topics","title":"A linear example: the classical \"transport\" problem","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"Obj: minimise transport costs c from several plants p to several markets m under the contraint to satisfy the demand d_m at each market while respecting the production capacity c_p of each plant: min_x_pm sum_p sum_m c_pm * x_pm subject to: sum_m x_pm leq d_m sum_p x_pm geq c_m","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"using  JuMP, GLPK, DataFrames, CSV","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html#\"Sets\"-and-exogenous-parameters-definition","page":"0202-further topics","title":"\"Sets\" and exogenous parameters definition","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"index sets","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"orig = [\"Epinal\", \"Bordeaux\", \"Grenoble\"] # plant/sawmills origin of timber\ndest = [\"Paris\", \"Lyon\", \"Nantes\", \"Tulouse\", \"Lille\", \"Marseille\", \"Strasbourg\"] # markets\nprod = [\"Fuelwood\", \"Sawnwood\", \"Pannels\"]","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"Read input data into DataFrames and then into Dictionaries with 2D or 3D tuples of index sets as keys","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"supply(prod, orig) amounts available at origins","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"supplytable = CSV.read(IOBuffer(\"\"\"\nprod     Epinal Bordeaux Grenoble\nFuelwood 400    700      800\nSawnwood 800    1600     1800\nPannels  200    300      300\n\"\"\"), DataFrame, delim=\" \", ignorerepeated=true,copycols=true)\nsupply = Dict( (r[:prod],o) => r[Symbol(o)] for r in eachrow(supplytable), o in orig)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"demand(prod, dest) amounts required at destinations","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"demandtable = CSV.read(IOBuffer(\"\"\"\nprod      Paris Lyon Nantes Tulouse Lille Marseille Strasbourg\nFuelwood  300   300  100    75      650   225       250\nSawnwood  500   750  400    250     950   850       500\nPannels   100   100  0      50      200   100       250\n\"\"\"), DataFrame, delim=\" \", ignorerepeated=true,copycols=true)\ndemand = Dict( (r[:prod],d) => r[Symbol(d)] for r in eachrow(demandtable), d in dest)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"limit(orig, dest) of total units from any origin to destination","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"defaultlimit = 625.0\nlimit = Dict((o,d) => defaultlimit for o in orig, d in dest)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"cost(prod, orig, dest) Shipment cost per unit","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"costtable = CSV.read(IOBuffer(\"\"\"\nprod     orig     Paris Lyon Nantes Tulouse Lille Marseille Strasbourg\nFuelwood Epinal   30    10   8      10      11    71        6\nFuelwood Bordeaux 22    7    10     7       21    82        13\nFuelwood Grenoble 19    11   12     10      25    83        15\n\nSawnwood Epinal   39    14   11     14      16    82        8\nSawnwood Bordeaux 27    9    12     9       26    95        17\nSawnwood Grenoble 24    14   17     13      28    99        20\n\nPannels  Epinal   41    15   12     16      17    86        8\nPannels  Bordeaux 29    9    13     9       28    99        18\nPannels  Grenoble 26    14   17     13      31    104       20\n\"\"\"), DataFrame, delim=\" \", ignorerepeated=true,copycols=true)\ncost = Dict( (r[:prod],r[:orig],d) => r[Symbol(d)] for r in eachrow(costtable), d in dest)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html#Optimisation-model-definition","page":"0202-further topics","title":"Optimisation model definition","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"trmodel = Model(GLPK.Optimizer)\nset_optimizer_attribute(trmodel, \"msg_lev\", GLPK.GLP_MSG_ON)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html#Model's-endogenous-variables-definition","page":"0202-further topics","title":"Model's endogenous variables definition","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"@variables trmodel begin\n    x[p in prod, o in orig, d in dest] >= 0\nend","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html#Constraints-definition","page":"0202-further topics","title":"Constraints definition","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"@constraints trmodel begin\n    supply[p in prod, o in orig], # observe supply limit at plant/sawmill origin o\n        sum(x[p,o,d] for d in dest) <= supply[p,o]\n    demand[p in prod, d in dest], # satisfy demand at market dest d\n        sum(x[p,o,d] for o in orig) >= demand[p,d]\n    c_total_shipment[o in orig, d in dest],\n        sum(x[p,o,d] for p in prod) <= limit[o,d]\nend","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html#Objective-function-definition","page":"0202-further topics","title":"Objective function definition","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"@objective trmodel Min begin\n    sum(cost[p,o,d] * x[p,o,d] for p in prod, o in orig, d in dest)\nend","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html#Human-readable-visualisatio-nof-the-model","page":"0202-further topics","title":"Human-readable visualisatio nof the model","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"print(trmodel)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html#Model-resolution","page":"0202-further topics","title":"Model resolution","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"optimize!(trmodel)\nstatus = termination_status(trmodel)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html#Post-resolution-information-retrieval","page":"0202-further topics","title":"Post-resolution information retrieval","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"Here, after the model has been \"solved\", we can retrieve information as the optimal level of the endogenous variables, the value of the opjective function at these optimal levels and the shadow costs of the contraints.","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"if (status == MOI.OPTIMAL || status == MOI.LOCALLY_SOLVED || status == MOI.TIME_LIMIT) && has_values(trmodel)\n    println(\"#################################################################\")\n    if (status == MOI.OPTIMAL)\n        println(\"** Problem solved correctly **\")\n    else\n        println(\"** Problem returned a (possibly suboptimal) solution **\")\n    end\n    println(\"- Objective value (total costs): \", objective_value(trmodel))\n    println(\"- Optimal routes:\\n\")\n    optRoutes = value.(x)\n    for p in prod\n      println(\"\\n* $(p):\")\n      [println(\"$o --> $d: $(optRoutes[p,o,d])\") for o in orig, d in dest]\n      println(\"- Shadow prices of supply:\")\n      [println(\"$o = $(dual(supply[p,o]))\") for o in orig]\n      println(\"- Shadow prices of demand:\")\n      [println(\"$d = $(dual(demand[p,d]))\") for d in dest]\n    end\nelse\n    println(\"The model was not solved correctly.\")\n    println(status)\nend","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html#A-nonlinear-example:-portfolio-optimisation","page":"0202-further topics","title":"A nonlinear example: portfolio optimisation","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"The problem objective is to choose the shares of different assets in the portfolio (here forest species, but the example is exactly the same considering other assets, for example financial investments) that maximise the portfolio expected returns while minimising its expected variance under the portfolio owner risk aversion risk. Here the \"returns\" are based on the timber production and the covariance between individual species of the portfolio is based on the observed volume growth covariances. The idea is that within the infinite possible allocations, the locus of those allocations for which is not possible to increase the portfolio profitability without increasing also its variance and the converse whose variance can not be lowered without at the same time lower its expected profitability are efficient in the Pareto meaning and form an \"efficient frontier\". Within this frontier the problem is to find the unique point that maximise the utility of the portfolio's owner given its risk aversion characteristic. Graphically the problem is depicted i nthe following picture:","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"(Image: The efficient frontier and the owner utility curves)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"Data originally from the Institut national de l'information géographique et forestière (IGN) of France. See the paper A. Dragicevic, A. Lobianco, A. Leblois (2016), ”Forest planning and productivity-risk trade-off through the Markowitz mean-variance model“, Forest Policy and Economics, Volume 64 for a thorough discussion of this model.","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"Declare the packages we are going to use:","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"using JuMP, Ipopt, StatsPlots","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"Forest species names","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"species   = [\"Chêne pédonculé\", \"Chêne sessile\", \"Hêtre\", \"Pin sylvestre\"]\nnSpecies  = length(species)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"Average productiities by specie This is implemented in a dictionary: key->value","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"y   = Dict( \"Chêne pédonculé\" => 1.83933333333333,\n            \"Chêne sessile\"   => 2.198,\n            \"Hêtre\"           => 3.286,\n            \"Pin sylvestre\"   => 3.3695)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"Covariance matrix between species","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"σtable = [[0.037502535947712\t0.016082745098039\t0.027797176470588\t-0.025589882352942]\n          [0.016082745098039\t0.015177019607843\t0.018791960784314\t-0.102880470588234]\n          [0.027797176470588\t0.018791960784314\t0.031732078431373\t-0.166391058823529]\n          [-0.025589882352942\t-0.102880470588234\t-0.166391058823529\t2.02950454411765]]","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"We reshape the covariance matrix in a dictionary (sp1,sp2) -> value The function (ix,x) = enumerate(X) returns a tuple of index position and element for each element of an array","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"σ = Dict((i,j) => σtable[i_ix,j_ix] for (i_ix,i) in enumerate(species), (j_ix,j) in enumerate(species))\n\n################################################################################\n###### Showing the possible mean/variance of the portfolio by simulation #######\n################################################################################\n\nnSamples = 1000\nshares   = rand(nSamples,nSpecies)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"Converting to probabilities","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"import BetaML.Utils:softmax\n[shares[i,:]  = softmax(shares[i,:], β=one.(shares[i,:]) .* 5) for i in 1:nSamples]\n\npScores = Array{Float64,2}(undef,0,2)\nfor i in 1:nSamples\n    global pScores\n    pVar    = sum(shares[i,j1] * shares[i,j2] * σ[species[j1],species[j2]] for j1 in 1:nSpecies, j2 in 1:nSpecies)\n    pY      = sum(shares[i,j]*y[species[j]] for j in 1:nSpecies)\n    pScores = vcat(pScores,[pVar pY])\nend\n\n#goodShares = [0,0,0.74,0.26]\n#pVar = sum(goodShares[j1] * goodShares[j2] * σ[species[j1],species[j2]] for j1 in 1:nSpecies, j2 in 1:nSpecies)\n#pY   = sum(goodShares[j]*y[species[j]] for j in 1:nSpecies)\n\nscatter(pScores[:,1],pScores[:,2],colour=:blue)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"(Image: )","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"################################################################################\n### Finding (one) optimal portfolio ############################################\n################################################################################","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"Risk aversion coefficient","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"α = 0.1","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"We declare an optimisation problem, we name it \"m\" and we let JuMP associate it with the most suitable solver within the one installed:","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"port = Model(Ipopt.Optimizer)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"We declare a set of variables, indicized by the species name:","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"@variables port begin\n    x[i in species] >= 0\nend","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"We declare the constraint shat the sum of shares must be equal to 1","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"@constraint(port, c_share, sum(x[i] for i in species) == 1)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"@objective port Min begin   α *  sum(x[i] * x[j] * σ[i,j] for i in species for j in species) - sum(x[i] * y[i] for i in species) end","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"@NLobjective port Min α *  sum(x[i] * x[j] * σ[i,j] for i in species for j in species) - sum(x[i] * y[i] for i in species)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"Print the optimisation model in nice human-readable format:","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"print(port)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"Solve the model and return the solving status:","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"optimize!(port)\nstatus = termination_status(port)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"Return the objective:","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"println(\"Objective value: \", objective_value(port))","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"Return the value of the decision variable:","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"optShares = value.(x)\n[println(\"$sp = $(optShares[sp])\") for sp in species];\npOptVar = sum(optShares[species[j1]] * optShares[species[j2]] * σ[species[j1],species[j2]] for j1 in 1:nSpecies, j2 in 1:nSpecies)\npOptY   = sum(optShares[species[j]]*y[species[j]] for j in 1:nSpecies)\n\n\nfunction computeOptimalPortfolio(species,y,σ,α)\n    port = Model(Ipopt.Optimizer)\n    set_optimizer_attribute(port, \"print_level\", 0)\n    @variables port begin\n        x[i in species] >= 0\n    end\n    @constraint(port, c_share, sum(x[i] for i in species) == 1)\n    @NLobjective port Min α *  sum(x[i] * x[j] * σ[i,j] for i in species for j in species) - sum(x[i] * y[i] for i in species)\n    optimize!(port)\n    status = termination_status(port)\n    optShares = value.(x)\n    pOptVar = sum(optShares[species[j1]] * optShares[species[j2]] * σ[species[j1],species[j2]] for j1 in 1:nSpecies, j2 in 1:nSpecies)\n    pOptY   = sum(optShares[species[j]]*y[species[j]] for j in 1:nSpecies)\n    return (pOptVar,pOptY)\nend\n\nαs = [1000,100,10,1,0.1,0.05,0.02,0.01]\npOptScores = Array{Float64,2}(undef,0,2)\nfor α in αs\n    global pOptScores\n    pVar,pY =computeOptimalPortfolio(species,y,σ,α)\n    pOptScores = vcat(pOptScores,[pVar pY])\nend\nscatter!(pOptScores[:,1],pOptScores[:,2],colour=:red)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"(Image: )","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"αs = [82.45,50,30,20,15,12,10,9,8,7,6,5]\npOptScores = Array{Float64,2}(undef,0,2)\nfor α in αs\n    global pOptScores\n    pVar,pY =computeOptimalPortfolio(species,y,σ,α)\n    pOptScores = vcat(pOptScores,[pVar pY])\nend\n\nscatter(pOptScores[:,1],pOptScores[:,2],colour=:red)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"(Image: )","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"View this file on Github.","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0202-further_topics.html","page":"0202-further topics","title":"0202-further topics","text":"This page was generated using Literate.jl.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"EditURL = \"https://github.com/sylvaticus/SPMLJ/blob/main/lessonsSources/01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.jl\"","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"################################################################################\n###  Introduction to Scientific Programming and Machine Learning with Julia  ###\n###                                                                          ###\n### Run each script on a new clean Julia session                             ###\n### GitHub: https://github.com/sylvaticus/IntroSPMLJuliaCourse               ###\n### Licence (apply to all material of the course: scripts, videos, quizes,..)###\n### Creative Commons By Attribution (CC BY 4.0), Antonello Lobianco          ###\n################################################################################","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html#Custom-Types","page":"0105-custom types","title":"0105 Custom Types","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html#Some-stuff-to-set-up-the-environment..","page":"0105-custom types","title":"Some stuff to set-up the environment..","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"cd(@__DIR__)\nusing Pkg\nPkg.activate(\".\")","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"If using a Julia version different than 1.7 please uncomment and run the following line (reproductibility guarantee will however be lost) Pkg.resolve() Pkg.instantiate() # run this if you didn't in Segment 01.01","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"using Random\nRandom.seed!(123)\nusing InteractiveUtils # loaded automatically when working... interactively","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html#\"Type\"-of-types","page":"0105-custom types","title":"\"Type\" of types","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"In Julia primitive, composite and abstract types can all be defined by the user","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"primitive type APrimitiveType 819200 end # name and size in bit - multiple of 8 and below 8388608 (1MB)\nprimitive type APrimitiveType2 819200 end\n819200/(8*1024)\nstruct ACompositeType end                # fields, constructors.. we'll see this later in details\nabstract type AnAbstractType end         # no objects, no instantialisation of objects","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html#Composite-types","page":"0105-custom types","title":"Composite types","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"mutable struct Foo # starting with a capital letter\n    field1\n    field2::String\n    field3::ACompositeType\nend","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"mutable struct Foo # error! can't change a struct after I defined it end","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"fieldnames(Foo)\n\no = Foo(123,\"aaa\",ACompositeType()) # call the default constructor (available automatically) - order matters!\ntypeof(o)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"Outer constructor","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"function Foo(f2,f3=ACompositeType()) # \"normal\" functions just happens it has the name of the object to create\n    if startswith(f2,\"Booo\")         # put whatever logic you wish\n        return nothing\n    end\n    return Foo(123,f2,f3)            # call the default constructor\nend\n\no = Foo(123,\"aaa\", ACompositeType()) # call the default constructor\no = Foo(\"blaaaaa\")                   # call the outer constructor we defined\n\no.field1       # access fields\no.field1 = 321 # modify field (because type defined as \"mutable\" !!!)\no\n\n\nfunction Base.show(io::IO, x::Foo)             # function(o) rather than o.function()\n    println(io,\"My custom representation for Foo objects\")\n    println(io,\"Field1: $(o.field1)\")\n    println(io,\"Field2: $(o.field2)\")\nend\no","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"Inner constructor","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"mutable struct Foo2\n    field1::Int64\n    field2::String\n    function Foo2(f1,f2,f3)\n        # ... logic\n        return new(f1+f2,f3)\n    end\nend\nFoo2(1,2,\"aaa\")","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"tip: Tip\nIf any inner constructor method is defined, no default constructor method is provided.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"Foo2(1,\"aaa\") # Error, no default constructor !","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html#Parametric-types","page":"0105-custom types","title":"Parametric types","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"struct Point{T<:Number} # T must be a child of type \"Number\"\n   x::T\n   y::T\nend\n\no = Point(1,2)\nPoint(1.0,2.)\n# Point(1,2.0) # error !\n\nfunction Point(x::T, y::T=zero(T)) where {T}\n    return Point(x,y)\nend\nPoint(2)\nPoint(1.5)\n\nabstract type Figure{T<:Number} end\n\na = Array{Int64,2}(undef,2,2) # Array is nothing else than a parametric type with 2 parameters\ntypeof(a)\neltype(a)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"As we see for arrays, parameters doesn't need to be types, but can be any value of a bits type (in practice an integer value) :","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"struct MyType{T,N}\n  data::Array{T,N}\nend\n\nintMatrixInside = MyType([1 2 3; 4 5 6])\nfloatVectorInside = MyType([1 2 3])\n\nfunction getPlane(o::MyType{T,N},dim,pos) where {T,N}\nsizes = size(o.data)\nif length(sizes) > N\n  error(\"Dim over the dimensions of the data\")\nelseif sizes[dim] < pos\n  error(\"Non enought elements in dimension $dim to cut at $pos\")\nend\nreturn selectdim(o.data,dim,pos)\nend\n\ngetPlane(intMatrixInside,1,2)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"A package where non-type parameters are emploied to boost speed is StaticArray.jl where one parameter is the size of the array that hence become known at compile time","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html#Inheritance","page":"0105-custom types","title":"Inheritance","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"abstract type MyOwnGenericAbstractType end                       # the highest-level\nabstract type MyOwnAbstractType1 <: MyOwnGenericAbstractType end # child of MyOwnGenericAbstractType\nabstract type MyOwnAbstractType2 <: MyOwnGenericAbstractType end # also child of MyOwnGenericAbstractType\nmutable struct AConcreteTypeA <: MyOwnAbstractType1\n  f1::Int64\n  f2::Int64\nend\nmutable struct AConcreteTypeB <: MyOwnAbstractType1\n  f1::Float64\nend\nmutable struct AConcreteTypeZ <: MyOwnAbstractType2\n  f1::String\nend\noA = AConcreteTypeA(2,10)\noB = AConcreteTypeB(1.5)\noZ = AConcreteTypeZ(\"aa\")\n\nsupertype(AConcreteTypeA)\nsubtypes(MyOwnAbstractType1)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"tip: Tip\nWhen multiple methods are available for an object, function calls are dispatched to the most stricter method, i.e. the one defined over the exact parameter's type or their immediate parents","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"function foo(a :: MyOwnGenericAbstractType)                      # good for everyone\n  println(\"Default implementation: $(a.f1)\")\nend\nfoo(oA) # Default implementation: 2\nfoo(oB) # Default implementation: 1.5\nfoo(oZ) # Default implementation: aa\nfunction foo(a :: MyOwnAbstractType1)                            # specialisation for MyOwnAbstractType1\n  println(\"A more specialised implementation: $(a.f1*4)\")\nend\nfoo(oA) # A more specialised implementation: 8\nfoo(oB) # A more specialised implementation: 6.0\nfoo(oZ) # Default implementation: aa                             # doesn't match the specialisation, default to foo(a :: MyOwnGenericAbstractType)\nfunction foo(a :: AConcreteTypeA)\n     println(\"A even more specialised implementation: $(a.f1 + a.f2)\")\nend\nfoo(oA) # A even more specialised implementation: 12\nfoo(oB) # A more specialised implementation: 6.0\nfoo(oZ) # Default implementation: aa","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"warning: Warning\nAttention to the inheritance for parametric types. If it is true that Vector{Int64} <: AbstractVector{Int64} and Int64 <: Number, it is FALSE that AbstractVector{Int64} <: AbstractVector{Number}. If you want to allow a function parameter to be a vector of numbers, use instead templates explicitly, e.g. foo(x::AbstractVector{T}) where {T<:Number} = return sum(x)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"Vector{Int64} <: AbstractVector{Int64}\nInt64 <: Number\nVector{Int64} <: Vector{Number}\nAbstractVector{Int64} <: AbstractVector{Number}","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html#Object-oriented-model","page":"0105-custom types","title":"Object-oriented model","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"OO model based on composition","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"struct Shoes\n   shoesType::String\n   colour::String\nend\nstruct Person\n  myname::String\n  age::Int64\nend\nstruct Student\n   p::Person        # by referencing a `Person`` object, we do not need to repeat its fields\n   school::String\n   shoes::Shoes     # same for `shoes`\nend\nstruct Employee\n   p::Person\n   monthlyIncomes::Float64\n   company::String\n   shoes::Shoes\nend\ngymShoes = Shoes(\"gym\",\"white\")\nproShoes = Shoes(\"classical\",\"brown\")\nMarc     = Student(Person(\"Marc\",15),\"Divine School\",gymShoes)\nMrBrown  = Employee(Person(\"Brown\",45),3200.0,\"ABC Corporation Inc.\", proShoes)\n\nfunction printMyActivity(self::Student)\n   println(\"Hi! I am $(self.p.myname), I study at $(self.school) school, and I wear $(self.shoes.colour) shoes\") # I can use the dot operator chained...\nend\nfunction printMyActivity(self::Employee)\n  println(\"Good day. My name is $(self.p.myname), I work at $(self.company) company and I wear $(self.shoes.colour) shoes\")\nend\n\nprintMyActivity(Marc)     # Hi! I am Marc, ...\nprintMyActivity(MrBrown)  # Good day. My name is MrBrown, ...","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"OO models based on Specialisation (Person → Student) or Weack Relation (Person → Shoes) instead of Composition (Person → Arm) can be implemented using third party packages, like e.g. SimpleTraits.jl or OOPMacro.jl","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"View this file on Github.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0105-custom_types.html","page":"0105-custom types","title":"0105-custom types","text":"This page was generated using Literate.jl.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"EditURL = \"https://github.com/sylvaticus/SPMLJ/blob/main/lessonsSources/01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.jl\"","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"################################################################################\n###  Introduction to Scientific Programming and Machine Learning with Julia  ###\n###                                                                          ###\n### Run each script on a new clean Julia session                             ###\n### GitHub: https://github.com/sylvaticus/IntroSPMLJuliaCourse               ###\n### Licence (apply to all material of the course: scripts, videos, quizes,..)###\n### Creative Commons By Attribution (CC BY 4.0), Antonello Lobianco          ###\n################################################################################","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Predefined-types","page":"0103-predefined types","title":"0103 Predefined types","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Some-stuff-to-set-up-the-environment..","page":"0103-predefined types","title":"Some stuff to set-up the environment..","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"cd(@__DIR__)\nusing Pkg\nPkg.activate(\".\")","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"If using a Julia version different than 1.7 please uncomment and run the following line (reproductibility guarantee will hower be lost) Pkg.resolve() Pkg.instantiate() # run this if you didn't in Segment 01.01","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"using Random\nRandom.seed!(123)\nusing InteractiveUtils # loaded automatically when working... interactively","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Primitive-types","page":"0103-predefined types","title":"Primitive types","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"Primitive types have a fixed number of bits associated to them. Examples of them are Int64, Float64, Char, UInt64, UFloat64, Int32, Float32,... Even primitive types can be custom defined. See the \"custom types\" segment !","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Char-and-Strings-Char,-String","page":"0103-predefined types","title":"Char and Strings - Char, String","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"a = \"Hello World \"\nb = a[2]\ntypeof(b)\nb = a[3:end]\ntypeof(b)\n#a[2] = 'E' # error !\n\n# info...\nismutable(a) # long story.... https://github.com/JuliaLang/julia/issues/30210\nlength(a)\nfindfirst(isequal('o'), a)\nfindnext(isequal('o'), a, 6)\noccursin(\"world\",a)\noccursin(lowercase(\"world\"),lowercase(a))\nusing Unicode\noccursin(Unicode.normalize(\"world\", casefold=true),Unicode.normalize(a, casefold=true))\nendswith(a,\"ld \")\nstartswith(a,\"Mooo\")\noccursin(r\"H*.d \", a)\n\n# modifications..\nlowercase(a)\nlowercasefirst(a)\nsplit(a, \" \")\nreplace(a,\"World\" => \"Universe\")\nstrip(a)\n\n# concatenation..\na = \"Hello\"; b= \"World\"\nc = join([a,b],\" \")\nc = a*\" \"*b\nc = string(a,\" \",b)\nc = \"$a $b\"              # interpolation\n\n# Conversion..\na = parse(Int64,\"2012\")\nb = string(2019)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"warning: Warning\nAttention not to confuse the string function with the String type and the String() constructor!","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"# to know more...\nmethodswith(String,supertypes=true); # where any argument is a String or any parent type (such e.g. AbstractString)\n# See also https://docs.julialang.org/en/v1/manual/strings/","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Arrays-Array{T,N}","page":"0103-predefined types","title":"Arrays - Array{T,N}","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"Array{T,NDims} A parameteric type where the type of the content and the number of dimensions define the specific type","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"tip: Tip\nVector{T} is an alias for Array{T,1} and Matrix{T} is an alias for Array{T,2}, but there isn't anything \"special\" for 1 or 2 dimensions compared to more dimensions","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Vectors-Array{T,1}","page":"0103-predefined types","title":"Vectors - Array{T,1}","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"One-dimensions arrays in julia are treated as column vector, and, depending on the inner type, they can be stored efficiently contiguously in memory. However they are NOT the same of a single column of a two dimensions array. A row vector is necessarily instead a single row of a 2 dimensions array.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"a = [1,2,3]\nb = [1 ; 2 ; 3 ;;] # This syntax requires Julia >= 1.7\na == b","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Initialisation","page":"0103-predefined types","title":"Initialisation","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"a = [1,2,3]; #= or =# a = [1;2;3]\na = [1; 6:-2:2; 10] # notes: (a) the semicolon, (b) the range includes BOTH the extremes\na = [[1,2],[3,4]]   # nested vectors. Each elements can have a different lenght, but rules of linear algebra doesn't apply","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"danger: Danger\nDon't confuse nested vectors with multi-dimensional arrays!","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"Empty (zero-elements) arrays:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"a = []\na = Int64[]\na = [1,2,3]\nb = [1,\"pizza\",\"beer\"]\na = Array{Int64,1}()","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"warning: Warning\nWatch out for the difference between a = Array{Int64,1}() and a = Array{Int64,1}","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"a = Vector{Int64}()","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"n-elements initialisation:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"n = 3\nT = Int64\nzeros(n)            # zeros (Float64)\nzeros(T,n)          # zeros (casted as type T)\nones(n)             # ones  (Float64)\nones(T,n)           # ones  (casted of type T)\nArray{T,1}(undef,n) # garbage\nfill(2,3)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Accessing-Vectors","page":"0103-predefined types","title":"Accessing Vectors","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"a = [101:200;]\na[1]\na[end]\na[[1; 6:-2:2; 10]] # indicised by a vector of positions","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Collecting-iterators-into-vectors","page":"0103-predefined types","title":"Collecting iterators into vectors","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"aRange = 3:2:7\na = collect(aRange)\ntypeof(aRange)\ntypeof(aRange) <: AbstractArray # Everywhere an AbstractArray is expected, you can provide a range instead","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Common-operations-with-vectors","page":"0103-predefined types","title":"Common operations with vectors","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"a = [1,2,3]\nreverse(a), a[end:-1:1] # Other way to revert an array\nvcat([1,2,3],[4,5],6)\n\npush!(a,4)  # add as individual elements\nappend!(a,5) # add as many new elements","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"tip: Functions with exclamation marks\nBy convention functions that modify one of their parameters (and usually this is the first one) are named with an exclamation mark at the end. Remember (most) unicode characters are valid in functions or variable names.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"push!([[1,2],[3,4,5]],[6,7])\nappend!([1,2,3,4,5],[6,7])\n\npop!(a)\na\npopfirst!(a)\ndeleteat!(a,2)\npushfirst!([2,3],1)\na = [2,1,3,1]\nsort(a)   # also `sort!(a)``\nunique(a) # also `unique!(a)`\nin(1,a)   # also available as operator: `if 2 in a [...] end`\nlength(a) # number of elements contained in all the dimensions\nsize(a),size(a,1) # number of elements by dimension\nminimum(a)\nmin(a...)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"tip: ...\n\"...\" is called the splat operator and it is used to convert the elements in a vector into a tuple of separate elements in a function call, like the example above","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"min(4,7,3)\nminimum([4,7,9])\nargmin([4,2,5,2])\nsum([1,2,3])\ncumsum([1,2,3])\nempty!(a) # only for Vectors\nusing Random\nshuffle([1,2,3]) # also shuffle!([1,2,3])\nisempty(a)\nfindall(x -> x == 1, [2,1,3,1]) # anonymous function returning an array of bools, findall then return the indexes\nfindfirst(x -> x == 1, [2,1,3,1])\nmyComparitionWith1(i) = i==1\nfindall(x -> myComparitionWith1(x), [2,1,3,1])\nfilter(i -> i > 2, [1,2,3,4])\n\n\n# delete [7,2,5] from an 1:10 array:\ndata     = [1:10;]\ntoDelete = [7,5,2]\ndeleteat!(data, findall(x -> x in toDelete, data))\n\nfor (i,value) in enumerate([10,20,30]) # iterator that returns an index/element tuple\n    println(\"$i - $value\")\nend\n\nnames = [\"Marc\", \"Anne\"]\nsex   = ['M','F']\nage   = [25,20]\n\nfor zippedElements in zip(names,sex,age) # iterator that returns tuples made with one element per argument of zip\n    println(zippedElements)\nend","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Multidimensional-arrays-Array{T,N}","page":"0103-predefined types","title":"Multidimensional arrays - Array{T,N}","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Initialisation-2","page":"0103-predefined types","title":"Initialisation","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"a = [[1,2,3] [4,5,6]] # By column, i.e. elements of the first column, elements of the second column, ...\na = [1 4; 2 5; 3 6]   # By row, i.e. elements of the first row, elements of the second row, ...\n\n# Empty (zero-elements) arrays:\na = Array{Float64}(undef, 0, 0, 0) # using explicitly the constructor and explicitly giving zero for each wanted dimension\n# n-elements initialisation:\n(T,n,m,g,j) = (Int64,1,2,3,'a')\na = zeros(n,m,g)            # n,m,g-elements zeros array\na = ones(n,m,g)             # n,m,g-elements ones array\na = Array{T,3}(undef,n,m,g) # n,m,g-elements array whose content is garbage\na = fill(j,n,m,g)           # n,m,g-elements array of identical j elements\na = rand(n,m,g)             # n,m,g-elements array of of random numbers\na = [3x + 2y + z for x in 1:2, y in 2:3, z in 1:2] # from using list comprehension","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Accessing-n-dimensional-arrays","page":"0103-predefined types","title":"Accessing n-dimensional arrays","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"Access by indicating position","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"a = [1 2 3 4; 5 6 7 8; 9 10 11 12]\na[2,1]   # comma to separate the dimensions","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"warning: Warning\nDon't confuse a[i,j] for selecting an element of a Matrix with a[i][j] to select the inner component of a nested array","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"a[1,2:3]   # with a range on the second dimension\na[[1,3],1] # with a vector of positions in the first dimension\na[2,:]     # with a full range (all values) in the second dimension, i.e. all columns value for row 2","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"warning: Warning\nNote that when the data as only one element on a given dimension, julia reduces the dimensions automatically: the result of a[2,:] is NOT a row vector (that is a one-row matrix) but a one dimensional array","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"Access by a mask (boolean selection)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"b = [true false true false; true true true false; true false true false]\na[b] # always flatted array returned (need eventually reshaping, see later)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Funcionality-related-to-dimensions","page":"0103-predefined types","title":"Funcionality related to dimensions","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"size(a)              # returns a tuple (i.e. an immutable list) with the sizes of the n dimensions\nndims(a)             # return the number of dimensions of the array (e.g. `2` for a matrix)\nreshape(a, 2,3,2)\n2*3*2 == length(a)\nb = rand(2,1,3)\ndropdims(b,dims=(2)) # remove the specified dimensions, provided that the specified dimension have only a single element\npermutedims(a)  # \"swap\" the dimensions\nreshape(a,4,3)  # keep the column mayor order\nfor slice in eachslice(a,dims=1)\n    println(slice)\nend\na = reshape(1:24, 3,4,2)\nfor slice in eachslice(a,dims=1)\n    println(slice)\nend\na = [1 2;3 4; 5 6]\nselectdim(a,1,3) # Select an hyperplane on dimension 1 (rows) at position 3. Returns a view","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Flat-to-vector..","page":"0103-predefined types","title":"Flat to vector..","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"a = [1 2; 3 4]\nvec(a)        # shadow copy (different view of the underlying data)\nreshape(a,4)  # shadow copy\na[:]          # allocate, as all slice operations do","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Other-functionality-related-to-Arrays","page":"0103-predefined types","title":"Other functionality related to Arrays","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"vcat([1 2; 3 4], [5 6; 7 8]) # works also for DataFrames\nhcat([1,2,3],[4,5,6])        # works also for DataFrames\na = [1 2; 3 4]\nb = similar(a) # garbage inside\ncat(a,a,a,dims=3)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"Sort by column (field)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"a = [[3,2,1] [20,30,20] [1000,3000,2000] [300,100,200]]\nidx = sortperm(a[:,3], rev=true) # return the positions that sort the 3rd column\nsortedMatrix = a[idx,:] # selected by using the sorted positions array on the row dimension\nsortslices(a, dims=2)   # by cols, using the first row to sort\nsortslices(a, dims=1)   # by rows, using the first column to sort\nsortslices(a, dims=1, by = x -> (x[2],x[4])) # by rows, using second and fourth columns","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Basic-linear-algebra","page":"0103-predefined types","title":"Basic linear algebra","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"using LinearAlgebra\na = [-1,2,3]\nb = [4,5,6]\ntranspose(a)\na'\nnorm(a)   # l-2 by default\nnorm(a,1)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"Vector products:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"dot(a,b)    # dot, aka \"inner\" product\na' * b  == dot(a,b)\ncross(a,b)  # cross product\na .* b      # element-wise product\na * b'\n\nA = [1 2 3; 6 4 5; 7 8 9]\n\nA^(-1) # inverse\nA^2\ndet(A) # determinant\ntranspose(A)\nA'","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"warning: Warning\nBe aware that transpose works only for numerical types. When the matrix contains other types (e.g. strings), use permutedims","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"diag(A)\nI # operator that automatically scale to the context without actually building the matrix\nA*I\nB = [1 2; 3 4]; B*I\n(evalues, evectors) = eigen(A)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Tuples-Tuple{T1,T2,...}","page":"0103-predefined types","title":"Tuples - Tuple{T1,T2,...}","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"A \"collection\" similar to Array but:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"Immutable\nCan efficiently host heterogeneous types, as type information is stored for each individual element\nLinear algebra doesn't apply (use StaticArray.jl package for that)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"Can be tought as anonymous (immutable) structures Used to unpack multiple values, e.g. to store on inddividual variables the output of functions with multiple return value","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Initialisation-3","page":"0103-predefined types","title":"Initialisation","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"t = (1,2.5,\"a\",3)\nt = 1,2.5,\"a\",3\ntypeof(t)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Indexing","page":"0103-predefined types","title":"Indexing","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"t[1]","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Conversion","page":"0103-predefined types","title":"Conversion","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"v = [1,2,3]\nt = (v...,) # note the comma\nv2 = [t...]\nv3 = [i[1] for i in t]\nv4 = collect(t)\nv == v2 == v3 == v4","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Named-tuples-NamedTuple{T1,T2,...}","page":"0103-predefined types","title":"Named tuples - NamedTuple{T1,T2,...}","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"As the name suggests, named tuples are collection similar to ordinary tuples, but whose indexing can accept also a name:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"nt = (a=1, b=2.5)\n#nt = (\"a\"=1, \"b\"=2.5)    # Error !\ntypeof(nt)\nnt[1]\nnt.a\nkeys(nt)\nvalues(nt)\n\nfor (k,v) in pairs(nt)\n    println(\"$k - $v\")\nend","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"warning: Warning\nThe keys of NamedTuples are symbols, not strings. We'll see symbols in the metaprogramming segment.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Conversion-2","page":"0103-predefined types","title":"Conversion","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"k = [:a,:b,:c]\nv = [1,2,3]\nnt = NamedTuple(Dict(:a=>1,:b=>2,:c=>3))             # Order not guaranteed! We are \"lucky\" here\nnt = NamedTuple(Dict([k=>v for (k,v) in zip(k,v)]))  # Same...\nv2 = [nt...]\nv3 = [i[1] for i in nt]\nv4 = collect(nt)\nv == v2 == v3 == v4","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Dictionaries-Dict{Tkey,TValue}","page":"0103-predefined types","title":"Dictionaries - Dict{Tkey,TValue}","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"Dictionary are mutable, key-referenced containers:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":" Mutable Immutable\nUse position Arrays Tuples\nUse keys Dictionaries Named tuples","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"warning: Warning\nNote that order is not preserved. For insertion-order preservation see OrderedDict and for sorted dictionaries see SortedDict, both from the DataStructures.jl package.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Initialisation-4","page":"0103-predefined types","title":"Initialisation","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"mydict = Dict(); #= or better =#  mydict = Dict{String,Int64}()\nmydict = Dict('a'=>1, 'b'=>2, 'c'=>3)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Indexing-2","page":"0103-predefined types","title":"Indexing","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"mydict['a']\n#mydict['d']     # error!\nget(mydict,'d',0) # specific a default if key not found","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Adding/deleting/checking","page":"0103-predefined types","title":"Adding/deleting/checking","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"mydict['d'] = 4\n\ndelete!(mydict,'d')\nhaskey(mydict, 'a')\nin(('a' => 1), mydict)\ntypeof('a' => 1)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Conversion-3","page":"0103-predefined types","title":"Conversion","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"Array - > Dictionary","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"map((i,j) -> mydict[i]=j, ['e','f','g'], [4,5,6])\nmydict\nk = [:a,:b,:c]\nv = [1,2,3]\nmydict = Dict([k=>v for (k,v) in zip(k,v)])","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"Dictionary -> Arrays","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"collect(keys(mydict)) # keys or values alore return an iterator\ncollect(values(mydict))","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Iteration","page":"0103-predefined types","title":"Iteration","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"for (k,v) in mydict\n   println(\"$k is $v\")\nend","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Sets-Set{T}","page":"0103-predefined types","title":"Sets - Set{T}","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"s = Set(); #= or better =# Set{Int64}()\ns = Set([1,2,3,4]) # Only a single `2` will be stored\ns\npush!(s,5)\ndelete!(s,1)\ns2 = Set([4,5,6,7])\nintersect(s,s2)\nunion(s,s2)\nsetdiff(s,s2)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Date-and-time-Date,-DateTime","page":"0103-predefined types","title":"Date and time - Date, DateTime","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"using Dates # a standard library module dealing with dates and times, including periods and calendars","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"While a DateTime is a more informative object it is also a much more complex one, as it has to deal with problems as the time zones and the daylight saving","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Creation-of-a-date-or-time-object-(\"input\")","page":"0103-predefined types","title":"Creation of a date or time object (\"input\")","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"From current (local) date/time...","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"todayDate = today()\nnowTime = now()\ntypeof(todayDate)\n\ntypeof(nowTime)\nDate     <: Dates.AbstractTime\nDateTime <: Dates.AbstractTime\nnowTimeUnix = time()  # The so-called \"Unix time, a 64bit integer counting the number of seconds since the beginning of the year 1970\nnowTime = Dates.unix2datetime(nowTimeUnix) # attention this is not local but UTC (Coordinated Universal Time - the Greenwitch time )!\nnowTime = Dates.now(Dates.UTC) # an other way to have UTC time","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"tip: Tip\nFor Time Zone functionalities and conversion, use the external package TimeZone.jl","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"From a String...","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"christmasDay      = Date(\"25 Dec 2030\", \"d u yyyy\")\nnewYearDay        = Date(\"2031/01/01\", \"yyyy/m/d\")\nchristmasLunch    = DateTime(\"2030-12-25T12:30:00\", ISODateTimeFormat)   # well known string datetime ISO8601 Format\nnewYearEvenDinner = DateTime(\"Sat, 30 Dec 2030 21:30:00\", RFC1123Format) # an othe well known format","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"Date and time formatters:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"y  Year digit (ef yyyy => 2030, yy => 30)\nm  Month digit (eg m => 3, mm => 03)\nu  Month name (eg \"Jan\")\nU  Month name long (eg \"January\")\ne  Day of week (eg \"Tue\")\nE  Day of week long (eg \"Tuesday\")\nd  Day of month (eg d => 3, dd => 03)\nH  Hour digit (eg H => 8, HH => 08)\nM  Minute digit (eg M => 0, MM => 00)\nS  Second digit (eg S => 0, SS => 00)\ns  Millisecond digit (eg .000, fixed 3 digits)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"Note that the doubling for the digits matters only for using the formatters in the output (see later)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"From a tuple of integers: y, m, d, H, M, S, s ...","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"d  = Date(2030, 12)  # no need to give it all\ndt = DateTime(2030, 12, 31, 9, 30, 0, 0)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Date/Time-extraction-of-information-(\"output\")...","page":"0103-predefined types","title":"Date/Time extraction of information (\"output\")...","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"To String represerntation...","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"Dates.format(newYearDay, \"dd/m/yy\")\nDates.format(christmasLunch, \"dd/mm/yy H:M:SS\")","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"Other...","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"# Date and DateTime...\nyear(christmasDay)\nisleapyear(christmasDay)\nmonth(christmasLunch)\nmonthname(christmasDay)\nday(christmasDay)\ndayofweek(christmasDay)\ndayname(christmasDay)\ndaysofweekinmonth(christmasDay) # there are 4 Wednesdays in December 2030\ndayofweekofmonth(christmasDay)  # and the 25th is the 4th of them\n\n# Only datetime..\nhour(christmasLunch)\nminute(christmasLunch)\nsecond(christmasLunch)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Periods-and-datetime-arithmetics","page":"0103-predefined types","title":"Periods and datetime arithmetics","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"hollidayPeriod = newYearDay - christmasDay  # between dates is in days\nlongPeriod = Date(2035,6,1) - christmasDay\nmealPeriod = DateTime(2030,12,31,23,30) - newYearEvenDinner # between datetime is in milliseconds\n#newYearDay - newYearEvenDinner # error! no mixed\nconvert(DateTime,newYearDay)\nconvert(Date,newYearEvenDinner) # possible information loss\nmealPeriod = convert(DateTime,newYearDay) - newYearEvenDinner\ntypeof(hollidayPeriod)\ntypeof(mealPeriod)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"Period hierarchy:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"Period\nDatePeriod\nYear\nMonth\nWeek\nDay\nTimePeriod\nHour\nMinute\nSecond\nMillisecond\nMicrosecond\nNanosecond","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"#convert(Dates.Year,longPeriod)      # going up: error or inexacterror\nconvert(Dates.Millisecond,longPeriod) # going down:  fine\nconvert(Dates.Millisecond,mealPeriod)\n\ncanLongPeriod = Dates.canonicalize(longPeriod)\ntypeof(canLongPeriod)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"That the best we can get. We can't \"easily\" decompose a \"period\" in  years or months... how many days in a month ? 31 or 30 ? And in an year ? A Period doesn't store information on when it starts. However we can make math with periods based on a specific date/time:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"nextChristmas                = christmasDay + Year(1) # We can use the constructors of the various periods\nchristmasPresentsOpeningTime = christmasLunch + Hour(3)\nthisWeekdayNextCentury       = dayname(today()+Year(100))","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"Ranges","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"semesters = Dates.Date(2020,1,1):Dates.Month(6):Dates.Date(2022,1,1)\ncollect(semesters)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html#Adjustments","page":"0103-predefined types","title":"Adjustments","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"Iterate the past/future days of a date untill some condition is true","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"sundayBefChristmas = toprev(d -> Dates.dayname(d) == \"Sunday\", christmasDay)\nlastDayOfThisMonth = tonext(d -> Dates.day(d+Day(1)) == 1, today())","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"Find first or last weekday of {month,year} of a given date:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"lastTuesdayOfThisMonth = tolast(today(), 2, of=Month) # \"2\" stands for Tuesday\nfirstSundayOfThisYear  = tofirst(today(), 7, of=Year) # \"7\" stands for Sunday","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"View this file on Github.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0103-predefined_types.html","page":"0103-predefined types","title":"0103-predefined types","text":"This page was generated using Literate.jl.","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html#Machine-Learning-main-concepts","page":"0301-MachineLearningMainIdeas","title":"0301 - Machine Learning -  main concepts","text":"","category":"section"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"We start our journey on Machine Learning from the perceptron algorithm. This is a linear classifier that historically has been a bit a pioneer in ML algorithms. We start from it due to its simplicity, and it will be the only algorithm that we will study in detail.","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html#A-linear-classifier-for-the-binary-classification-problem","page":"0301-MachineLearningMainIdeas","title":"A linear classifier for the binary classification problem","text":"","category":"section"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"So, which is our problem? We are in the realm of supervised machine learning as we defined in the kick-off lesson, where the objective is to make some predictions over a component of the dataset (an unknown characteristic, or some future event...) that we call \"label\" based on other known characteristics of the data (that we call \"features\"), and we can \"learn\" this relation by \"supervising\" the algorithm, that is providing the algorithm with data from which we know both the features and the associated labels (across this course I'll often use \"X\" as a shortcut for the former, and \"Y\" for the latter). More specifically we are in the realm of classification, where the labels are given a finite set of possible values, and we start from binary labels, where the values can only be -1 or +1 (it is easy then to use this binary classifier as the base for a multiclass classifier, e.g. using a so-called one-vs-all strategy). The features are numerical, and possibly highly multi-dimensional.","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"The Perceptron algorithm is a method to find the parameters of a linear classifier that minimise classification errors. These classifiers will be nothing else than a hyperplane (the generalisation of the concept of \"plane\" on multiple dimensions) that divides our space into two parts, with the hyperplane itself forming the boundaries between the two parts, and we will use this hyperplane to discriminate all points on one side of it v.s. all points on the other side. For example, the following figure shows a hyperplane in 2D (i.e. a line) used to classify some points:","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"(Image: A linear classifier in 2D)","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"All points in the direction of the arrow are \"positive\", all points in the opposite direction are negative. From the figure we can deduce a few things in that example:","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"the current classifier (as drawn) is NOT classifying all points correctly, ie it makes \"errors\"\nthe points are however linearly separable\nit would be enough to \"rotate\" a bit the classifier clockward to get the classifier making no more errors","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"The perceptron algorithm is indeed an online algorithm (that is, that is updated as data is processed..) to \"rotate\" the classifier until it minimises the classification errors. For simplicity, we will work with classifiers passing through the origin, but we don't lose in generality as we can always think of the constant term as another dimension where the feature data is all filled with ones.","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"Our first step is to \"decide\" how to define the classifier, and how to check if it classifies a record correctly or not. Concerning the former, we define the boundary given by the parameters theta as the set of points x for which x cdot theta = 0 (the inner product is equal to zero). It results that all points x for which $ x \\cdot \\theta > 0$ are classified positively, and similarly all points x for which $ x \\cdot \\theta < 0$ are classified negatively. For a given record, we can now check if this classifier matches the label of the record (-1 or +1). In analytical terms, we have a classification error of the (linear) classifier theta for the record n when  y^n * (theta cdot x^n)) leq 0. The overall error rate of the classifier will then be the sum of the errors for each record divided by the number of records N:","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"epsilon_n(theta) = sum_n=1^N frac mathbb1  y^n * (theta cdot x^n ) leq 0  n","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"where the one at the numerator is an indicator function. And note that we consider a point exactly on the boundary still as a classification error.","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html#Supervised-learning","page":"0301-MachineLearningMainIdeas","title":"Supervised learning","text":"","category":"section"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"Before we can turn to the problem of actually finding a linear classifier that agrees with the data to the extent possible, that is looking at the specific perceptron algorithm, we need to develop a method to generally deal with \"learning algorithms\" in the context of supervised learning, where - like here - we are given a set of both the features (the \"X\" matrix) and the associated labels (the \"Y\" vector - or sometimes matrix).","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"Let's then define as the algorithm's parameters those parameters that are learned by an algorithm by processing the (X,y) data that we provide to it to learn its relations. Often an algorithm has also so-called hyperparameters. These are additional parameters that remain constant during the learning (also called training) step, while still affecting the performances of the algorithm. For example, the number of neurons in a neural network layer, or the number of individual decision trees in the random forest algorithm. Or, for many algorithms (including perceptron) how long should the learning step continue (this can take different forms depending on the algorithm).","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"Hyperparameters play a fundamental role in the trade-off between specialisation and generalisation. The objective of the training is not indeed to learn a relation between the given X and the given Y, but rather to learn from the provided data the general relationship between X and Y for all the populations from which X and Y have been sampled. And hyperparameters should be \"set\" to the levels that maximise this objective, not the minimisation of errors in the data used to train the algorithm. If we use too many neurons, if we train too much,.. we would learn the specific relation between X and Y in the training data. However, this reflects the specific data provided and not the general population. In statistical terminology, we would overfit our model, or in other words, generate too much variance in the trained parameter of our model, that would depend too much on the specific training data (i.e. different training data would lead to very different learned parameters). On the opposite, if our model is too simple or receives too little training, we will have too much bias and not learn the relationship sufficiently. Techniques that allow an algorithm to better generalise, at the expense of better performances over the training data, are called \"regularisation\".","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"How can we choose the hyperparameters that minimise the bias-variance trade-off ? We put no assumptions on the data except that they all come from the same population. And the idea is to use the data itself to \"evaluate\" the generality of our model. We randomly split our dataset into three subsets:","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"The training set is the one used to actually \"train\" the algorithm to learn the relation between the given X and the given y, provided a certain set of hyperparameters, that is to find the parameters than minimise the error made by the algorithm\nthe validation set is used to evaluate the results of our trained algorithm on data that has not been used by the algorithm to train the parameters, that is to find the hyperparameters that allow for the best generalisation\nfinally the test set is used to judge the overall performances of the algorithm when it is used with the \"best\" hyperparameter (we can't use the validation set for this, as the hyperparameters are \"fitted\" based on it).","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"(Image: Train, validation and test set)","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"In practice, we have various ways to look for the \"best hyperparameters\".. grid search over the hyperparameters space, random search, gradient-based methods... In all cases, we run the algorithm under the training set, and we evaluate it under the validation set until we find the \"best\" hyperparameter set. At this point, with the \"best\" hyperparameters we train one last time the algorithm using the training set and we evaluate it under the test set.","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html#K-folds-cross-validation","page":"0301-MachineLearningMainIdeas","title":"K-folds cross validation","text":"","category":"section"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"Note that training and validation sets don't need to be the same sample across the whole process. Indeed a common technique is the so-called K-folds cross-validation:","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"(Image: 5-folds CrossValidation)","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"Here we first randomly divide our whole dataset in a train/validation set and in the test set. For each possible hyperparameter set, we randomly partition the train/validation test in K sets. We use K-1 of them for training and the remaining one for computing the out-of-sample score of the model. We do that (keeping the same hyperparameters and the same partition) for all the different K subsets and we average the performances of the model with that given hyperparameters. We then select the \"best\" hyperparameters and we run the final training on the train/validation set and evaluation on the test set.","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html#The-perceptron-algorithm","page":"0301-MachineLearningMainIdeas","title":"The perceptron algorithm","text":"","category":"section"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"We can now start our analysis of the Perceptron algorithm.","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"We start with the parameters of the hyperplane all zeros theta = 0\nWe check if, with this parameter, the classifier makes an error\nIf so, we progressively update the classifier using as the update function  theta^n = theta^n - 1 + y^n * x^n.","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"As we start with theta^0 = beginbmatrix00endbmatrix, the first attempt will always lead to an error and to a first \"update\" that will be theta^1 = beginbmatrix00endbmatrix + y^1 * beginbmatrixx^1_d1x^1_d2endbmatrix.","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"Let's make an exaple in 2 dimensions, with two points x^1 = beginbmatrix24endbmatrix and x^2 = beginbmatrix-61endbmatrix, both with negative labels.","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"After being confronted with the first point, the classifier theta^0 undergos its first update to become theta^1 = beginbmatrix00endbmatrix + -1 * beginbmatrix24endbmatrix = beginbmatrix-2-4endbmatrix. Let's continue with the second point, x^(2) = beginbmatrix-61endbmatrix. Does theta^1 make an error in classifying x^2 ? We have:  y^(2) * theta^1 cdot x^(2) = -1 * beginbmatrix-2-4endbmatrix beginbmatrix-61endbmatrix = -8, so yes, we have another classification error. We hence run a second update to obtain  theta^2 = beginbmatrix-2-4endbmatrix + -1 * beginbmatrix-61endbmatrix = beginbmatrix4-5endbmatrix. I let you see geometrically that this classifier correctly classify the two points:","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"(Image: Perceptron example over 2 points)","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"More in general, we run the perceptron algorithm over the whole training set, starting from the 0 parameter vector and then going over all the training examples. And if the n-th example is a mistake, then we perform that update that we just discussed.","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"So we moved the parameters in the right direction, based on an individual update. However, since the different training examples might update the parameters in different directions, the later updates might also \"undo\" some of the earlier updates, and some of the earlier examples would no longer be correctly classified. In other words, there may be cases where the perceptron algorithm needs to go over the training set multiple times before a separable solution is found (I let you try as exercise what would happen if the second point is +1-2 instead of -6+1, still with negative label).","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"So we have to go through the training set here multiple times. In the jargon of machine learning, we call epoch each time an algorithm goes through the whole training set, either in order or selecting at random. On each record, we look at whether the current classify makes a mistake and eventually perform a simple update.","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"function perceptron displaystyle left(big  (x^(n) y^(n)) n=1Nbig   epochs right):\ninitialize theta =0 (vector);\nfor t=1epochs do\nfor n=1N do\nif y^(n)(theta cdot x^(n)) leq 0 then\nupdate theta = theta + y^(n)x^(n)\nreturn theta","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"So the perceptron algorithm takes two parameters: the training set of data (pairs feature vectors => label) and the epochs parameter that tells how many times going over the training set.","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"For a sufficiently large number of epochs, if there exists a linear classifier through the origin that correctly classifies the training samples (i.e. the training set is linearly separable), this simple algorithm actually will find a solution to that problem. Typically, there are many solutions, but the algorithm will find one. And note that the one found is not, in general, the \"optimal\" one, where the points are \"best\" separated, just one where the points are separated.","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html#Support-Vector-Machines:-\"better\"-linear-classifiers","page":"0301-MachineLearningMainIdeas","title":"Support Vector Machines: \"better\" linear classifiers","text":"","category":"section"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"While the Perceptron algorithm finds one possible classifier, it is clear that this may not be the \"best\" one. See the following figure:","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"(Image: Different linear classifiers over the same dataset)","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"Linear classifiers do generalise relatively well and the epochs parameter could be used as a form of regularisation. Still, we could end up with a perceptron classifier like in figure (a), very dependent on noisy data and that doesn't generalise well. Support Vector Machines (SVM, which we will not develop further in this course except in this small discussion) are linear classifiers that try to maximise the boundary with the classified data. So here we enter the realm of \"optimisation\", usually achieved employing a gradient-based approach that we'll see when discussing neural networks: it is no longer indifferent one classifier that separates the data from another, but SVM (should) retrieve the classifier that is more \"far away\" from the two datasets, on both the directions (figure (b)). The second important characteristic of SVM is that this optimisation can be \"adjusted\" to consider not only the points that lie closest to the decision surface (the \"support vectors\", from which the name..) but rather to give importance to the points that are farther away from the boundary. This adjustment takes the form of a regularisation parameter that can try to optimize with the cross-validation technique above. So, in the figure example, we intuitively see that the third classifier ( figure (c) ) would be the best for our dataset, it will better match with the nature of our data, even if it would make some classification mistakes, and we can steer an SVM algorithm toward the one depicted on figure (c) by increasing its regularisation parameter.","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html#Using-linear-classifiers-for-non-linear-classification","page":"0301-MachineLearningMainIdeas","title":"Using linear classifiers for non-linear classification","text":"","category":"section"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"Often the relationship between the X and the Y is not linear in nature, and even employing the best linear classifier would result in significant classification errors (same for regressions). The \"good news\" is that we can easily engineer our data performing non-linear transformation over it and still using a linear classifier.","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"For example in the left diagram in the figure below, the three points are not separable in one dimension:  ","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"(Image: Inseparable points becoming separable in higher dimensions)","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"However, we can \"engineer\" our dataset by creating a new dimension that is the square of our original dimension (diagram on the right): the points are now clearly separable by a linear classifier !","category":"page"},{"location":"03_-_ML1_-_Introduction_to_Machine_Learning/0301-MachineLearningMainIdeas.html","page":"0301-MachineLearningMainIdeas","title":"0301-MachineLearningMainIdeas","text":"The \"bad news\" is that this engineering is not \"learned\" by the algorithm, but it is something we still do on a case-by-case, using our expertise of the specific problem on hand.  This is the main difference between linear algorithms used together with feature transformation and more \"modern\" non-linear algorithms where the non-linearity is learned from the data itself, like in trees-based approaches and neural networks. ","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"EditURL = \"https://github.com/sylvaticus/SPMLJ/blob/main/lessonsSources/01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.jl\"","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"################################################################################\n###  Introduction to Scientific Programming and Machine Learning with Julia  ###\n###                                                                          ###\n### Run each script on a new clean Julia session                             ###\n### GitHub: https://github.com/sylvaticus/IntroSPMLJuliaCourse               ###\n### Licence (apply to all material of the course: scripts, videos, quizes,..)###\n### Creative Commons By Attribution (CC BY 4.0), Antonello Lobianco          ###\n################################################################################","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Further-Topics","page":"0106-further topics","title":"0106 Further Topics","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Some-stuff-to-set-up-the-environment..","page":"0106-further topics","title":"Some stuff to set-up the environment..","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"cd(@__DIR__)\nusing Pkg\nPkg.activate(\".\")","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"If using a Julia version different than 1.7 please uncomment and run the following line (reproductibility guarantee will however be lost) Pkg.resolve() Pkg.instantiate() # run this if you didn't in Segment 01.01","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"using Random\nRandom.seed!(123)\nusing InteractiveUtils # loaded automatically when working... interactively","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Metaprogramming-and-macros","page":"0106-further topics","title":"Metaprogramming and macros","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"\"running\" some code include the following passages (roughly):","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"parsing of the text defining the code and its translation in hierarchical expressions to the Abstract syntax Tree (AST) (syntax errors are caugth at this time)\non the first instance required (\"just in time\") compilation of the AST expressions into object code (using the LLVM compiler)\nexecution of the compiled object code","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"\"Macros\" in many other language (e.g. C or C++) refer to the possibility to \"pre-process\" the textual representation of the code statements before it is parsed. In julia instead it refers to the possibility to alter the expression once has already being parsed in the AST, allowing a greater expressivity as we are no longer limited by the parsing syntax","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"The AST is organised in a hierarchical tree of expressions where each element (including the operators) is a symbol For variables, you can use symbols to refer to the actual identifiers instad to the variable's value","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"Expressions themselves are objects representing unevaluated computer expressions","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Expressions-and-symbols","page":"0106-further topics","title":"Expressions and symbols","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"expr1 = Meta.parse(\"a = b + 2\") # What the parser do when reading the source code. b doesn't need to actually been defined, it's just a namebinding without the reference to any object, not even `nothing`\ntypeof(expr1) # expressions are first class objects\nexpr2 = :(a = b + 1)\nexpr3 = quote a = b + 1 end\nexpr3\ndump(expr1)   # The AST ! Note this is already a nested statement, an assignment of the result of an expression (the sum call between the symbol `:b` and 1) to the symbol `a`\nexpr4 = Expr(:(=),:a,Expr(:call,:+,:b,1)) # The AST using the \"Expr\" constructor\n\nsymbol1   = :(a)               # as for expressions\nsymbol2   = Meta.parse(\"a\")    # as for expressions\nsymbol3   = Symbol(\"a\")        # specific for symbols only\nothsymbol = Symbol(\"aaa\",10,\"bbb\")\ntypeof(symbol1)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"I can access any parts of my expression before evaluating it (indeed, that's what macro will do...)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"myASymbol = expr1.args[2].args[1]\nexpr1.args[2].args[1] = :(*)\nb = 2\n# a # error, a not defined\neval(expr1)\na # here now is defined and it has an object associated... 4!","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"danger: Danger\nThe capability to evaluate expressions is very powerfull but due to obvious secutiry implications never evaluate expressions you aren't sure of their provenience. For example if you develop a Julia web app (e.g. using Genie.jl) never evaluate user provided expressions.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"Note that evaluation of expressions happens always at global scope, even if it done inside a function:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"function foo()\n    locVar = 1\n    expr = :(locVar + 1)\n    return eval(expr)\nend\n# a = foo() # error locVar not defined","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"To refer to the value of a variable rather than the identifier itself within an expression, interpolate the variable using the dollar sign:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"expr = :($a + b) # here the identifier 'a' has been replaced with its numerical value, `4`\ndump(expr)\neval(expr)\na = 10\neval(expr) # no changes\nb = 100\neval(expr) # here it change, as it is at eval time that the identifier `b` is \"replaced\" with its value","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Macros","page":"0106-further topics","title":"Macros","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"One of the best usage of macros is they allow package developers to provide a very flexible API to their package, suited for the specific needs of the package, making life easier for the users. Compare for example the API of JuMP with those of Pyomo to define model constraints !","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"Some examples of macros: MultiDimEquations.jl","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"from: @meq par1[d1 in DIM1, d2 in DIM2, dfix3] =  par2[d1,d2]+par3[d1,d2]\nto:   [par1[d1,d2,dfix3] =  par2[d1,d2]+par3[d1,d2] for d1 in DIM1, d2 in DIM2]","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"Pipe.jl:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"from: @pipe  10 |> foo(_,a) |> foo2(b,_,c) |> foo3(_)\nto:   foo3(foo2(b,foo(10,a),c))","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"Brodcasting (Base):","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"from: @. a + b * D^2\nto:   a .+ b .* D.^2","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"Defining a macro...","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"Like functions, but both the arguments and the returned output are expressions","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"macro customLoop(controlExpr,workExpr)\n    return quote\n      for i in $controlExpr\n        $workExpr\n      end\n    end\nend","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"Invoking a macro....","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"a = 5\n@customLoop 1:4 println(i) #note that \"i\" is in the macro\n@customLoop 1:a println(i)\n@customLoop 1:a if i > 3 println(i) end\n@customLoop [\"apple\", \"orange\", \"banana\"]  println(i)\n@customLoop [\"apple\", \"orange\", \"banana\"]  begin print(\"i: \"); println(i)  end\n@macroexpand @customLoop 1:4 println(i) # print what the macro does with the specific expressions provided","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"String macros (aka \"non-standard string literals\") Invoked with the syntax xxx\" ...text...\" or xxx\"\"\" ...multi-line text...\"\"\" where xxx is the name of the macro and the macro must be defined as macro  xxx_str. Used to perform textual modification o nthe given text, for example this print the given text on a 8 characters","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"macro print8_str(mystr)                                 # input here is a string, not an expression\n    limits = collect(1:8:length(mystr))\n    for (i,j) in enumerate(limits)\n      st = j\n      en = i==length(limits) ? length(mystr) : j+7\n      println(mystr[st:en])\n    end\nend\n\nprint8\"123456789012345678\"\nprint8\"\"\"This is a text that once printed in 8 columns with terminal will be several lines. Ok, no rammar rules relating to carriage returns are emploied here...\"\"\"","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"While normally used to modify text, string macros are \"true\" macros:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"macro customLoop_str(str)\n    exprs = Meta.parse(str)\n    controlExpr,workExpr = exprs.args[1],exprs.args[2]\n    return quote\n      for i in $controlExpr\n        $workExpr\n      end\n    end\nend\n\ncustomLoop\"\"\"1:4; println(i)\"\"\"","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Interfacing-with-other-languages","page":"0106-further topics","title":"Interfacing with other languages","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"There are 3 ways to interface Julia with programs or libraries wrote in other languages. At the lowest level, Julia allows to directly interface with C or Fortran libraries, and this means, aside using directly libraries written in C, to be able to interface with any programming language that offer also a C interface (R, Python...) Using this low level C Interface, users have created specific packages to interface many languages using a simple, Julian-way syntax. We will see these interfaces for R and Python. Finally, at the highest level, many common packages of other languages have been already \"interfaced\", so that the user can use the Julia Package without even knowing that this is an interface for an other package, for example SymPy.jl is a large interface to the Python package SymPy.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Using-C-libraries","page":"0106-further topics","title":"Using C libraries","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"Let's start by seing how to use a C library. For this example to work you will need to have the GCC compiler installed on your machine First let's write the header and source C files and write them to the disk:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"cheader = \"\"\"\nextern int get5();\nextern double mySum(float x, float y);\n\"\"\"\ncsource = \"\"\"\nint get5(){\n    return 5;\n}\n\ndouble mySum(float x, float y){\n    return x+y;\n}\n\"\"\"\n\nopen(f->write(f,cheader),\"myclib.h\",\"w\")  # We open a stream to file with the \"w\" parameter as for \"writing\", and we pass the stream to the anonymous function to actually write to the stream. If this funcitons is many lines of code, consider rewriting the `open` statement using a `do` block\nopen(f->write(f,csource),\"myclib.c\",\"w\")","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"Now let's run the command to compile the C code we saved as shared library using gcc, a C compiler. The following example assume that GCC is installed in the machine where this example is run and available as gcc.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"compilationCommand1 = `gcc -o myclib.o -c myclib.c` # the actual compilation, note the backticks used to define a command\ncompilationCommand2 = `gcc -shared -o libmyclib.so myclib.o -lm -fPIC` # the linking into a shared library\nrun(compilationCommand1)\nrun(compilationCommand2)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"This should have created the C library libmyclib.so on disk. Let's gonna use it:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"const myclib = joinpath(@__DIR__, \"libmyclib.so\")  # we need the full path","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"ccall arguments:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"A tuple with the funcion name to call and the library path. For both, if embedded in a variable, the variable must be set constant.\nThe Julia type that map to the C type returned by the function.\nint → Int32 or Int64 (or the easy-to remmeber Cint alias)\nfloat → Float32 (or the Cfloat alias)\ndouble → Float64 (or the Cdouble alias)\nA tuple with the Julia types of the parameters passed to the C function\nAny other argument are the values of the parameter passed","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"a = ccall((:get5,myclib), Int32, ())\nb = ccall((:mySum,myclib), Float64, (Float32,Float32), 2.5, 1.5)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"More details on calling C or Fortran code can be obtained in the official Julia documentation.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Using-Python-in-Julia","page":"0106-further topics","title":"Using Python in Julia","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"The \"default\" way to use Python code in Julia is trough the PyCall.jl package. It automatically take care of convert between Python types (including numpy arrays) and Julia types (types that can not be converted automatically are converted to the generic PyObject type).","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"ENV[\"PYTHON\"] = \"\" # will force PyCall to download and use a \"private to Julia\" (conda based) version of Python. use \"/path/to/python\" if you want to reuse a version already installed on your system\n# using Pkg\n# Pkg.add(\"PyCall\")\n# Pkg.build(\"PyCall\")\nusing PyCall","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Embed-short-python-snippets-in-Julia","page":"0106-further topics","title":"Embed short python snippets in Julia","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"py\"\"\"\ndef sumMyArgs (i, j):\n  return i+j\ndef getNthElement (vec,n):\n  return vec[n]\n\"\"\"\na = py\"sumMyArgs\"(3,4)             # 7 - here we call the Python object (a function) with Julia parameters\nb = py\"getNthElement\"([1,2,3],1)   # 2 - attention to the diffferent convention for starting arrays!. Note the Julia Array ahas been converted automatically to a Python list\nd = py\"getNthElement([1,$a,3],1)\"  # 7 - here we interpolate the Python call","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"Alternativly, use @pyinclude(\"pythonScript.py\")","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"pythonCode = \"\"\"\ndef sumMyArgs (i, j, z):\n  return i+j+z\n\"\"\"\nopen(f->write(f,pythonCode),\"pythonScript.py\",\"w\")\n@pyinclude(\"pythonScript.py\")\na = py\"sumMyArgs\"(3,4,5)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"tip: Tip\nNote thaat the 3 arguments definition of sumMyArgs has replaced the 3-arguments one. This would now error py\"sumMyArgs\"(3,4)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Use-Python-libraries","page":"0106-further topics","title":"Use Python libraries","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"Add a package to the local Python installation using Conda:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"pyimport_conda(\"ezodf\", \"ezodf\", \"conda-forge\") # pyimport_conda(module, package, channel)\n\nconst ez = pyimport(\"ezodf\")  # Equiv. of Python `import ezodf as ez`\ndestDoc  = ez.newdoc(doctype=\"ods\", filename=\"anOdsSheet.ods\")","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"Both ez and destDoc are PyObjects for which we can access attributes and call the methods using the usual obj.method() syntax as we would do in Python","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"sheet    = ez.Sheet(\"Sheet1\", size=(10, 10))\ndestDoc.sheets.append(sheet)\n# dcell1 = sheet[(2,3)] # This would error because the index is a tuple. Let's use directly the `get(obj,key)` function instead:\ndcell1   = get(sheet,(2,3)) # Equiv. of Python `dcell1 = sheet[(2,3)]`. Attention again to Python indexing from zero: this is cell \"D3\", not \"B3\" !\ndcell1.set_value(\"Hello\")\nget(sheet,\"A9\").set_value(10.5) # Equiv. of Python `sheet['A9'].set_value(10.5)`\ndestDoc.backup = false\ndestDoc.save()","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Using-Julia-in-Python","page":"0106-further topics","title":"Using Julia in Python","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Installation-of-the-Python-package-PyJulia","page":"0106-further topics","title":"Installation of the Python package PyJulia","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"PyJulia can be installed using pip, taking note that its name using pip is julia not PyJulia: $ python3 -m pip install --user julia","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"We can now open a Python terminal and initialise PyJulia to work with our Julia version:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":">>> import julia\n>>> julia.install() # Only once to set-up in julia the julia packages required by PyJulia","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"If we have multiple Julia versions, we can specify the one to use in Python passing julia=\"/path/to/julia/binary/executable\" (e.g. julia = \"/home/myUser/lib/julia-1.1.0/bin/julia\") to the install() function.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Running-Julia-libraries-and-code-in-Python","page":"0106-further topics","title":"Running Julia libraries and code in Python","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"On each Python session we need to run the following code:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"from julia import Julia\nJulia(compiled_modules=False)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"This is a workaround to the common situation when the Python interpreter is statically linked to libpython, but it will slow down the interactive experience, as it will disable Julia packages pre-compilation, and every time we will use a module for the first time, this will need to be compiled first. Other, more efficient but also more complicate, workarounds are given in the package documentation, under the Troubleshooting section.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"We can now direcltly load a Julia module, including Main, the global namespace of Julia’s interpreter, with from julia import ModuleToLoad and access the module objects directly or using the Module.evel() interface.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Add-a-Julia-package...","page":"0106-further topics","title":"Add a Julia package...","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":">>> from julia import Pkg\n>>> Pkg.add(\"BetaML\")","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"Of course we can add a package alternatively from within Julia","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#\"Direct\"-calling-of-Julia-functions...","page":"0106-further topics","title":"\"Direct\" calling of Julia functions...","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":">>> from julia import BetaML\n>>> import numpy as np\n>>> model = BetaML.buildForest([[1,10],[2,12],[12,1]],[\"a\",\"a\",\"b\"])\n>>> predictions = BetaML.predict(model,np.array([[2,9],[13,0]]))\n>>> predictions\n[{'b': 0.36666666666666664, 'a': 0.6333333333333333}, {'b': 0.7333333333333333, 'a': 0.26666666666666666}]","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Access-using-the-eval()-interface...","page":"0106-further topics","title":"Access using the eval() interface...","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"If we are using the jl.eval() interface, the objects we use must be already known to julia. To pass objects from Python to Julia, we can import the julia Main module (the root module in julia) and assign the needed variables, e.g.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":">>> X_python = [1,2,3,2,4]\n>>> from julia import Main\n>>> Main.X_julia = X_python\n>>> Main.eval('BetaML.gini(X_julia)')\n0.7199999999999999\n>>> Main.eval(\"\"\"\n...   function makeProd(x,y)\n...       return x*y\n...   end\n...   \"\"\"\n... )\n>>> Main.eval(\"makeProd(2,3)\") # or Main.makeProd(2,3)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"For large scripts instead of using eval() we can equivalently use Main.include(\"aJuliaScript.jl\")","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Using-R-in-Julia","page":"0106-further topics","title":"Using R in Julia","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"To use R from within Julia we use the RCall package.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"ENV[\"R_HOME\"] = \"*\" #  # will force RCall to download and use a \"private to Julia\" (conda based) version of R. use \"/path/to/R/directory\" (e.g. `/usr/lib/R`) if you want to reuse a version already installed on your system\n# using Pkg\n# Pkg.add(\"RCall\")\n# Pkg.build(\"RCall\")\nusing RCall\n\n\nR\"\"\"\nsumMyArgs <- function(i,j) i+j\ngetNthElement <- function(vec,n) {\n  return(vec[n])\n}\n\"\"\"\na = rcopy(R\"sumMyArgs\"(3,4))             # 7 - here we call the R object (a function) with Julia parameters\nb = rcopy(R\"getNthElement\"([1,2,3],1))   # 1 - no differences in array indexing here\nd = rcopy(R\"as.integer(getNthElement(c(1,$a,3),2))\")  # 7 - here we interpolate the R call\nd = convert(Int64,R\"getNthElement(c(1,$a,3),2)\")","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"While we don't have here the problem of different array indexing convention (both Julia and R start indexing arrays at 1), we have the \"problem\" that the output returned by using R\"...\" is not yet an exploitable Julia object but it remains as an RObject that we can convert with rcopy() or explicitly with convert(T,obj). Also, R elements are all floats by default, so if we need an integer in Julia we need to explicitly convert it, either in R or in Julia.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"If the R code is on a script, we don't have here a sort of @Rinclude macro, so let's implement it ourselves by loading the file content as a file and evaluating it using the function reval provided by RCall:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"macro Rinclude(fname)\n    quote\n        rCodeString = read($fname,String)\n        reval(rCodeString)\n        nothing\n    end\nend\n\nRCode = \"\"\"\nsumMyArgs <- function(i, j, z) i+j+z\n\"\"\"\nopen(f->write(f,RCode),\"RScript.R\",\"w\")\n@Rinclude(\"RScript.R\")\na = rcopy(R\"sumMyArgs\"(3,4,5))  # 12\n# a = rcopy(R\"sumMyArgs\"(3,4)) # error !  The 3-arguments version of `sumMyArgs` has _replaced_ the 2-arguments one","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Using-Julia-in-R","page":"0106-further topics","title":"Using Julia in R","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Installation-of-the-R-package-JuliaCall","page":"0106-further topics","title":"Installation of the R package JuliaCall","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"JuliaCall can be installed from CRAN:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"> install.packages(\"JuliaCall\")\n> library(JuliaCall)\ninstall_julia()","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"install_julia()will force R download and install a private copy of julia. If you prefer to use instead an existing version of julia and having R default to download a private version only if it can't find a version already installed, usejuliasetup(installJulia = TRUE)instead ofinstalljulia(), eventually passing theJULIAHOME = \"/path/to/julia/binary/executable/directory\"(e.g.JULIAHOME = \"/home/myUser/lib/julia-1.7.0/bin\") parameter to thejulia_setup` call","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"JuliaCall depends for some things (like object conversion between Julia and R) from the Julia RCall package. If we don't already have it installed in Julia, it will try to install it automatically.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Running-Julia-libraries-and-code-in-R","page":"0106-further topics","title":"Running Julia libraries and code in R","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"On each R session we need to run the julia_setup function:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"library(JuliaCall)\njulia_setup() # If we have already downloaded a private version of Julia for R it will be retrieved automatically","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"We can now load a Julia module and access the module objects directly or using the Module.evel() interface.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Add-a-Julia-package...-2","page":"0106-further topics","title":"Add a Julia package...","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"> julia_eval('using Pkg; Pkg.add(\"BetaML\")')","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"Of course we can add a package alternatively from within Julia","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"Let's load some data from R and do some work with this data in Julia:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"> library(datasets)\n> X <- as.matrix(sapply(iris[,1:4], as.numeric))\n> y <- sapply(iris[,5], as.integer)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Calling-of-Julia-functions-with-julia_call...","page":"0106-further topics","title":"Calling of Julia functions with julia_call...","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"With JuliaCall, differently than PyJulia, we can't call direclty the julia functions but we need to employ the R function julia_call(\"juliaFunction\",args):","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"> julia_eval(\"using BetaML\")\n> yencoded <- julia_call(\"integerEncoder\",y)\n> ids      <- julia_call(\"shuffle\",1:length(y))\n> Xs       <- X[ids,]\n> ys       <- yencoded[ids]\n> cOut     <- julia_call(\"kmeans\",Xs,3L)    # kmeans expects K to be an integer\n> y_hat    <- sapply(cOut[1],as.integer)[,] # We need a vector, not a matrix\n> acc      <- julia_call(\"accuracy\",y_hat,ys)\n> acc\n[1] 0.8933333","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Access-using-the-eval()-interface...-2","page":"0106-further topics","title":"Access using the eval() interface...","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"As alternative, we can embed Julia code directly in R using the julia_eval() function:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"> kMeansR  <- julia_eval('\n+      function accFromKmeans(x,k,y_true)\n+        cOut = kmeans(x,Int(k))\n+        acc = accuracy(cOut[1],y_true)\n+        return acc\n+      end\n+ ')","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"We can then call the above function in R in one of the following three ways:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"kMeansR(Xs,3,ys)\njulia_assign(\"Xs_julia\", Xs); julia_assign(\"ys_julia\", ys); julia_eval(\"accFromKmeans(Xs_julia,3,ys_julia)\")\njulia_call(\"accFromKmeans\",Xs,3,ys).","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"While other \"convenience\" functions are provided by the package, using  julia_call or julia_assign followed by julia_eval should suffix to accomplish most of the task we may need in Julia.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Some-performance-tips","page":"0106-further topics","title":"Some performance tips","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Type-stability","page":"0106-further topics","title":"Type stability","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"\"Type stable\" functions guarantee to the compiler that given a certain method (i.e. with the arguments being of a given type) the object returned by the function is also of a certain fixed type. Type stability is fundamental to allow type inference continue across the function call stack.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"function f1(x)    # Type unstable\n    outVector = [1,2.0,\"2\"]\n    if x < 0\n        return outVector[1]\n    elseif x == 0\n        return outVector[2]\n    else\n        return outVector[3]\n    end\nend\n\nfunction f2(x)   # Type stable\n    outVector = [1,convert(Int64,2.0),parse(Int64,\"2\")]\n    if x < 0\n        return outVector[1]\n    elseif x == 0\n        return outVector[2]\n    else\n        return outVector[3]\n    end\nend\n\na = f1(0)\nb = f1(1)\ntypeof(a)\ntypeof(b)\n\nc = f2(0)\nd = f2(1)\ntypeof(c)\ntypeof(d)\n\nusing BenchmarkTools\n@btime f1(0) # 661 ns 6 allocations\n@btime f2(0) #  55 ns 1 allocations\n\n@code_warntype f1(0) # Body::Any\n@code_warntype f2(0) # Body::Int64","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"While in general is NOT important to annotate function parameters for performance, it is important to annotate struct fields with concrete types","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"abstract type Goo end\nstruct Foo <: Goo\n    x::Number\nend\nstruct Boo <: Goo\n    x::Int64\nend\n\nfunction f1(o::Goo)\n    return o.x +2\nend\n\nfobj = Foo(1)\nbobj = Boo(1)\n@btime f1($fobj) # 17.1 ns 0 allocations\n@btime f1($bobj) #  2.8 ns 0 allocations","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"Here the same function under some argument types is type stable, under other argument types is not","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"@code_warntype f1(fobj)\n@code_warntype f1(bobj)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Avoid-(non-constant)-global-variables","page":"0106-further topics","title":"Avoid (non-constant) global variables","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"g        = 2\nconst cg = 1   # we can't change the _type_ of the object binded to a constant variable\ncg       = 2   # we can rebind to an other object of the same type, but we get a warning\n# cg    = 2.5 # this would error !\nf1(x,y) = x+y\nf2(x)   = x + g\nf3(x)   = x + cg\n\n@btime f1(3,2)\n@btime f2(3)    # 22 times slower !!!\n@btime f3(3)    # as f1","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Loop-arrays-with-the-inner-loop-by-rows","page":"0106-further topics","title":"Loop arrays with the inner loop by rows","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"Julia is column mayor (differently than Python) so arrays of bits types are contiguous in memory across the different rows of the same column","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"a = rand(1000,1000)\nfunction f1(x)\n    (R,C) = size(x)\n    cum = 0.0\n    for r in 1:R\n        for c in 1:C\n            cum += x[r,c]\n        end\n    end\n    return cum\nend\nfunction f2(x)\n    (R,C) = size(x)\n    cum = 0.0\n    for c in 1:C\n        for r in 1:R\n            cum += x[r,c]\n        end\n    end\n    return cum\nend\n@btime f1($a) # 2.3 ms 0 allocations\n@btime f2($a) # 1.3 ms 0 allocations","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Use-low-level-optimisation-when-possible","page":"0106-further topics","title":"Use low-level optimisation when possible","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"function f1(x)\n    s = 0.0\n    for i in 1:length(x)\n        s += i * x[i]\n    end\n    return s\nend\n\nfunction f2(x)\n    s = 0.0\n    for i in 1:length(x)\n        @inbounds s += i * x[i] # remove bound checks\n    end\n    return s\nend\n\nfunction f3(x)\n    s = 0.0\n    @simd for i in 1:length(x) # tell compiler it is allowed to run the loop in whatever order, allowing in-thread paralllelism of modern CPUs\n        s += i * x[i]\n    end\n    return s\nend\n\nx = rand(10000)\n@btime f1($x)\n@btime f2($x)\n@btime f3($x)\n\nX = rand(100,20)\nfunction f1(x)\n    s = 0.0\n    for i in 1:size(x,1)\n        s += sum(x[i,:])\n    end\n    return s\nend\nfunction f2(x)\n    s = 0.0\n    @views for i in 1:size(x,1)\n        s += sum(x[i,:])   # the slice operator copy the data.. the views macro force to have instead to have a view (reference)\n    end\n    return s\nend\n\n@btime f1($X)\n@btime f2($X)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"warning: Warning\nAttention that while the @views macro \"save time\" by not copying the data, the resulting array has a pretty messy layout. If you need to use it for many subsequent operations it may be more efficient to \"pay\" the copy cost once and then have an array with a nicelly continuous block of memory..","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"function f1(x,y)\n    if x+y > 100\n        return x + y + 2\n    else\n        return x + 1\n    end\nend\n\n@inline function f2(x,y)   # the function is \"inlined\", its whole definition copied at each calling place rather than being called\n    if x+y > 100\n        return x + y + 2\n    else\n        return x + 1\n    end\nend\n\nfunction f3(y)\n    s = 0.0\n    for i in 2:y\n       s += f1(i,i-1)\n       s += f1(i,i)\n    end\n    return s\n end\n\nfunction f4(y)\n    s = 0.0\n    for i in 2:y\n       s += f2(i,i-1)\n       s += f2(i,i)\n    end\n    return s\nend\n\nx = 1000\n@btime f3($x)\n@btime f4($x)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"But attention! Not always a ggood idea:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"function f3(y)\n    s = 0.0\n    for i in 2:y\n       s += sum(f1(a,a-1) for a in 2:i)\n    end\n    return s\n end\n\nfunction f4(y)\n    s = 0.0\n    for i in 2:y\n       s += sum(f2(a,a-1) for a in 2:i)\n    end\n    return s\nend\n\nx = 1000\n@btime f3($x)\n@btime f4($x)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"Note that the Julia compiles already inline small functions automatically when it thinks it will improve performances","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Profiling-the-code-to-discover-bootlenecks","page":"0106-further topics","title":"Profiling the code to discover bootlenecks","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"We already see @btime and @benchmark from the package BenchmarkTools.jl Remember to quote the global variables used as parameter of your function with the dollar sign to have accurate benchmarking of the function execution. Julia provide the macro @time but we should run on a second call to a given function (with a certain parameter types) or it will include compilation time in its output:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"function fb(x)\n    out = Union{Int64,Float64}[1,2.0,3]\n    push!(out,4)\n    if x > 10\n        if ( x > 100)\n            return [out[1],out[2]] |>  sum\n        else\n            return [out[2],out[3]] |>  sum\n        end\n    else\n        return [out[1],out[3]] |>  sum\n    end\nend\n\n\n@time fb(3)\n@time fb(3)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"We can use @profile function(x,y) to use a sample-based profiling","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"using Profile # in the stdlib\nfunction foo(n)\n    a = rand(n,n)\n    b = a + a\n    c = b * b\n    return c\nend\n@profile (for i = 1:100; foo(1000); end) # too fast otherwise\nProfile.print() # on my pc: 243 rand, 174 the sum, 439 the matrix product\nProfile.clear()","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Introspection-and-debugging","page":"0106-further topics","title":"Introspection and debugging","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"To discover problems on the code more in general we can use several introspection functions that Julia provide us (some of which we have already saw):","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"# @less rand(3)  # Show the source code of the specific method invoked - use `q` to quit\n# @edit rand(3)  # Like @loss but it opens the source code in an editor\nmethods(foo)\n@which foo(2)          # which method am I using when I call foo with an integer?\ntypeof(a)\neltype(a)\nfieldnames(Foo)\ndump(fobj)\nnames(Main, all=false) # available (e.g. exported) identifiers of a given module\nsizeof(2)              # bytes\ntypemin(Int64)\ntypemax(Int64)\nbitstring(2)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"Various low-level interpretation of an expression","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"@code_native foo(3)\n@code_llvm foo(3)\n@code_typed foo(3)\n@code_lowered foo(3)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"We can use a debugger, like e.g. the one integrated in Juno or VSCode. Graphical debuggers allow to put a breakpoint on some specific line of code, run the code in debug mode (yes, it will be slower), let the program arrive to the breakpoint and inspect the state of the system at that point of the code, including local variables. In Julia we can also change the program interactively ! Other typycal functions are running a single line, running inside a function, running until the current function return, ecc..","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Runtime-exceptions","page":"0106-further topics","title":"Runtime exceptions","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"As many (all?) languages, Julia when \"finds\" an error issues an exception, that if it is not caugth at higher level in the call stack (i.e. recognised and handled) lead to an error and return to the prompt or termination of the script (and rarely with the Julia process crashing altogether).","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"The idea is that we try some potentially dangerous code and if some error is raised in this code we catch it and handle it.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"function customIndex(vect,idx;toReturn=0)\n    try\n        vect[idx]\n    catch e\n        if isa(e,BoundsError)\n            return toReturn\n        end\n        rethrow(e)\n    end\nend\n\na = [1,2,3]\n# a[4] # Error (\"BoundsError\" to be precise)\ncustomIndex(a,4)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"Note that handling exceptions is computationally expensive, so do not use exceptions in place of conditional statements","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Parallel-computation","page":"0106-further topics","title":"Parallel computation","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"Finally one note on parallel computation. We see only some basic usage of multithreading and multiprocesses in this course, but with Julia it is relativelly easy to parallelise the code either using multiple threads or multiple processes. What's the difference ?","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"multithread\nadvantages: computationally \"cheap\" to create (the memory is shared)\ndisadvantages: limited to the number of cores within a CPU, require attention in not overwriting the same memory or doing it at the intended order (\"data race\"), we can't add threads dynamically (within a script)\nmultiprocesses\nadvantages: unlimited number, can be run in different CPUs of the same machine or differnet nodes of a cluster, even using SSH on different networks, we can add processes from within our code with addprocs(nToAdd)\ndisadvantages: the memory being copied (each process will have its own memory) are computationally expensive (you need to have a gain higher than the cost on setting a new process) and require attention to select which memory a given process will need to \"bring with it\" for its functionality","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"Note that if you are reading this document on the github pages, this script is compiled using GitHub actions where a single thread and process are available, so you will not see performance gains.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Multithreading","page":"0106-further topics","title":"Multithreading","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"warning: Warning\nIt is not possible to add threads dinamically, either we have to start Julia with the parameter -t (e.g. -t 8 or -t auto) in the command line or use the VSCode Julia externsion setting Julia: Num Threads","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"function inner(x)\n    s = 0.0\n    for i in 1:x\n        for j in 1:i\n            if j%2 == 0\n                s += j\n            else\n                s -= j\n            end\n        end\n    end\n    return s\nend\n\nfunction parentSingleThread(x,y)\n    toTest = x .+ (1:y)\n    out = zeros(length(toTest))\n    for i in 1:length(toTest)\n        out[i] = inner(toTest[i])\n    end\n    return out\nend\nfunction parentThreaded(x,y)\n    toTest = x .+ (1:y)\n    out = zeros(length(toTest))\n    Threads.@threads for i in 1:length(toTest)\n        out[i] = inner(toTest[i])\n    end\n    return out\nend\n\n\nx = 100\ny = 20\n\nstr = parentSingleThread(x,y)\nmtr = parentThreaded(x,y)\n\nstr == mtr # true\nThreads.nthreads() # 4 in my case\nThreads.threadid()\n@btime parentSingleThread(100,20) # 140 μs on my machine\n@btime parentThreaded(100,20)     #  47 μs","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Multiprocessing","page":"0106-further topics","title":"Multiprocessing","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"NOTE The code on multiprocessing is commented out (not executed, so you don't see the output) as GitHub actions (that are used to run this code and render the web pages you are reading) have problems running multi-process functions:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"using Distributed     # from the Standard Library\naddprocs(3)           # 2,3,4","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"The first process is considered a sort of \"master\" process, the other one are the \"workers\" We can add processes on other machines by providing the SSH connection details directly in the addprocs() call (Julia must be installed on that machines as well) We can alternativly start Julia directly with n worker processes using the armument -p n in the command line.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"println(\"Worker pids: \")\nfor pid in workers()  # return a vector to the pids\n    println(pid)      # 2,3,4\nend\nrmprocs(workers()[1])    #  remove process pid 2\nprintln(\"Worker pids: \")\nfor pid in workers()\n    println(pid) # 3,4 are left\nend\n@everywhere begin using Distributed end # this is needed only in GitHub action\n@everywhere println(myid()) # 4,3","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Run-heavy-tasks-in-parallel","page":"0106-further topics","title":"Run heavy tasks in parallel","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"using Distributed, BenchmarkTools\na = rand(1:35,100)\n@everywhere function fib(n)\n    if n == 0 return 0 end\n    if n == 1 return 1 end\n    return fib(n-1) + fib(n-2)\nend","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"The macro @everywhere make available the given function (or functions with @everywhere begin [shared function definitions] end or @everywhere include(\"sharedCode.jl\")) to all the current workers.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"# result  = map(fib,a)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"The pmap function (\"parallel\" map) automatically pick up the free processes, assign them the job prom the \"input\" array and merge the results in the returned array. Note that the order is preserved:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"result2 = pmap(fib,a)\nresult == result2\n@btime map(fib,$a)  # serialised:   median time: 514 ms    1 allocations\n@btime pmap(fib,$a) # parallelised: median time: 265 ms 4220 allocations # the memory of `a` need to be copied to all processes","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html#Divide-and-Conquer","page":"0106-further topics","title":"Divide and Conquer","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"Rather than having a \"heavy operation\" and being interested in the individual results, here we have a \"light\" operation and we want to aggregate the results of the various computations using some aggreagation function. We can then use @distributed (aggregationfunction) for [forConditions] macro:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"using Distributed, BenchmarkTools\nfunction f(n)   # our single-process benchmark\n  s = 0.0\n  for i = 1:n\n    s += i/2\n  end\n    return s\nend\nfunction pf(n)\n  s = @distributed (+) for i = 1:n # aggregate using sum on variable s\n        i/2                        # the last element of the for cycle is used by the aggregator\n  end\n  return s\nend\n@btime  f(10000000) # median time: 11.1 ms   0 allocations\n@btime pf(10000000) # median time:  5.7 ms 145 allocations","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"Note that also in this case the improvement is less than proportional with the number of processes we add","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"Details on parallel comutation can be found on the official documentation, including information to run nativelly Julia on GPUs or TPUs.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"View this file on Github.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0106-further_topics.html","page":"0106-further topics","title":"0106-further topics","text":"This page was generated using Literate.jl.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"EditURL = \"https://github.com/sylvaticus/SPMLJ/blob/main/lessonsSources/01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.jl\"","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"################################################################################\n###  Introduction to Scientific Programming and Machine Learning with Julia  ###\n###                                                                          ###\n### Run each script on a new clean Julia session                             ###\n### GitHub: https://github.com/sylvaticus/IntroSPMLJuliaCourse               ###\n### Licence (apply to all material of the course: scripts, videos, quizes,..)###\n### Creative Commons By Attribution (CC BY 4.0), Antonello Lobianco          ###\n################################################################################","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html#Control-Flow-and-Functions","page":"0104-control flow and functions","title":"0104 Control Flow and Functions","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html#Some-stuff-to-set-up-the-environment..","page":"0104-control flow and functions","title":"Some stuff to set-up the environment..","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"cd(@__DIR__)\nusing Pkg\nPkg.activate(\".\")","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"If using a Julia version different than 1.7 please uncomment and run the following line (reproductibility guarantee will hower be lost) Pkg.resolve() Pkg.instantiate() # run this if you didn't in Segment 01.01","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"using Random\nRandom.seed!(123)\nusing InteractiveUtils # loaded automatically when working... interactively","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html#Variables-scope","page":"0104-control flow and functions","title":"Variables scope","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"The scope of a variable is the region of code where the variable can be accessed directly (without using prefixes). Modules, functions, for and other blocks (but notably not \"if\" blocks) introduce an inner scope that hinerit from the scope where the block or function is defined (but not, for function, from the caller's scope). Variables that are defined outside any block or function are global for the module where they are defined (the Main module if outside any other module, e.g. on the REPL), the others being local. Variables defined in a for block that already exists as global behave differently depending if we are working interactively or not:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"g  = 2\ng2 = 20\nfor i in 1:2\n    l1 = g2                                       # l1: local, g2: global (read only)\n    l1 += i\n    g = i                                         # REPL/INTERACTIVE: global (from Julia 1.5), FILE MODE: local by default (with a warning `g` being already defined)\n    g += i\n    println(\"i: $i\")\n    println(\"l1: $l1\")\n    println(\"g: $g\")\n    for j in 1:2\n        l1 += j                                   # still the local in outer loop, not a new local one\n        l2 = j\n        g  += j\n        println(\"j: $j\")\n        println(\"l1 inside inner loop: $l1\")\n        println(\"l2 inside inner loop: $l2\")\n        println(\"g inside inner loop: $g\")\n    end\n    # println(\"l2 post: $l2\")                     # error: l2 not defined in this scope\n    println(\"l1 post: $l1\")\n    println(\"g post: $g\")\nend\n# println(\"l1 global $l1\")                        # error; l1 is not defined in the global scope\nprintln(\"g in global: $g\")                        # REPL/INTERACTIVE: \"7\", FILE MODE: \"2\"\n\nfunction foo(i)\n    l1 = g2                                       # l1: local, g2: global (read only)\n    l1 += i\n    g = i                                         # REPL/INTERACTIVE and FILE MODE: local by default (with a warning `g` being already defined)\n    g += i\n    println(\"i: $i\")\n    println(\"l1: $l1\")\n    println(\"g: $g\")\n    for j in 1:2\n        l1 += j                                   # still the local in outer loop, not a new local one\n        l2 = j\n        g  += j\n        println(\"j: $j\")\n        println(\"l1 inside inner loop: $l1\")\n        println(\"l2 inside inner loop: $l2\")\n        println(\"g inside inner loop: $g\")\n    end\n    # println(\"l2 post: $l2\")                     # error: l2 not defined in this scope\n    println(\"l1 post: $l1\")\n    println(\"g post: $g\")\nend\n\nprintln(\"Calling foo..\")\nfoo(10)\nprintln(\"g in global: $g\")                        # REPL/INTERACTIVE: \"7\", FILE MODE: \"2\"\n\ng = 2\ninclude(\"010401-varScopeExample.jl.txt\")            # gives a warning !","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html#Repeated-iterations:-for-and-while-loops,-List-Comprehension,-Maps","page":"0104-control flow and functions","title":"Repeated iterations: for and while loops, List Comprehension, Maps","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"for i in 1:2, j in 3:4             # j is the inner loop\n    println(\"i: $i, j: $j\")\nend\na = 1\nwhile true             # or condition, e.g. while a == 10\n    global a += 1\n    println(\"a: $a\")\n    if a == 10\n        break\n    else\n        continue\n    end\n    println(\"This is never printed\")\nend","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html#List-Comprehension","page":"0104-control flow and functions","title":"List Comprehension","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"[ i+j for i in 1:2, j in 3:4 if j >= 4]","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html#Maps","page":"0104-control flow and functions","title":"Maps","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"Apply a (possible anonymous) function to a list of arguments:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"map((name,year) -> println(\"$name is $year year old\"), [\"Marc\",\"Anna\"], [25,22])","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"warninng: Warninng\nDon't confuse the single-line arrows used in anonymous functions (->) with the double-line arrow used to define a Pair (=>)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"We can use maps to substitute values of an array based on a dictionary:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"countries = [\"US\",\"UK\",\"IT\",\"UK\",\"UK\"]\ncountryNames = Dict(\"IT\" => \"Italy\", \"UK\" => \"United Kngdom\",  \"US\"=>\"United States\")\ncountryLongNames = map(cShortName -> countryNames[cShortName], countries)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html#Conditional-statements:-if-blocks-and-ternary-operators","page":"0104-control flow and functions","title":"Conditional statements: if blocks and ternary operators","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"a = 10\n\nif a < 4                      # use `!`, `&&` and `||` for \"not\", \"and\" and  \"or\" conditions\n    println(\"a < 4\")\nelseif a < 8\n    println(\"a < 8\")\nelse\n    println(\"a is big!\")\nend\n\na = 10\n\nif a < 5\n  b = 100\nelse\n  b = 200\nend\n\nb","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"Ternary operators","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"b =  a < 5 ? 100 : 200   # ? condition : if true : if false","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"Short-circuit evaluation","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"b = 100\n(a < 5) || (b = 200)    # replace an if: the second part is executed unless the first part is already true\nb\n(a < 50) || (b = 500)   # here is never executed\nb","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"warning: Warning\nDon't confuse boolean operators && and || with their analogous & and | bitwise operators","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"a = 3\nb = 2\nbitstring(a)\nbitstring(b)\n\n##a && b     # error non boolean used in boolean context\na & b\na | b","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html#Functions","page":"0104-control flow and functions","title":"Functions","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"function foo(x)             # function definition\n    x+2\nend\nfoo(2)                      # function call\ninlineFunction(x) = x+2\nfoo2 = x -> x+2             # anonymous function (aka \"lambda function\") and assignment to the variable foo2\nfoo2(2)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"A nested function:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"function f1(x)\n    function f2(x,y)\n        x+y\n    end\n    f2(x,2)\nend\n\nf1(2)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"A recursive function:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"function fib(n)                   # This is a naive implementation. Much faster implementations of the Fibonacci numbers exist\n    if n == 0  return 0\n    elseif n == 1 return 1\n    else\n     return fib(n-1) + fib(n-2)\n    end\nend\nfib(4)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html#Function-arguments","page":"0104-control flow and functions","title":"Function arguments","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html#Positional-vs-keyword-arguments","page":"0104-control flow and functions","title":"Positional vs keyword arguments","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"f(a,b=1;c=1) = a+10b+100c  # `a` and `b` are positional arguments (`b` with a default provided), `c` is a keyword argument\nf(2)\nf(2,c=3)\n\nfoo(a, args...;c=1) = a + length(args) + sum(args) + c\nfoo(1,2,3,c=4)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"Rules for positional and keyword arguments:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"keyword arguments follow a semicolon ; in the parameters list of the function definition\na positional argument without a default can not follow a positional argument with a default provided\nthe splat operator to define variable number of arguments must be the last positional argument\nthe function call must use positional arguments by position and keyword arguments by name","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"# foo(a::String=\"aaa\",b::Int64) = \"$a \"+string(b) # error! Optional positional argument before a mandatory positional one","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html#Argument-types-and-multiple-dispatch","page":"0104-control flow and functions","title":"Argument types and multiple dispatch","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"Simple to understand the usage, complex to understand the deep implications","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"foo3(a::Int64,b::String) = a + parse(Int64,b)\nfoo3(2,\"3\")\nfoo3(a::String,b::Int64) = parse(Int64,a) + b\nfoo3(\"3\",2)\nmethods(foo3)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"Multiple dispatch allows to compile a specialised version JIT at run time, on the first call with the given parameters type We will see it again when dealing with type inheritance In general, unless we need to write specialised methods, no need to specify the type of the parameters. No influence on performances, this is automatically inferred (and the funciton compiled) based on the run-time type of the argument","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"!!! tip Functions performances tip     The most important things for performances are (1) that the function is type stable, that is, that conditional to a specific combination of the types of the parameters the function returns the same type. This is a condition necessary to have a working chain of type inference across function calls; (2) that no (non constant) global constants are used in the function and indeed all the required information for the functio ndoing its work is embedded in the function parameters","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html#Function-templates","page":"0104-control flow and functions","title":"Function templates","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"foo3(a::T,b::String) where {T<: Number} = a + parse(T,b)             # can use T in the function body\nfoo3(2,\"1\")\nfoo3(1.5,\"1.5\")\nfoo4(a::Int64,b::T where T <: Number) = a + b                        # ok not used in functio nbody\nfoo4(a::Int64,b::Array{T} where T <: Number) = a .+ fill(T,b,2)      # wil lerror, can't use T in the function body\n# foo4(2,[1,2])                                                     # run time error, T not defined","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html#*Call-by-reference*-vs.-*call-by-value*","page":"0104-control flow and functions","title":"Call by reference vs. call by value","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"How the variable used as function argument within the function body relates to the variable used in calling the function ?","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"call by value: the value of the argument is copied and the function body works on a copy of the value\ncall by reference: the function works on the same object being referenced by the caller variable and the function argument\ncall by sharing (Julia): the arguments are just new local variables that bind the same object. The effects of \"modifications\" on the local variable on the caller's one depends on the mutability property of the object as we saw in the Types and objects segment:\nimmutable objects: we can only have that the argument is rebinded to other objects. No effects on the original caller object\nmutable objects: if the argument is rebinded to an other object, no effects on the caller object. If the object is modified, the caller object (being the same object) is also modified","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"x = 10\nfoo(y) = y = 1\nfoo(x)\nx\nfoo(x) = x[1] = 10\nx = [1,2]\nfoo(x)\nx\nfoo3(x) = x = [10,20]\nfoo3(x)\nx","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"info: Info\nFunctions that modify at least one of their arguments are named, by convention, with an exclamation mark at the end of their name and the argument(s) that is (are) modified set as the first(s) argument(s)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"foo!(x) = x[1] = 10 # to follow the convention","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html#do-blocks","page":"0104-control flow and functions","title":"do blocks","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"Functions that accept an other function as their first parameter can be rewritten with the function itself defined in a do block:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"using Statistics\npool(f,x,poolSize=3) = [f(x[i:i+poolSize-1]) for i in 1:length(x)-poolSize+1] # a real case, used in neural networks as pooling layer\npool(mean,[1,2,3,4,5,6])\npool(maximum,[1,2,3,4,5,6])\npool([1,2,3,4,5]) do x      # x is a local variable within the do block. We need as many local variables as the number of parameters of the inner function\n    sum(x)/length(x)\nend","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"Using the doblock we can call the outer function and define the inner function at the same time.do` blocks are frequently used in input/output operations","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"View this file on Github.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0104-control_flow_and_functions.html","page":"0104-control flow and functions","title":"0104-control flow and functions","text":"This page was generated using Literate.jl.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html","page":"0101 - Basic syntax","title":"0101 - Basic syntax","text":"EditURL = \"https://github.com/sylvaticus/SPMLJ/blob/main/lessonsSources/01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.jl\"","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html","page":"0101 - Basic syntax","title":"0101 - Basic syntax","text":"################################################################################\n###  Introduction to Scientific Programming and Machine Learning with Julia  ###\n###                                                                          ###\n### Run each script on a new clean Julia session                             ###\n### GitHub: https://github.com/sylvaticus/IntroSPMLJuliaCourse               ###\n### Licence (apply to all material of the course: scripts, videos, quizes,..)###\n### Creative Commons By Attribution (CC BY 4.0), Antonello Lobianco          ###\n################################################################################","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html#Basic-Syntax-Elements","page":"0101 - Basic syntax","title":"0101 - Basic Syntax Elements","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html#Some-stuff-to-set-up-the-environment..","page":"0101 - Basic syntax","title":"Some stuff to set-up the environment..","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html","page":"0101 - Basic syntax","title":"0101 - Basic syntax","text":"cd(@__DIR__)\nusing Pkg\nPkg.activate(\".\")\nENV[\"PYTHON\"] = \"\"  # This will be needed in a further segment\nENV[\"R_HOME\"] = \"*\" # This wil lbe needed in a further segment","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html","page":"0101 - Basic syntax","title":"0101 - Basic syntax","text":"If using a Julia version different than 1.7 please uncomment and run the following line (reproductibility guarantee will hower be lost) Pkg.resolve()","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html","page":"0101 - Basic syntax","title":"0101 - Basic syntax","text":"Pkg.instantiate()\nusing Random\nRandom.seed!(123)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html#Comments","page":"0101 - Basic syntax","title":"Comments","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html","page":"0101 - Basic syntax","title":"0101 - Basic syntax","text":"# This is a comment\na = 1 # also this one\na = #= also this one =# 1\n#= also\n#= this =#\none\n=#","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html#Code-organisation","page":"0101 - Basic syntax","title":"Code organisation","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html","page":"0101 - Basic syntax","title":"0101 - Basic syntax","text":"# Semicolon:\na = 1\na = 1;\nfor i in 1:3\n   println(\"i is $i\")\nend # Keyword `end` to finish a block\nprintln(\"Hello world!\")\n# println(\"This would error!\")","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html#Unicode-support","page":"0101 - Basic syntax","title":"Unicode support","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html","page":"0101 - Basic syntax","title":"0101 - Basic syntax","text":"Actually you can use any fancy unicode character and modifiers in the names of variable, type, funcion..","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html","page":"0101 - Basic syntax","title":"0101 - Basic syntax","text":"using Statistics # for the `mean` function, in the Standard Library\nσ²(x) = sum( (x .- mean(x)).^2 )/length(x)\nσ²([1,2,3])\nx̄ₙ = 10\nvàlidVarNαme! = 2","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html#Broadcasting","page":"0101 - Basic syntax","title":"Broadcasting","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html","page":"0101 - Basic syntax","title":"0101 - Basic syntax","text":"10 .+ [1,2,3]\nadd2(x) = x + 2\nadd2(10)\n# add2([1,2,3]) # would return an error\nadd2.([1,2,3])  # any, including user defined functions, can be broadcasted. No need for map, for loops, etc..","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html#based-arrays","page":"0101 - Basic syntax","title":"1 based arrays","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html","page":"0101 - Basic syntax","title":"0101 - Basic syntax","text":"a = [1,2,3]\na[1]","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html","page":"0101 - Basic syntax","title":"0101 - Basic syntax","text":"joke: 0 or 1 ?\nShould array indices start at 0 or 1?  My compromise of 0.5 was rejected without, I thought, proper consideration. –Stan Kelly-Bootle","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html#Basic-Mathematic-operations","page":"0101 - Basic syntax","title":"Basic Mathematic operations","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html#All-standard-mathepatical-arithmetic-operators-(,-,*,/)-are-supported-in-the-obvious-way.","page":"0101 - Basic syntax","title":"All standard mathepatical arithmetic operators (+,-,*,/) are supported in the obvious way.","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html","page":"0101 - Basic syntax","title":"0101 - Basic syntax","text":"a = 2^4         # rise to power\nb = ℯ^2; #= or =# b = exp(2) # Exponential with base ℯ\nd = log(7.3890) # base ℯ\ne = log(10,100) # custom base\nf = 5 ÷ 2       # integer division\ne = 5 % 2       # reminder (modulo operator)\na = 2//3 + 1//3     # rational numbers\ntypeof(a)\nπ == pi         # some irrational constants\ntypeof(ℯ)\nconvert(Float64,a)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html#Quotation","page":"0101 - Basic syntax","title":"Quotation","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html","page":"0101 - Basic syntax","title":"0101 - Basic syntax","text":"a = 'k'              # single quotation mark: a single Char\nb = \"k\"              # double quotation mark: a (Unicode) String\n#c = 'hello'         # error !\nc = \"hello\"\nd = `echo hello`     # backtick: define a command to (later) run (e.g. on the OS)\ne = \"\"\"a\nmultiline\nstring\"\"\"\nprintln(c)\nprintln(e)\nusing Markdown\nf = md\"\"\"a\n**markdown**\n_string_\"\"\"","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html#Missingness-implementations","page":"0101 - Basic syntax","title":"Missingness implementations","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html","page":"0101 - Basic syntax","title":"0101 - Basic syntax","text":"a = nothing # C-style, \"software engineer's null → run-time error\nb = missing # Data scientist's null → silent propagation\nc = NaN     # Not a number → silent propagation\ntypeof(a)\ntypeof(b)\ntypeof(c)\nd = 0/0\n# a2 = mean([1,a,3]) # would error\nb2 = mean([1,b,3])\nc2 = mean([1,c,3])\nb3 = mean(skipmissing([1,b,3]))\nb == missing # propagate\nismissing(b)\nisequal(b,2)  # exception to the propagation rule, it allows comparations when one of the item may be missing\nisequal(b,missing)\nb4 = [1,missing,3]\ntypeof(b4)\neltype(b4)\nnonmissingtype(eltype(b4))","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html#Random-values","page":"0101 - Basic syntax","title":"Random values","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html","page":"0101 - Basic syntax","title":"0101 - Basic syntax","text":"rand()       # [0,1] continuous\nrand(30:40)  # [30,40] integer\nrand(30:0.01:40) # [30,40] with precision to the second digit\nusing Distributions\nrand(Exponential(10)) # We'll see Distributions more in detail in the Scientific Programming lesson\nrand(30:40,10) # A vector of 10 random numbers.\nrand(Exponential(10),10,23)\nusing Random\nmyRNG = MersenneTwister(123) # use StableRNG for a RNG guaranteed to remain stable between Julia-versions\na1 = rand(myRNG,10:1000,5)\na2 = rand(myRNG,10:1000,5)\na1 == a2\nmyRNG = MersenneTwister(123)\nb1 = rand(myRNG,10:1000,5)\nb2 = rand(myRNG,10:1000,5)\nb1 == b2\na1 == b1\na2 == b2\n\na = rand(myRNG,Exponential(10),5)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html","page":"0101 - Basic syntax","title":"0101 - Basic syntax","text":"View this file on Github.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html","page":"0101 - Basic syntax","title":"0101 - Basic syntax","text":"","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_Basic_syntax.html","page":"0101 - Basic syntax","title":"0101 - Basic syntax","text":"This page was generated using Literate.jl.","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html#Quiz-01.1-on-Modules,-packages-and-environments","page":"0006 - q01 - QUIZ modules packages environment","title":"Quiz 01.1 on Modules, packages and environments","text":"","category":"section"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"cd(@__DIR__)    \nusing Pkg      \nPkg.activate(\".\")  \n## Pkg.resolve()   \n## Pkg.instantiate()\nusing Random\nRandom.seed!(123)\nusing QuizQuestions","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html#Q1:-What-is-printed-?","page":"0006 - q01 - QUIZ modules packages environment","title":"Q1: What is printed ?","text":"","category":"section"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"Given a file foo.jl with the following code:","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"println(\"A - I am in foo.jl\")\n\nmodule Foo\n\nprintln(\"B - I am in module Foo in foo.jl\")\nexport x\n\nconst x=1\nconst y=2\nz() = println(\"C - I am in a function of module Foo\")\nend\n\nmodule Foo2\n\nprintln(\"D - I am in module Foo2 in foo.jl\")\nexport a\n\nconst a=1\nconst b=2\nc() = println(\"E - I am in a function of module Foo2\")\nend","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"Which print statements will appear after running the command include(foo.jl) ?","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"\nchoices = [ # hide\n  \"All statements from `A` to `E`\", # hide\n  \"No statements will be printed (e.g. due to an error)\", # hide\n  \"Statement `A` only\", # hide\n  \"Statements `A`, `B` and `D` only\", # hide\n  \"Statements `A`, `C` and `E` only\", # hide\n  \"Statements `B` and `D` only\", # hide\n  ]  # hide\nanswers = [2]  # hide\nmultiq(choices, answers;)  # hide\n","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"<details><summary>RESOLUTION</summary>","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"The include(foo.jl) statement will lead to an error because there are no quotes around the filename. If the quotations would have been included it would have resulted in the statements A, B and D. Statements C and E are within function definition and would occur only when functions z or c would have been called.}","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"The correct answer is:","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"\"No statements will be printed (e.g. due to an error)\"","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"</details>","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html#Q2:-Inclusion-of-a-module","page":"0006 - q01 - QUIZ modules packages environment","title":"Q2: Inclusion of a module","text":"","category":"section"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"Given a file foo.jl with the following code:","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"module Foo\n\nexport x\n\nconst x=1\nconst y=2\nz() = println(\"Hello world!\")\nend","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"and the following sequence of commands:","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"include(\"foo.jl\")         # Command 1\nx                         # Command 2\nFoo.x                     # Command 3\nusing Foo                 # Command 4\nusing .Foo                # Command 5\nx                         # Command 6\nFoo.z()                   # Command 7","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"Which statements are correct ?","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"\nchoices = [ # hide\n  \"Command 1 is wrong at it should have been `include foo` (without the .jl file extension)\", # hide\n  \"Command 2 returns the value `1`\", # hide\n  \"Command 3 returns the value `1`\", # hide\n  \"Command 4 returns an `ArgumentError: Package Foo not found in current path:`\", # hide\n  \"Command 5 returns an `ArgumentError: Package Foo not found in current path:`\", # hide\n  \"Command 6 returns the value  `1`\", # hide\n  \"Command 7 returns an `UndefVarError: z not defined`\", # hide\n  ]  # hide\nanswers = [3,4,6]  # hide\nmultiq(choices, answers;keep_order=true)  # hide\n","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"<details><summary>RESOLUTION</summary>","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"The include(\"foo.jl\") statement evaluates the included content, but it doesn't yet bring it into scope. You can't yet refer directly to the objects of the Foo module, you need to use the qualified name as in command 3. Foo is a module, not a package, so command 4 will complain that it doesn't find the \"package\" Foo. After the module has been bring to scope we can refer to x directly as in command 6. Command 7, as we are using the qualified name, is indipenden than whether z was exported by Foo or not, and hence it works, and would have been worked even without the using .Foo of command 5.","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"The correct answers are:","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"\"Command 3 returns the value 1\"\n\"Command 4 returns an ArgumentError: Package Foo not found in current path:\"\n\"Command 6 returns the value  1\"","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"</details>","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html#Q3:-Submodules","page":"0006 - q01 - QUIZ modules packages environment","title":"Q3: Submodules","text":"","category":"section"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"Given a file Foo.jl with the following code:","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"module Foo\nexport x, plusOne\nx = 1\nplusOne(x) = x + 1\nmodule Foo2\n  export plusTwo\n  plusTwo(x) = plusOne(x)+1\nend\nend","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"After including the file we try to run the command Foo.Foo2.plusTwo(10). Which of the following statements is correct ?","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"\nchoices = [ # hide\n  \"The result is 12\", # hide\n  \"The result is 3\", # hide\n  \"The result is an error that we can avoid if we run instead the command `Main.Foo.Foo2.plusTwo(10)`\", # hide\n  \"The result is an error that we can avoid if we type `using Foo` before that command\", # hide\n  \"The result is an error that we can avoid if we type `using .Foo` before that command\", # hide\n  \"The result is an error that we can avoid if the function `plusTwo` in module `Foo2` is defined as `plusTwo(x) = Foo.plusOne(x)+1`\", # hide\n  \"The result is an error that we can avoid if the function `plusTwo` in module `Foo2` is defined as `plusTwo(x) = Main.Foo.plusOne(x)+1`\", # hide\n  \"The result is an error that we can avoid if the function `plusTwo` in module `Foo2` is defined as `plusTwo(x) = ..Foo.plusOne(x)+1`\", # hide\n  \"The result is an error that we can avoid if in module `Foo2` the function `plusTwo` is preceded by the statement `using Foo`\", # hide\n  \"The result is an error that we can avoid if in module `Foo2` the function `plusTwo` is preceded by the statement `using .Foo`\", # hide\n  \" The result is an error that we can avoid if in module `Foo2` the function `plusTwo` is preceded by the statement `using ..Foo`\", # hide\n  ]  # hide\nanswers = [7,11]  # hide\nmultiq(choices, answers;)  # hide\n","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"<details><summary>RESOLUTION</summary>","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"The given command results in a UndefVarError: plusOne not defined. Indeed even if Foo2 is a submodule of Foo, it doesn't inherit the scope of parent modules. So its code can't find the 'plusOne' function.  When in the REPL we run the command we are in the Main module. Adding using .Foo doesn't change anything, as the problem is in the scope of the Foo2 module, not in those of the REPL (Main - and , of course, typing using Foo looks-up for the package Foo, not the module Foo, and would end in a Package Foo not found error. So what can we do? One solution is using in the plusTwo function the full path of the plusOne function:  plusTwo(x) = Main.Foo.plusOne(x)+1. While this works, it may be a less portable solution, as it then requires module Foo to be a child of Main. Perhaps a better solution is to use a relative path and use the statement using ..Foo in module Foo2 before the definition of plusTwo (trying to use a relative path directly in the function definition as in plusTwo(x) = ..Foo.plusOne(x)+1 results in a parsing error)","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"The correct answers are:","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"The result is an error that we can avoid if the function plusTwo in module Foo2 is defined as plusTwo(x) = Main.Foo.plusOne(x)+1\nThe result is an error that we can avoid if in module Foo2 the function plusTwo is preceded by the statement using ..Foo","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"</details>","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html#Q4:-Submodules2","page":"0006 - q01 - QUIZ modules packages environment","title":"Q4: Submodules2","text":"","category":"section"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"Given a module Foo with the following code:","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"module Foo\nexport x\nx = 1\nmodule Foo2\n  export plusTwo\n  plusTwo(x) = x+2\nend\nmodule Foo3\n  export plusThree\n  [XXXX]\n  plusThree(x) = plusTwo(x)+1\n  end                  \nend","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"Which of the following statements are correct ?","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"\nchoices = [ # hide\n  \"`[XXXX]` should be `using Main.Foo.Foo2` for the function `plusThree` to work\", # hide\n  \"`[XXXX]` should be `using Foo2` for the function `plusThree` to work\", # hide\n  \"`[XXXX]` should be `using .Foo2` for the function `plusThree` to work\", # hide\n  \"`[XXXX]` should be `using ..Foo2` for the function `plusThree` to work\", # hide\n  \"`[XXXX]` should be `import Main.Foo.Foo2` for the function `plusThree` to work\", # hide\n  \"`[XXXX]` should be `import Foo2` for the function `plusThree` to work\", # hide\n  \"`[XXXX]` should be `import .Foo2` for the function `plusThree` to work\", # hide\n  \"`[XXXX]` should be `import ..Foo2` for the function `plusThree` to work\", # hide\n  ]  # hide\nanswers = [1,4]  # hide\nmultiq(choices, answers;)  # hide\n","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"<details><summary>RESOLUTION</summary>","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"The function plusTwo needs to access a function on a sibling module. So the module Foo2 must be retrieved by going up to one level with the two dots and then naming the module, i.e. using ..Foo2 or using the full module path using Main.Foo.Foo2. import statemens alone will not work as the plusThree function call the plusTwo function using the unqualified name, without prefixing the module, so the plusThree function name need to be exported.","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"The correct answers are:","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"\"[XXXX] should be using Main.Foo.Foo2 for the function plusThree to work\"\n\"[XXXX] should be using ..Foo2 for the function plusThree to work\"","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"</details>","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html#Q5:-Reproducibility","page":"0006 - q01 - QUIZ modules packages environment","title":"Q5: Reproducibility","text":"","category":"section"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"Which elements do you have to provide to others to guarantee reproducibility of your results obtained with a Julia project?","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"\nchoices = [ # hide\n  \"The input data of your analysis\", # hide\n  \"The full source code of the scripts you have used\", # hide\n  \"The content of the Julia user folder on the machine your code ran to produce the results (e.g. `/home/[username]/.julia` in Linux)\", # hide\n  \"The file `Manifest.toml` of the environment where your code ran to produce the results\", # hide\n  \"The file `Project.toml` of the environment where your code ran to produce the results\", # hide\n  ]  # hide\nanswers = [1,2,4]  # hide\nmultiq(choices, answers;)  # hide\n","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"<details><summary>RESOLUTION</summary>","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"To provide replicable results, assuming a deterministic algorithm or one where the random seed generator has been fixed, we need to provide the input data, the source code and the 'Manifest.toml' file that describe the exact version of all packages. The Project.toml file instead, when present, is used to describe in which conditions our scripts could be used (i.e. the list and eventually range of dependent packages), but not a unique environment state. The information of the Manifest.toml (and, for Julia versions before 1.7, the Julia version itself, as this info was not encoded in the Manifest.toml file) is enougth, we don't need to provide the whole content of the user Julia folder.","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"The correct answers are:","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"\"The input data of your analysis\"\n\"The full source code of the scripts you have used\"\n\"The file Manifest.toml of the environment where your code ran to produce the results\"","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0006_-_q01_-_QUIZ_modules_packages_environment.html","page":"0006 - q01 - QUIZ modules packages environment","title":"0006 - q01 - QUIZ modules packages environment","text":"</details>","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"EditURL = \"https://github.com/sylvaticus/SPMLJ/blob/main/lessonsSources/02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.jl\"","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"################################################################################\n###  Introduction to Scientific Programming and Machine Learning with Julia  ###\n###                                                                          ###\n### Run each script on a new clean Julia session                             ###\n### GitHub: https://github.com/sylvaticus/IntroSPMLJuliaCourse               ###\n### Licence (apply to all material of the course: scripts, videos, quizes,..)###\n### Creative Commons By Attribution (CC BY 4.0), Antonello Lobianco          ###\n################################################################################","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#Data-Wrangling","page":"0201-wrangling data","title":"0201 - Data Wrangling","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#Some-stuff-to-set-up-the-environment..","page":"0201-wrangling data","title":"Some stuff to set-up the environment..","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"cd(@__DIR__)\nusing Pkg\nPkg.activate(\".\")","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"If using a Julia version different than 1.7 please uncomment and run the following line (reproductibility guarantee will hower be lost) Pkg.resolve()","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"Pkg.instantiate()\nusing Random\nRandom.seed!(123)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#Introduction","page":"0201-wrangling data","title":"Introduction","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"This segment will be mostly based on DataFrames and related packages","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"!!! info DataFrames vs Matrix     DataFrames are popular format for in-memory tabular data. Their main advantages over Arrays are that they can efficiently store different types of data on each column (indeed each column is a wrapper over an Array{T,1} where T is specific to each column) and, thanks also to their named columns, provide convenient API for data operations, like indexing, querying , joining, split-apply-combine, etc.","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"info: Info\nIn most circunstances we can refer to dataframe columns either by using their name as a string, e.g. \"Region\", or as symbol, e.g. :Region. In the rest of the segment we will use the strings approach.","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#Data-import","page":"0201-wrangling data","title":"Data import","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"Our example: Forest volumes and area by country and year Source: Eurostat; units: forarea: Milion hectars, forvol: Milion cubic metres","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#Built-in-solution:-CSV-–-Matrix","page":"0201-wrangling data","title":"Built-in solution: CSV –> Matrix","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"using DelimitedFiles  # in the stdlib\ndata = convert(Array{Float64,2},readdlm(\"data.csv\",';')[2:end,3:end]) # Skip the first 1 row and the first 2 columns - out is a Matrix","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#CSV.jl:-{CSV-file,-hardwritten-data}-–-DataFrame","page":"0201-wrangling data","title":"CSV.jl: {CSV file, hardwritten data} –> DataFrame","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"using CSV, DataFrames\ndata = CSV.read(\"data.csv\",DataFrame) # source, sink, kword options\ndata = CSV.read(\"data.csv\",NamedTuple)\n\ndata = CSV.read(IOBuffer(\"\"\"\nCountry\tYear\tforarea\tforvol\nGermany\t2000\t11.354\t3381\nFrance\t2000\t15.288\t2254.28\nItaly\t2000\t8.36925\t1058.71\nSweden\t2000\t28.163\t3184.67\nGermany\t2020\t11.419\t3663\nFrance\t2020\t17.253\t3055.83\nItaly\t2020\t9.56613\t1424.4\nSweden\t2020\t27.98\t3653.91\n\"\"\"), DataFrame, copycols=true)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"Some common CSV.jl options: delim (use '\\t' for tab delimited files), quotechar, openquotechar, closequotechar, escapechar, missingstring, dateformat, append, writeheader, header, newline, quotestrings, decimal, header, normalizenames, datarow, skipto, footerskip, limit, transpose, comment, use_mmap, type, types (e.g. types=Dict(\"fieldFoo\" => Union{Missing,Int64})), typemap, pool, categorical, strict, silencewarnings, ignorerepeated","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#XLSX.jl:-xlsx-{Matrix,-DataFrame}","page":"0201-wrangling data","title":"XLSX.jl: xlsx -> {Matrix, DataFrame}","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"using XLSX\nsheetNames = XLSX.sheetnames(XLSX.readxlsx(\"data.xlsx\"))\ndata = XLSX.readxlsx(\"data.xlsx\")[\"Sheet1\"][\"A1:D9\"]\ndata = XLSX.readxlsx(\"data.xlsx\")[\"Sheet1\"][:]\ndata = XLSX.readdata(\"data.xlsx\", \"Sheet1\", \"A1:D9\")\nXLSX.readtable(\"data.xlsx\", \"Sheet1\") # tuple vector of (data) vectors, vector of symbols, usable as DF constructor\ndata = DataFrame(XLSX.readtable(\"data.xlsx\", \"Sheet1\")...)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#OdsIO.jl:-ods-{Matrix,-DataFrame}","page":"0201-wrangling data","title":"OdsIO.jl: ods -> {Matrix, DataFrame}","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"using OdsIO\nods_read(\"data.ods\";sheetName=\"Sheet1\",retType=\"DataFrame\")\nods_read(\"data.ods\";sheetName=\"Sheet1\",retType=\"Matrix\",range=[(2,3),(9,4)]) # [(tlr,tlc),(brr,brc)]","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#HTTP.jl:-from-internet","page":"0201-wrangling data","title":"HTTP.jl: from internet","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"import HTTP\nusing Pipe, ZipFile, Tar\nurlData = \"https://github.com/sylvaticus/IntroSPMLJuliaCourse/raw/main/lessonsSources/02_-_JULIA2_-_Scientific_programming_with_Julia/data.csv\"\nurlDataZ = \"https://github.com/sylvaticus/IntroSPMLJuliaCourse/raw/main/lessonsSources/02_-_JULIA2_-_Scientific_programming_with_Julia/data.zip\"\n\n\ndata = @pipe HTTP.get(urlData).body        |>\n             replace!(_, UInt8(';') => UInt8(' ')) |>  # if we need to do modifications to the file before importing\n             CSV.File(_, delim=' ')                |>\n             DataFrame;\nnothing #hide","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#ZipFile.jl-:-from-a-single-zipped-csv-file..","page":"0201-wrangling data","title":"ZipFile.jl : from a single zipped csv file..","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"...on disk...","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"data = @pipe ZipFile.Reader(\"data.zip\").files[1] |>\n             CSV.File(read(_), delim=';') |>\n             DataFrame","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"...or on internet:","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"data = @pipe HTTP.get(urlDataZ).body       |>\n             IOBuffer(_)                      |>\n             ZipFile.Reader(_).files[1]    |>\n             CSV.File(read(_), delim=';')  |>\n             DataFrame","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#DataFrame-constructor","page":"0201-wrangling data","title":"DataFrame constructor","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"# named tuple of (colName,colData)..\ndata = DataFrame(\n    country = [\"Germany\", \"France\", \"Italy\", \"Sweden\", \"Germany\", \"France\", \"Italy\", \"Sweden\"],\n    year    = [2000,2000,2000,2000,2020,2020,2020,2020],\n    forarea = [11.354, 15.288, 8.36925, 28.163, 11.419, 17.253, 9.56613, 27.98],\n    forvol  = [3381, 2254.28, 1058.71, 3184.67, 3663, 3055.83, 1424.4, 3653.91]\n)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#Matrix-DataFrame","page":"0201-wrangling data","title":"Matrix -> DataFrame","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"Headers and data separated:","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"M = [\"Germany\"\t2000\t11.354\t3381\n     \"France\"\t2000\t15.288\t2254.28\n     \"Italy\"\t2000\t8.36925\t1058.71\n     \"Sweden\"\t2000\t28.163\t3184.67\n     \"Germany\"\t2020\t11.419\t3663\n     \"France\"\t2020\t17.253\t3055.83\n     \"Italy\"\t2020\t9.56613\t1424.4\n     \"Sweden\"\t2020\t27.98\t3653.91]\nheaders = [\"Country\", \"Year\", \"forarea\", \"forvol\"]\n# array of colData arrays, array of headers\ndata = DataFrame([[M[:,i]...] for i in 1:size(M,2)], Symbol.(headers))","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"Headers on the first row of the matrix:","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"M = [\"Country\"\t\"Year\"\t\"forarea\" \"forvol\"\n     \"Germany\"\t2000\t11.354\t  3381\n     \"France\"\t2000\t15.288\t  2254.28\n     \"Italy\"\t2000\t8.36925\t  1058.71\n     \"Sweden\"\t2000\t28.163\t  3184.67\n     \"Germany\"\t2020\t11.419\t  3663\n     \"France\"\t2020\t17.253\t  3055.83\n     \"Italy\"\t2020\t9.56613\t  1424.4\n     \"Sweden\"\t2020\t27.98\t  3653.91]\ndata = DataFrame([[M[2:end,i]...] for i in 1:size(M,2)], Symbol.(M[1,:])) # note the autorecognision of col types","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#Getting-insights-on-the-data","page":"0201-wrangling data","title":"Getting insights on the data","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"In VSCode, we can also use the workpanel for a nice sortable tabular view of a df","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"show(data,allrows=true,allcols=true)\nfirst(data,6)\nlast(data, 6)\ndescribe(data)\nnR,nC = size(data)\nnames(data)\nfor r in eachrow(data)\n    println(r) # note is it a \"DataFrameRow\"\nend\nfor c in eachcol(data)\n    println(c) # an array\n    println(nonmissingtype(eltype(c)))\nend","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#Selection-and-querying-data","page":"0201-wrangling data","title":"Selection and querying data","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#Column(s)-selection","page":"0201-wrangling data","title":"Column(s) selection","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"In general we can select: (a) by name (strings or symbols) or by position; (b) a single or a vector of columns, (c) copying or making a view (a reference without copying) of the underlying data","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"data[:,[\"Country\",\"Year\"]] # copy, using strings\ndata[!,[:Country,:Year]]   # view, using symbols\ndata.Year                  # equiv. to `data[!,Year]`\ndata[:,1]                  # also `data[!,1]`\ndata[:,Not([\"Year\"])]","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#Row(s)-selection","page":"0201-wrangling data","title":"Row(s) selection","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"data[1,:]    # DataFrameRow\ndata[1:3,:]  # DataFrame","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"Note rows have no title names as colums do.","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#Cell(s)-selection","page":"0201-wrangling data","title":"Cell(s) selection","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"data[2,[2,4]]\ndata[2,\"forarea\"]","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"Note that the returned selection is:","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"an Array{T,1} if it is a single column;\na DataFrameRow (similar in behaviour to a DataFrame) if a single row;\nT if a single cell;\nan other DataFrame otherwise.","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#Boolean-selection","page":"0201-wrangling data","title":"Boolean selection","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"Both rows and column of a DataFrame (but also of an Matrix) can be selected by passing an array of booleans as column or row mask (and, only for Matrices, also a matrix of booleans)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"mask = [false, false, false, false, true, true, true, true]\ndata[mask,:]\nmask = fill(false,nR,nC)\nmask[2:end,2:3] .= true\nmask\n# data[mask] # error !\nMatrix(data)[mask]","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"Boolean selection can be used to filter on conditions, e.g.:","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"data[data.Year .>= 2020,:]\ndata[[i in [\"France\", \"Italy\"] for i in data.Country] .&& (data.Year .== 2000),:] # note the parhenthesis","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#Filtering-using-the-@subset-macro-from-the-DataFramesMacro-package","page":"0201-wrangling data","title":"Filtering using the @subset macro from the DataFramesMacro package","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"using DataFramesMeta\n@subset(data, :Year .> 2010 )\ncolToFilter = :Country\n@subset(data, :Year .> 2010, cols(colToFilter) .== \"France\" ) # Conditions are \"end\" by default. If the column name is embedded in a varaible we eed to use `cols(varname)`","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#Filtering-using-the-Query-package","page":"0201-wrangling data","title":"Filtering using the Query package","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"using Query\ndfOut = @from i in data begin # `i` is a single row\n    @where i.Country == \"France\" .&& i.Year >= 2000\n    # Select a group of columns, eventually changing their name:\n    @select {i.Year, FranceForArea=i.forarea} # or just `i` for the whole row\n    @collect DataFrame\nend","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"long but flexible","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#Managing-missing-values","page":"0201-wrangling data","title":"Managing missing values","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"tip: Tip\nSee also the section Missingness implementations for a general discussion on missing values","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"df = copy(data)\n# df[3,\"forarea\"]  = missing # Error, type is Flat64, not Union{Float64,Missing}\ndf.forarea = allowmissing(df.forarea) # also disallowmissing\nallowmissing!(df)\ndf[3,\"forarea\"]  = missing\ndf[6,\"forarea\"]  = missing\ndf[6,\"Country\"]  = missing\nnMissings        = length(findall(x -> ismissing(x), df.forarea)) # Count `missing` values in a column.\ndropmissing(df)\ndropmissing(df[:,[\"forarea\",\"forvol\"]])\ncollect(skipmissing(df.forarea))\ncompletecases(df)\ncompletecases(df[!,[\"forarea\",\"forvol\"]])\n[df[ismissing.(df[!,col]), col] .= 0 for col in names(df) if nonmissingtype(eltype(df[!,col])) <: Number] # Replace `missing` with `0` values in all numeric columns, like `Float64` and `Int64`;\n[df[ismissing.(df[!,col]), col] .= \"\" for col in names(df) if nonmissingtype(eltype(df[!,col])) <: AbstractString] # Replace `missing` with `\"\"` values in all string columns;\ndf","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#Editing-data","page":"0201-wrangling data","title":"Editing data","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"df = copy(data)\ndf[1,\"forarea\"] = 11.3\ndf[[2,4],\"forarea\"] .= 10\ndf\npush!(df,[\"UK\",2020,5.0,800.0]) # add row\nsort!(df,[\"Country\",\"Year\"], rev=false)\ndf2 = similar(df) # rubish inside\ndf = similar(df,0) # empty a dataframe. The second parameter is the number of rows desired","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#Work-on-dataframe-structure","page":"0201-wrangling data","title":"Work on dataframe structure","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"df       = copy(data)\ndf.foo   = [1,2,3,4,5,6,7,8] # existing or new column\ndf.volHa = data.forvol ./ data.forarea\ndf.goo   = Array{Union{Missing,Float64},1}(missing,size(data,1))\nselect!(df,Not([\"foo\",\"volHa\",\"goo\"])) # remove  cols by name\nrename!(df, [\"Country2\", \"Year2\", \"forarea2\", \"forvol2\"])\nrename!(df, Dict(\"Country2\" => \"Country\"))\ndf       = df[:,[\"Year2\", \"Country\",\"forarea2\",\"forvol2\"] ] #  change column order\ninsertcols!(df, 2, :foo => [1,2,3,4,5,6,7,8] ) # insert a column at position 2\n\ndf.namedYear = map(string,df.Year2)\nstringToInt(str) = try parse(Int64, str) catch; return(missing) end; df.Year3 = map(stringToInt, df.namedYear)\n\ndf2 = hcat(df,data,makeunique=true)\ndf3 = copy(data)\ndf4 = vcat(data,df3)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#Categorical-data","page":"0201-wrangling data","title":"Categorical data","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"using CategoricalArrays # You may want to consider also PooledArrays\ndf.Year2 = categorical(df.Year2)\ntransform!(df, names(df, AbstractString) .=> categorical, renamecols=false) # transform to categorical all string columns","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"warning: Warning\nAttention that while the memory to store the data decreases, and grouping is way more efficient, filtering with categorical values is not necessarily quicker (indeed it can be a bit slower)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"levels(df.Year2)\nlevels!(df.Country,[\"Sweden\",\"Germany\",\"France\",\"Italy\"]) # Let you define a personalised order, useful for ordered data\nsort(df.Country)\nsort!(df,\"Country\")\ndf.Years2 = unwrap.(df.Year2) # convert a categorical array into a normal one.","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#Joining-dataframes","page":"0201-wrangling data","title":"Joining dataframes","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"df1,df2 = copy(data),copy(data)\npush!(df1,[\"US\",2020,5.0,1000.0])\npush!(df2,[\"China\",2020,50.0,1000.0])\nrename!(df2,\"Year\"=>\"year\")\ninnerjoin(df1,df2,on=[\"Country\",\"Year\"=>\"year\"],makeunique=true) # common records only","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"Also available: leftjoin (all records on left df), rightjoin (all on right df), outerjoin(all records returned), semijoin (like inner join by only with columns from the right df), antijoin (left not on right df) and crossjoin (like the cartesian product, each on the right by each on the left)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#Pivoting-data","page":"0201-wrangling data","title":"Pivoting data","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"long and wide are two kind of layout for equivalent representation of tabled data. In a long layout we have each row being an observation of a single variable, and each record is represented as dim1, dim2, ..., value. As the name implies, \"long\" layouts tend to be relativelly long and hard to analyse by an human, but are very easity to handle. At the opposite, A wide layout represents multiple observations on the same row, eventually using multiple horizontal axis as in the next figure (but Julia dataframes handle only a single horizzontal axis):","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"    \n Forest Area  Forest Volumes \n 2000 2020 2000 2020\nGermany 11.35 11.42 3381 3663\nFrance 15.29 17.25 2254 3056","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"_wide layout is easier to visually analise for a human mind but much more hard to analyse in a sistermatic way. We will learn now how to move from one type of layout to the other.","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#Stacking-columns:-from-*wide*-to-*long*","page":"0201-wrangling data","title":"Stacking columns: from wide to long","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"longDf  = stack(data,[\"forarea\",\"forvol\"])    # we specify the variable to stack (the \"measured\" variables)\nlongDf2 = stack(data,Not([\"Country\",\"Year\"])) # we specify the variables _not_ to stack (the id variables)\nlongDf3 = stack(data)                         # automatically stack all numerical variables\nlongDf == longDf2 == longDf3","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"Note how the columns variable and value have been added automatically to host the stachked data","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#Unstacking-columns:-from-*wide*-to-*long*","page":"0201-wrangling data","title":"Unstacking columns: from wide to long","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"wideDf = unstack(longDf,[\"Country\",\"Year\"],\"variable\",\"value\") # args: df, [cols to remains cols also in the wide layout], column with the ids to expand horizontally and column with the relative values\nwideDf2 = unstack(longDf,\"variable\",\"value\") # cols to remains cols also in the wide layout omitted: all cols not to expand and relative value col remains as col\nwideDf == wideDf2 == data","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"While the DataFrames package doesn't support multiple axis we can still arrive to the table below with a little bit of work by unstacking different columns in separate wide dataframes and then joining or horizontally concatenating them:","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"wideArea = unstack(data,\"Country\",\"Year\",\"forarea\")\nwideVols = unstack(data,\"Country\",\"Year\",\"forvol\")\nrename!(wideArea,[\"Country\",\"area_2000\",\"area_2020\"])\nrename!(wideVols,[\"Country\",\"vol_2000\",\"vol_2020\"])\nwideWideDf = outerjoin(wideArea,wideVols,on=\"Country\")","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#The-Split-Apply-Combine-strategy","page":"0201-wrangling data","title":"The Split-Apply-Combine strategy","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"Aka \"divide and conquer\". Rather than try to modify the dataset direclty, we first split it in subparts, we work on each subpart and then we recombine them in a target dataset","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"using Statistics # for `mean`\ngroupby(data,[\"Country\",\"Year\"]) # The \"split\" part","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"Aggregation:","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"combine(groupby(data,[\"Year\"]) ,  \"forarea\" => sum => \"sum_area\", \"forvol\" => sum => \"sum_vol\", nrow)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"...or...","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"combine(groupby(data,[\"Year\"])) do subdf # slower\n    (sumarea = sum(subdf.forarea), sumvol = sum(subdf.forvol), nCountries = size(subdf,1))\nend","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"Cumulative computation:","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"a = combine(groupby(data,[\"Year\"])) do subdf # slower\n    (country = subdf.Country, area = subdf.forarea, cumArea = cumsum(subdf.forarea))\nend","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"Note in these examples that while in the aggregation we was returning a single record for each subgroup (hence we did some dimensionality reduction) in the cumulative compuation we still output the whole subgroup, so the combined dataframe in output has the same number of rows as the original dataframe.","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"An alternative approach is to use the @linq macro from the DatAFrameMEta package that provide a R's dplyr-like query language using piped data:","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"using DataFramesMeta\ndfCum = @linq data |>\n            groupby([:Year]) |>\n            transform(:cumArea = cumsum(:forarea))","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#Export-and-saving","page":"0201-wrangling data","title":"Export and saving","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#DataFrame-to-Matrix","page":"0201-wrangling data","title":"DataFrame to Matrix","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"M = Matrix(data)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"warning: Warning\nAttention that if the dataframe contains different types across columns, the inner type of the matrix will be Any","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"M = Matrix{Union{Float64,Int64,String}}(data)","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#DataFrame-to-Dictionary","page":"0201-wrangling data","title":"DataFrame to Dictionary","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"function toDict(df, dimCols, valueCol)\n    toReturn = Dict()\n    for r in eachrow(df)\n        keyValues = []\n        [push!(keyValues,r[d]) for d in dimCols]\n        toReturn[(keyValues...,)] = r[valueCol]\n    end\n    return toReturn\nend\ndict = toDict(data,[\"Country\",\"Year\"],[\"forarea\",\"forvol\"])\ndict[\"Germany\",2000][1]\ndict[\"Germany\",2000][\"forvol\"]\ntoDict(data,[\"Country\",\"Year\"],\"forarea\")","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#DataFrame-to-NamedTuple","page":"0201-wrangling data","title":"DataFrame to NamedTuple","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"nT = NamedTuple(Dict([Symbol(c) => data[:,c]  for c in names(data)]))        # order not necessarily preserved\nusing DataStructures\nnT = NamedTuple(OrderedDict([Symbol(c) => data[:,c]  for c in names(data)])) # order preserved","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#Saving-as-CSV-file","page":"0201-wrangling data","title":"Saving as CSV file","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"CSV.write(\"outdata.csv\",data) # see options at the beginning of segment in the import section and `? CSV.write` for specific export options","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#Saving-as-OpenDocument-spreadsheet","page":"0201-wrangling data","title":"Saving as OpenDocument spreadsheet","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"ods_write(\"outdata.ods\",Dict((\"myData\",3,2) => data)) # exported starting on cell B3 of sheet \"myData\"","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html#Saving-as-Excel-spreadsheet","page":"0201-wrangling data","title":"Saving as Excel spreadsheet","text":"","category":"section"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"XLSX.writetable(\"outdata.xlsx\",myData = (collect(eachcol(data)),names(data)))","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"View this file on Github.","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"","category":"page"},{"location":"02_-_JULIA2_-_Scientific_programming_with_Julia/0201-wrangling_data.html","page":"0201-wrangling data","title":"0201-wrangling data","text":"This page was generated using Literate.jl.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html#Quiz-on-Basic-Syntax","page":"0101 - q01 - QUIZ basic syntax","title":"Quiz on Basic Syntax","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html","page":"0101 - q01 - QUIZ basic syntax","title":"0101 - q01 - QUIZ basic syntax","text":"cd(@__DIR__)    \nusing Pkg      \nPkg.activate(\".\")  \n## Pkg.resolve()   \n## Pkg.instantiate()\nusing Random\nRandom.seed!(123)\nusing QuizQuestions","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html","page":"0101 - q01 - QUIZ basic syntax","title":"0101 - q01 - QUIZ basic syntax","text":"","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html#Q1:-What-is-it-stored-in-a-project-file-?","page":"0101 - q01 - QUIZ basic syntax","title":"Q1: What is it stored in a project file ?","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html","page":"0101 - q01 - QUIZ basic syntax","title":"0101 - q01 - QUIZ basic syntax","text":"What information can be stored on a Julia Project.toml file ?","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html","page":"0101 - q01 - QUIZ basic syntax","title":"0101 - q01 - QUIZ basic syntax","text":"\nchoices = [ # hide\n    \"The name of the packages directly used in the project (julia scripts)\", # hide\n    \"The ID of the packages directly used in the project (julia scripts)\", # hide\n    \"The minimum and maximum version of the packages directly used in the project (julia scripts) that are compatible with the project\", # hide\n    \"The exact version of the package directly emploied in the project (julia scripts)\", # hide\n    \"The name of all the dependencies libraries of the project (julia scripts)\", # hide\n    \"The ID of all the dependencies libraries of the project (julia scripts)\", # hide\n    \"The minimum and maximum version of all the dependencies libraries used in the project (julia scripts) that are compatible with the project\", # hide\n    \"The exact version of all the dependencies libraries emploied in the project (julia scripts)\", # hide\n    \"None of the (other) sentences is correct\" ]  # hide\nanswers = [1,2,3]  # hide\nmultiq(choices, answers;)  # hide\n","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html","page":"0101 - q01 - QUIZ basic syntax","title":"0101 - q01 - QUIZ basic syntax","text":"<details><summary>RESOLUTION</summary>","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html","page":"0101 - q01 - QUIZ basic syntax","title":"0101 - q01 - QUIZ basic syntax","text":"The Project.toml file task is to indicate which is the set of packages that works with the given project, but not the concrete istance of the environment that is used in a project, that is the exact version of all directly and indirectly used packages. This is indeed the task of the Manifest.toml file.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html","page":"0101 - q01 - QUIZ basic syntax","title":"0101 - q01 - QUIZ basic syntax","text":"The correct answers are:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html","page":"0101 - q01 - QUIZ basic syntax","title":"0101 - q01 - QUIZ basic syntax","text":"\"The name of the packages directly used in the project (julia scripts)\"\n\"The ID of the packages directly used in the project (julia scripts)\"\n\"The minimum and maximum version of the packages directly used in the project (julia scripts) that are compatible with the project\"","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html","page":"0101 - q01 - QUIZ basic syntax","title":"0101 - q01 - QUIZ basic syntax","text":"</details>","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html","page":"0101 - q01 - QUIZ basic syntax","title":"0101 - q01 - QUIZ basic syntax","text":"","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html#Q2:-Syntax-for-comments","page":"0101 - q01 - QUIZ basic syntax","title":"Q2: Syntax for comments","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html","page":"0101 - q01 - QUIZ basic syntax","title":"0101 - q01 - QUIZ basic syntax","text":"Given the following sequence of commands (one for each line) run in an interactive session:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html","page":"0101 - q01 - QUIZ basic syntax","title":"0101 - q01 - QUIZ basic syntax","text":"# a = 1\na = 2 # hello\na = # hello # 3\n#= a = 4\n#= a = 5 =#\na = 6\n=#","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html","page":"0101 - q01 - QUIZ basic syntax","title":"0101 - q01 - QUIZ basic syntax","text":"Which statements are correct ?","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html","page":"0101 - q01 - QUIZ basic syntax","title":"0101 - q01 - QUIZ basic syntax","text":"choices = [ # hide\n    \"`a` is now `1`\", # hide\n    \"`a` is now `2`\", # hide\n    \"`a` is now `3`\", # hide\n    \"`a` is now `4`\", # hide\n    \"`a` is now `5`\", # hide\n    \"`a` is now `6`\", # hide\n    \"None of the (other) sentences is correct\", # hide\n    \"At least one of that commands raises a run-time error\", # hide\n    \"None of that commands raises a run-time error\"]  # hide\nanswers = [2,8]  # hide\nmultiq(choices, answers;)  # hide","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html","page":"0101 - q01 - QUIZ basic syntax","title":"0101 - q01 - QUIZ basic syntax","text":"<details><summary>RESOLUTION</summary>","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html","page":"0101 - q01 - QUIZ basic syntax","title":"0101 - q01 - QUIZ basic syntax","text":"The first command is a comment. On the second one, a is assigned the value 2. The third one raises a syntax error as the equal operator expects a right and a left hand side, while here the right hand side is all commented out. Finally lines 4  to the end is a big nested comment. It results that after that commands have been run, a remains assigned to 2. The correct answers are:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html","page":"0101 - q01 - QUIZ basic syntax","title":"0101 - q01 - QUIZ basic syntax","text":"\"a is now 2\"\n\"At least one of that commands raises a run-time error\"","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html","page":"0101 - q01 - QUIZ basic syntax","title":"0101 - q01 - QUIZ basic syntax","text":"</details>","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html","page":"0101 - q01 - QUIZ basic syntax","title":"0101 - q01 - QUIZ basic syntax","text":"","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html#Q3:-Various-syntax-rules","page":"0101 - q01 - QUIZ basic syntax","title":"Q3: Various syntax rules","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html","page":"0101 - q01 - QUIZ basic syntax","title":"0101 - q01 - QUIZ basic syntax","text":"Given a file \"Foo.jl\" with the following code:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html","page":"0101 - q01 - QUIZ basic syntax","title":"0101 - q01 - QUIZ basic syntax","text":"function foo(x)\nprintln(x²)\nend\na = [2,3]\nfoo(a)\nfoo.(a)\nfoo(a[1])","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html","page":"0101 - q01 - QUIZ basic syntax","title":"0101 - q01 - QUIZ basic syntax","text":"Which of the following statements are correct ?","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html","page":"0101 - q01 - QUIZ basic syntax","title":"0101 - q01 - QUIZ basic syntax","text":"choices = [ # hide\n    \"The output of `foo(a)` is `[4,9]`\", # hide\n    \"The output of `foo.(a)` is `[4,9]`\", # hide\n    \"The output of `foo(a[1])` is `4`\", # hide\n    \"The output of `foo(a[1])` is `9`\", # hide\n    \"Defining the function produces a run-time error because the body of the function is not idented\", # hide\n    \"Calling the function produces a run-time error because the body of the function is not idented\", # hide\n    \"Calling the function produces a run-time error because Unicode characters (`²`) are not allowed in Julia\", # hide\n    \"Calling the function produces a run-time error because `x²` is not defined\", # hide\n    \"None of the (other) sentences is correct\", # hide\n]  # hide\nanswers = [8]  # hide\nmultiq(choices, answers;)  # hide","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html","page":"0101 - q01 - QUIZ basic syntax","title":"0101 - q01 - QUIZ basic syntax","text":"<details><summary>RESOLUTION</summary>","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html","page":"0101 - q01 - QUIZ basic syntax","title":"0101 - q01 - QUIZ basic syntax","text":"First, Unicode characters are allowed (with very rare exceptions) and identation doesn't matter in Julia. We would then be tempted to say hence that the broadcasted call foo.(a) produces [4,9] as output and foo(a[1]) produces 4. However the rising to the power is not obtained by using the Unicode ² character, but using the exponential operator, i.e. x^2. x² is just an other idetifier name that has not been defined, so the function in all cases returns an error that x² is not defined. The correct answer is:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html","page":"0101 - q01 - QUIZ basic syntax","title":"0101 - q01 - QUIZ basic syntax","text":"\"Calling the function produces a run-time error because x² is not defined\"","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0101_-_q01_-_QUIZ_basic_syntax.html","page":"0101 - q01 - QUIZ basic syntax","title":"0101 - q01 - QUIZ basic syntax","text":"</details>","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0001_-_Course_presentation.html#Course-Presentation","page":"0001 - Course presentation","title":"Course Presentation","text":"","category":"section"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0001_-_Course_presentation.html#Objectives","page":"0001 - Course presentation","title":"Objectives","text":"","category":"section"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0001_-_Course_presentation.html","page":"0001 - Course presentation","title":"0001 - Course presentation","text":"This course aims to provide a general initialisation to Julia, a modern, expressive and efficient programming language, and introduce the main concepts around machine learning, together with some algorithms and practical implementations of machine learning workflows.","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0001_-_Course_presentation.html","page":"0001 - Course presentation","title":"0001 - Course presentation","text":"In particular the objectives are : ","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0001_-_Course_presentation.html","page":"0001 - Course presentation","title":"0001 - Course presentation","text":"Supply students with an operational knowledge of a modern and efficient general-purpose language that can be employed for the implementation of their research daily activities;\nPresent several specific but commonly used tools in multiple scientific areas (data transformation, optimisation,...)\nIntroducing students to modern tools for scientific collaboration and software quality, such as version control systems and best practices to obtain replicable results.\nIntroduce machine learning approaches: scopes, terminology, typologies, workflow organisation\nIntroduce some specific machine learning algorithms for classification and regression","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0001_-_Course_presentation.html#Organisation","page":"0001 - Course presentation","title":"Organisation","text":"","category":"section"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0001_-_Course_presentation.html","page":"0001 - Course presentation","title":"0001 - Course presentation","text":"The course is multi-channel, with these pages complemented with youtube videos (see Program ), quizzes and exercises. Thanks to projects as Literate.jl and Documenter.jl the source of most of these pages are runnable valid Julia files.","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0001_-_Course_presentation.html","page":"0001 - Course presentation","title":"0001 - Course presentation","text":"To fully master the subject, nothing is better than cloning the repository on GitHub and run these pages by yourself! To execute yourself the code discussed in the videos run the code in the lessonsSource folder. Other resources used in the course (in particular the examples of the introduciton and the exercises) are located under the lessonsMaterial folder.","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0001_-_Course_presentation.html","page":"0001 - Course presentation","title":"0001 - Course presentation","text":"Note that there will be a bit of incongruence in the terminology used for \"units\". Sometimes I call them \"lessons\", especially at the beginning of the course, then it ended up that the actual content was much bigger than a standard \"lesson\", so I started to use the word \"unit\". Any-how, the course is organised in units/lessons (e.g. JULIA1). Each unit/lesson has its own Julia environment and it is organised in several segments. These are the individual pages on this site and correspond to a single file in the github repository. Then each segment is divised in multiple videos, that I call parts.","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0001_-_Course_presentation.html#Course-author","page":"0001 - Course presentation","title":"Course author","text":"","category":"section"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0001_-_Course_presentation.html","page":"0001 - Course presentation","title":"0001 - Course presentation","text":"@raw html  <img src=\"https://raw.githubusercontent.com/sylvaticus/SPMLJ/main/lessonsSources/00_-_INTRO_-_Introduction_julia_ml/assets/imgs/photo_antonello_lobianco.jpg\" alt=\"Antonello Lobianco\" width=\"200\">","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0001_-_Course_presentation.html","page":"0001 - Course presentation","title":"0001 - Course presentation","text":"Antonello Lobianco","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0001_-_Course_presentation.html","page":"0001 - Course presentation","title":"0001 - Course presentation","text":"OrcID - Google Schoolar - GitHub - Personal site","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0001_-_Course_presentation.html","page":"0001 - Course presentation","title":"0001 - Course presentation","text":"I am a Forest and Natural Resources Economist @ AgroParisTech, a French \"Grand ecole\" (sort of polytecnic university) in the life science domain and affiliated to BETA, the Bureau d'Économie Théorique et Appliquée, which brings together most of the economists located in the Grand-Est region of France. My main interest is in exploring the interplay between the biophysical layers in the forest sector (climate change, forest dynamics) and the socio-economic ones (individual forest owners behaviours, timber markets \"behaviours\") in order to better understand the space of actions that society has to maximise social benefits in a sustenible way. For that I design, develop and use bio-economic simulation models of the forest sector.","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0001_-_Course_presentation.html","page":"0001 - Course presentation","title":"0001 - Course presentation","text":"While this course is in English, English is not my native language.. please, be understanding !","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0102-types_and_objects.html","page":"0102-types and objects","title":"0102-types and objects","text":"EditURL = \"https://github.com/sylvaticus/SPMLJ/blob/main/lessonsSources/01_-_JULIA1_-_Basic_Julia_programming/0102-types_and_objects.jl\"","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0102-types_and_objects.html","page":"0102-types and objects","title":"0102-types and objects","text":"################################################################################\n###  Introduction to Scientific Programming and Machine Learning with Julia  ###\n###                                                                          ###\n### Run each script on a new clean Julia session                             ###\n### GitHub: https://github.com/sylvaticus/IntroSPMLJuliaCourse               ###\n### Licence (apply to all material of the course: scripts, videos, quizes,..)###\n### Creative Commons By Attribution (CC BY 4.0), Antonello Lobianco          ###\n################################################################################","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0102-types_and_objects.html#Types-and-objects","page":"0102-types and objects","title":"0102 Types and objects","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0102-types_and_objects.html#Some-stuff-to-set-up-the-environment..","page":"0102-types and objects","title":"Some stuff to set-up the environment..","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0102-types_and_objects.html","page":"0102-types and objects","title":"0102-types and objects","text":"cd(@__DIR__)\nusing Pkg\nPkg.activate(\".\")","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0102-types_and_objects.html","page":"0102-types and objects","title":"0102-types and objects","text":"If using a Julia version different than 1.7 please uncomment and run the following line (reproductibility guarantee will hower be lost) Pkg.resolve() Pkg.instantiate() # run this if you didn't in Segment 01.01","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0102-types_and_objects.html","page":"0102-types and objects","title":"0102-types and objects","text":"using Random\nRandom.seed!(123)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0102-types_and_objects.html#Types","page":"0102-types and objects","title":"Types","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0102-types_and_objects.html","page":"0102-types and objects","title":"0102-types and objects","text":"# 1 in not 1.0:\na = 1\nb = 1.0\ntypeof(a) # type is inferred !\ntypeof(b)\n# Convert type (cast)\na = 1\nb = convert(Float64,a)\ntypeof(b)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0102-types_and_objects.html","page":"0102-types and objects","title":"0102-types and objects","text":"Type hierarchy in Julia:","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0102-types_and_objects.html","page":"0102-types and objects","title":"0102-types and objects","text":"Any\nAbstractString     # We'll see what all these \"abstract\" mean....\nString\n...\nAbstractArray\nArray\n....\nNumber\nComplex\nReal\nRational\nInteger\nUnsigned\nUInt64\n...\nSigned\nInt32\nInt64\nBigInt\n...\nBool\nFixedPoints\n...\nAbstractIrrational\nIrrational\nAbstractFloat\nFloat32\nFloat64\nBigFloat\n...\n...","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0102-types_and_objects.html","page":"0102-types and objects","title":"0102-types and objects","text":"Complete Number hierarchy: https://upload.wikimedia.org/wikipedia/commons/d/d9/Julia-number-type-hierarchy.svg","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0102-types_and_objects.html","page":"0102-types and objects","title":"0102-types and objects","text":"# Everythong is an object, i.e. of some \"type\"\nc = typeof(a)\ntypeof(c)\nd = sin\ntypeof(d) <: Function\ntypeof(+) <: Function\n\n# Operators are just functions:\n1 + 2\n+(1,2) # this call the function \"+\"\nimport Base.+\n# +(a,b,c) = a*b*c  # Defining my new crazy addition operation with 3 arguments\n10+20+30            # This call it\n10+20               # The addition with two parameters remains the same\n10+20+30+40         # Also this one remains with the standard addition..","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0102-types_and_objects.html","page":"0102-types and objects","title":"0102-types and objects","text":"warning: Warning\nAfter you tested this crazy addition, please restart julia or norhing will work. With great power come great responsability.. (..if you change the meaning of addition it is difficult you will not run into problems...)","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0102-types_and_objects.html#Objects-and-variables","page":"0102-types and objects","title":"Objects and variables","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0102-types_and_objects.html","page":"0102-types and objects","title":"0102-types and objects","text":"k = 10    # \"create\" an object Int64 in memory and binds (assign) it to the `k` identifier (the variable name)\ntypeof(k)\nsizeof(k)  # bytes (1 byte is 8 bits)\nbitstring(k)\n0*2^0+1*2^1+0*2^2+1*2^3\nm = k      # name binding: it binds (assign) the entity (object) referenced by a to the b identifier (the variable name)\nm == k     # are the two objects equal ?\nm === k    # are the two identifiers binding the same identical object in memory ?","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0102-types_and_objects.html#Mutability-property-of-Julia-objects","page":"0102-types and objects","title":"Mutability property of Julia objects","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0102-types_and_objects.html","page":"0102-types and objects","title":"0102-types and objects","text":"k = 10\nv = [1,2]\np = 'z'\ng = \"hello\"\nismutable(k)\nismutable(v)\nismutable(p)\nismutable(g)\n# mutable objects are stored in memory \"directly\", while for mutable objects it is its memory address to be stored","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0102-types_and_objects.html#Three-different-ways-to-\"copy\"-objects...","page":"0102-types and objects","title":"Three different ways to \"copy\" objects...","text":"","category":"section"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0102-types_and_objects.html","page":"0102-types and objects","title":"0102-types and objects","text":"a = [[[1,2],3],4] # First element of a is said to be \"mutable\", second one is not:\nismutable(a[1])\nismutable(a[2])\nb = a            # binding to a new identifier\nc = copy(a)      # create a new copy of a and binds it to c\nd = deepcopy(a)  # copy all the references recursively and assign this new object to d\n\nc == a           # are the two objects equal ?\nc === a          # are the two identifiers binding the same identical object in memory ?\na[2] = 40        # rebinds a[2] to an other objects and at the same time mutates object a:\nb\nc\nd\na[1][2] = 30     # rebinds a[1][2] and at the same time mutates both a and a[1]\nb\nc\nd\na[1][1][2] = 20\nb\nc\nd\na = 5            # rebinds a:\nb\nc\nd","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0102-types_and_objects.html","page":"0102-types and objects","title":"0102-types and objects","text":"note: Note\nConsider these memory isues when we'll discuss calling a function by reference/value !","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0102-types_and_objects.html","page":"0102-types and objects","title":"0102-types and objects","text":"View this file on Github.","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0102-types_and_objects.html","page":"0102-types and objects","title":"0102-types and objects","text":"","category":"page"},{"location":"01_-_JULIA1_-_Basic_Julia_programming/0102-types_and_objects.html","page":"0102-types and objects","title":"0102-types and objects","text":"This page was generated using Literate.jl.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html#Neural-Networks-theory","page":"0401 NeuralNetworksTheory","title":"0401 - Neural Networks - theory","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"While powerful, neural networks are actually composed of very simple units that are akin to linear classification or regression methods. Don't be afraid by their name and the metaphor with the human brain. Neural networks are really simple transformations of the data that flow from the input, through various layers, ending with an output.   That's their beauty ! Complex capabilities emerge from very simple units when we put them together. For example the capability to recognise not \"just\" objects in an image but also abstract concepts such as people's emotions or situations and environments.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"We'll first describe them, and we'll later learn how to train a neural network from the data. Concerning the practical implementation in Julia, we'll not implement a complete neural network but rather only certain parts, as we will mostly deal with using them and apply them to different kinds of datasets.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html#Motivations-and-types","page":"0401 NeuralNetworksTheory","title":"Motivations and types","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"When we studied the Perceptron algorithm, we noted how we can transform the original feature vector mathbfx to a feature representation  phi(mathbfx) that includes non-linear transformations, to still use linear classifiers for non-linearly separable datasets (we studied classification tasks but the same is true for regression ones). The \"problem\" is that this feature transformation is not learned from the data but is applied a priori, before using the actual machine learning (linear) algorithm. With neural networks instead, the feature transformation is endogenous to the learning (training) step.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"We will see three kinds of neural networks:","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"Feed-forward Neural Networks, the simplest one where the inputs flow through a set of \"layers\" to reach an output. \nConvolutional Neural Networks (CNN), where one or more of the layers is a \"convolutional\" layer. These are used mainly for image classification\nRecurrent Neural Networks (RNN), where the input arrives not only at the beginning but also at each layer. RNNs are used to learn sequences of data","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html#Feed-forward-neural-networks","page":"0401 NeuralNetworksTheory","title":"Feed-forward neural networks","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html#Description","page":"0401 NeuralNetworksTheory","title":"Description","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"In deep forward neural networks, neural network units are arranged in layers, from the input layer, where each unit holds the input coordinate, through various hidden layer transformations, until the actual output of the model:","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"(Image: Neural network scheme)","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"More in detail, considering a single dense neuron (in the sense that is connected with all the previous layer's neurons or with the input layer), we have the following figure:","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"(Image: Single neuron)","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"where:","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"x\nis a two-dimensional input, with x_1 and x_2 being the two dimensions of our input data (they could equivalently be the outputs of a previous 2 neurons layers)\nw\nare the weigths that are applied to x plus a constant term (w_0). These are the parameter we will want to learn with our algorithm. f is a function (often non-linear) that is applied to w_0 + x_1w_1 + x_2w_2 to define the output of the neuron","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"The output of the neuron can be the output of our neural network or it can be the input of a further layer.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"In Julia we can implement a layer of neurons and its predictions very easily (although implementing the learning of the weights is a bit more complex):","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"using LinearAlgebra\nmutable struct DenseLayer\n    wb::Array{Float64,1} # weights with reference to the bias (will be learned from data)\n    wi::Array{Float64,2} # weigths with reference to the input (will be learned from data)\n    f::Function          # the activation function of each neuron (chosen from the modeller)\nend\n\nfunction forward(m,x) # The predictions  - or \"forward\" to the next layer\n      return m.f.(m.wb .+ m.wi * x)\nend\n\n(nI,nO) = 3,2 # Number of nodes in input and in outputs of this layer\n\nlayer = DenseLayer(rand(nO),rand(nO,nI),tanh)\nx = zeros(nI)\ny = forward(layer,x)","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"Let's specific a bit of terminology concerning Neural Networks:","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"The individual computation units of a layer are known as nodes or neurons.\nWidth_l (of the layer) is the number of units in that specific layer l\nDepth (of the architecture) is number of layers of the overall transformation before arriving to the final output\nThe weights are denoted with w and are what we want the algorithm to learn.\nEach node's aggregated input is given by z = sum_i=1^d x_i w_i + w_0 (or, in vector form, z = mathbfx cdot mathbfw + w_0, with z in mathbbR mathbfx in mathbbR^d mathbfw in mathbbR^d) and d is the width of the previous layer (or the input layer)\nThe output of the neuron is the result of a non-linear transformation of the aggregated input called activation function f = f(z)\nA neural network unit is a primitive neural network that consists of only the “input layer\", and an output layer with only one output.\nhidden layers are the layers that are not dealing directly with the input nor the output layers \nDeep neural networks are neural network with at least one hidden layer","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"While the weights will be learned, the width of each layer, the number of layers and the activation functions are all elements that can be tuned as hyperparameters of the model, although there are some more or less formal \"rules\":","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"the input layer is equal to the dimensions of the input data;\nthe output layer is equal to the dimensions of the output data. This is typically a scalar in a regression task, but it is equal to the number of categories in a multi-class classification, where each \"output dimension\" will be the probability associated with that given class;\nthe number of hidden layers reflects our judgment on how many \"levels\" we should decompose our input to arrive at the concept expressed in the label y (we'll see this point dealing with image classification and convolutional networks). Often 1-2 hidden layers are enough for classical regression/classification;\nthe number of neurons should give some \"flexibility\" to the architecture without exploding too much the number of parameters. A rule of thumb is to use about 20% more neurons than the input dimension. This is often fine-tuned using cross-validation as it risks leading to overfitting;\nthe activation function of the layers, with the exclusion of the last one, is chosen between a bunch of activation functions, nowadays almost always the Rectified Linear Unit function, aka relu, defined as relu(x) = max(0,x). The relu function has the advantage to add non-linearity to the transformation while remaining fast to compute (including the derivative) and limiting the problem of vanishing or exploding the gradient (we'll see this aspect when dealing with the actual algorithm to obtain the weights). Another common choice is tanh(), the hyperbolic tangent function, that maps with an \"S\" shape the real line to the interval [-1,1].\nthe activation function of the last layer depends on the nature of the labels we want the network to compute: if these are positive scalars we can use also here the relu, if we are doing a binary classification we can use the sigmoid function defined as sigmoid(x) = 1/(1+exp(-x)) whose output is in the range [0,1] and which we can interpret as the probability of the class that we encode as 1. If we are doing a multi-class classification we can use the softmax function whose output is a PMF of probabilities for each class. It is defined as softmax(xk) = frace^x_ksum_j=1^K e^x_j where x is the input vector, K its length and k the specific position of the class for which we want to retrieve its \"probability\".","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"Let's now make an example of a single layer, single neuron with a 2D input x=[2,4], weights w=[2,1], w₀ = 2 and activation function f(x)=sin(x).","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"In such a case, the output of our network is sin(2+2*2+4*1), i.e. -0.54. Note that with many neurons and many layers this becomes essentially (computationally) a problem of matrix multiplications, but matrix multiplication is easily parallelisable by the underlying BLAS/LAPACK libraries or, even better, by using GPU or TPU hardware, and running neural networks (and computing their gradients) is at the core of the demand for GPU computation.  ","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"Let's now assume that the true label that we know to be associated with our x is y=-0.6.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"Out (basic) network did pretty well, but still did an error: -0.6 is not -0.54. The last element of a neural network is indeed to define an error metric (the loss function) between the output computed by the neural network and the true label. Commonly used loss functions are the squared l-2 norm (i.e. epsilon = mid mid hat y - y midmid ^2) for regression tasks and cross-entropy (i.e. epsilon = - sum_d p_d  * log(hat p_d)) for classification jobs.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"Before moving to the next section, where we will study how to put everything together and learn how to train the neural network in order to reduce this error, let's first observe that neural networks are powerful tools that can work on many sorts of data, but they require however the input to be encoded in a numerical form, as the computation is strictly numerical. If I have a categorical variable, for example, I'll need to encode it expanding it to a set of dimensions where each dimension represent a single class and I encode with an indicator function if my record is that particular class or not. This is the most simple form of encoding and takes the name of one hot encoding:","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"(Image: One-hot encoding)","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"Note in the figure that using all the three columns leads to linearly dependency, and while, yes, we could save some resources by using only two columns instead of three, this is not a fundamental problem like it would be in statistical analysis. ","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html#Training-of-a-feed-forward-neural-network","page":"0401 NeuralNetworksTheory","title":"Training of a feed-forward neural network","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html#Gradient-and-learning-rate","page":"0401 NeuralNetworksTheory","title":"Gradient and learning rate","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"We now need a way to learn the parameters from the data, and a common way is to try to reduce the contribution of the individual parameter to the error made by the network. We need first to find the link between the individual parameter and the output of the loss function, that is how the error change when we change the parameter. But this is nothing else than the derivative of the loss function with respect to the parameter. In our simple one-neuron example above we have the parameters directly appearing in the loss function. Considering the squared error as lost we have epsilon = (y - sin(w_0 + w_1 x_1 + w_2 x_2))^2. If we are interested in the w_1 parameter we can compute the derivate of the error with respect to it using the chain rule as fracpartialepsilonpartial w_1 = 2*(y - sin(w_0 + w_1 x_1 + w_2 x_2)) * - cos(w_0 + w_1 x_1 + w_2 x_2) * x_1.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"Numerically, we have: fracpartialepsilonpartial w_1 = 2(-06-sin(2+4+4)) * -cos(2+4+4) * 2 = -0188 If I increase w_1 of 0.01, I should have my error moving of -001*0188 = -00018. Indeed, if I compute the original error I have epsilon^t=0 = 000313, but after having moved w_1 to 2.01, the output of the neural network chain would now be hat y^t=1 = 0561 and its error lowered to epsilon^t=1 =  000154. The difference is 000159, slighly lower in absolute terms than what we computed with the derivate, 00018. The reason, of course, is that the derivative is a concept at the margin, when the step tends to zero.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"We should note a few things:","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"the derivate depends on the level of w_1. \"zero\" is almost always a bad starting point (as the derivatives of previous layers will be zero). Various initialisation strategies are used, but all involve sampling randomly the initial parameters under a certain range\nthe derivate depends also on the data on which we are currently operating, x and y. If we consider different data we will obtain different derivates\nwhile extending our simple example to even a few more layers would seem to make the above exercise extremely complex, it remains just an application of the chain rule, and we can compute the derivatives efficiently by making firstly a forward passage, computing (and storing) the values of the chain at each layer, and then making a backward passage by computing (and storing) the derivatives with the chain rule backwards from the last to the first layer\nthe fact that the computation of the derivates for a layer includes the multiplication of the derivates for all the other layers means that if these are very small (big) the overall derivate may vanish (explode). This is a serious problem with neural networks and one of the main reasons why simple activation functions such as the relu are preferred.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"The derivate(s) of the error with respect to the various parameters is called the gradient.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"If the gradient with respect to a parameter is negative, like in our example, it means that if we slightly increase the parameter we will obtain a lower error. On the opposite, if it is positive, if we slightly reduce the parameter we should find a lower error.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"A gradient-descent based algorithm can hence be used to look iteratively for the minimum error by moving against the gradient with a certain step. The most basic algorithm is then w_i^t = w_i^t-1 - fracpartialepsilon^t-1partial w_1^t-1 * lambda where lambda is the step that you are willing to make against the gradient, also known as learning rate. Note in the example above that if instead of moving the parameter w_1 of 001 we would have increased it of 01, we would have increased the error to 000997 instead of reducing it. This highlights the problem to use a good learning rate (see next Figure): a too-small learning rate would make the learning slow and with the risk to get trapped in a local minimum instead of a global one. Conversely, a too-large learning rate would risk causing the algorithm to diverge.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"(Image: Learning rate effect)","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"So, the learning rate is also a hyper-parameter to calibrate, although some modern gradient descent variations, like the ADAptive Moment estimation (ADAM) optimisation algorithm, tend to self_tune themselves and we rarely need to calibrate the default values.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html#Batches-and-Stochastic-gradient-descent","page":"0401 NeuralNetworksTheory","title":"Batches and Stochastic gradient descent","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"We already note that the computation of the gradient depends on the data levels. We can then move between two extremes: on one extreme we compute the gradient as the average of those computed on all data points and we apply the optimisation algorithm to this average. On the other extreme, we sample randomly record by record and, at each record, we move the parameter. The compromise is to partition the data in a set of batches, compute the average gradient of each batch and at each time update the parameter with the optimisation algorithm. The \"one record at the time\" is the slowest approach, but also is very sensitive to the presence of outliers. The \"take the average of all the data\" approach is faster in running a certain epoch, but it takes longer to converge (i.e. it requires more epochs, the number of times we pass through the whole training data). It also requires more memory, as we need to store the gradients with respect to all records. So, the \"batch\" approach is a good compromise, and we normally set the batch number to a multiplier of the number of threads in the machine performing the training, as this step is often parallelised, and it represents a further parameter that we can cross-validate. When we sample the records (individually or in batch) before running the optimisation algorithm we speak of stochastic gradient descent.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html#Convolutional-neural-networks","page":"0401 NeuralNetworksTheory","title":"Convolutional neural networks","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html#Motivations","page":"0401 NeuralNetworksTheory","title":"Motivations","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"Despite typically classified separately, convolutional neural networks are essentially feed-forward neural networks with the only specification that one or more layers are convolutional. These layers are very good in recognising patterns within data with many dimensions, like spatial data or images, where each pixel can be thought a dimension of a single record. In both cases, we could use \"normal\" feed-forward neural networks, but convolutional layers offer two big advantages:","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"They require much fewer parameters.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"Convolutional neurons are made of small filters (or kernels) (typically 3x3 or 5x5) where the same weight convolves across the image. Conversely, if we would like to process with a dense layer a mid-size resolution image of 1000 times 1000 pixels, each layer would need a weight matrix connecting all these 10^6 pixels in input with 10^6 pixel in output, i.e. 10^12 weights","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"They can extend globally what they learn \"locally\"","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"If we train a feed-forward network to recognise cars, and it happens that our training photos have the cars all in the bottom half, then the network would not recognise a car in the top half, as these would activate different neurons. Instead, convolutional layers can learn independently on where the individual features apply.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html#Description-2","page":"0401 NeuralNetworksTheory","title":"Description","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"In these networks, the layer l is obtained by operating over the image at layer l-1 a small filter (or kernel) that is slid across the image with a step of 1 (typically) or more pixels at the time. The step is called stride, while the whole process of sliding the filter throughout the whole image can be mathematically seen as a convolution.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"So, while we slide the filter, at each location of the filter, the output is composed of the dot product between the values of the filter and the corresponding location in the image (both vectorised), where the values of the filters are the weights that we want to learn, and they remain constant across the sliding. If our filter is a 10 times 10 matrix, we have only 100 weights to learn by layer (plus one for the offset). Exactly as for feedforward neural networks, then the dot product is passed through an activation function, here typically the ReLU function (max(0x)) rather than tanh:","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"(Image: Convolutional filter)","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html#Example","page":"0401 NeuralNetworksTheory","title":"Example","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"For example, given an image x = beginbmatrix 1  1  2  1  1 \n3  1  4  1  1 \n1  3  1  2  2 \n1  2  1  1  1 \n1  1  2  1  1 \nendbmatrix and filter weights w = beginbmatrix  1  -2  0 \n 1   0  1 \n-1   1  0 \nendbmatrix, then the output of the filter z would be beginbmatrix  8  -3  6 \n 4   -3  5 \n-3   5  -2 \nendbmatrix. For example, the element of this matrix z_23 = 5 is the result of the sum of the scalar multiplication between x^prime = beginbmatrix  4   1  1 \n 1   2  2 \n 1   1  1 \nendbmatrix and w.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"Finally, the output of the layer would be (using ReLU) beginbmatrix  8  0  6 \n 4   0  5 \n 0   5  0 \nendbmatrix.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"We can run the following snippet to make the above computations:","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"ReLU(x) = max(0,x)\nx = [1 1 2 1 1;\n        3 1 4 1 1;\n        1 3 1 2 2;\n        1 2 1 1 1;\n        1 1 2 1 1]\nw = [ 1 -2  0;\n        1  0  1;\n        -1  1  0]\n(xr,xc) = size(x)\n(wr,wc) = size(w)\nz = [sum(x[r:r+wr-1,c:c+wc-1] .* w) for c in 1:xc-wc+1 for r in 1:xr-wr+1] # Julia is column major\nu = ReLU.(z)\nfinal = reshape(u, xr-wr+1, xc-wc+1)","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"You can notice that by applying the filter we obtain a dimensionality reduction. This reduction depends on both the dimension of the filter and the stride (sliding step). In order to avoid this, padding of one or more rows/columns can be applied to the image to preserve in the output the same dimension of the input (in the above example padding of one row and one column on both sides would suffice). Typically the padded cells are given a value of zero so not to contribute anything when they are included in the dot product computed by the filter.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"To determine the spatial size in the output of a filter (O), given the input size (I), the filter size (F), the stride (S) and the eventual padding (P) we can use the following simple formula:","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"O_d = 1 + (I_d+2*P_d-F_d)S","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"From it, we can also find the padding needed to obtain a certain output size as: P_d = ((O_d-1)S_d-I_d+F_d)2","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"Where the d index accounts for the (extremely unusual) case where one of the parameters is not a square matrix so that for example an image has different vertical and horizontal resolutions.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"Because the weights of the filters are the same, it doesn't really matter where the object is learned, in which part of the image. With convolutional layers, we have translational invariance as the same filter is passed over the entire image. Therefore, it will detect the patterns regardless of their location.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"Still, it is often convenient to operate some data augmentation to the training set, that is to add slightly modified images (rotated, mirrored..) in order to improve this translational invariance.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html#Considering-multiple-filters-per-layer","page":"0401 NeuralNetworksTheory","title":"Considering multiple filters per layer","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"Typically, one single layer is formed by applying multiple filters, not just one. This is because we want to learn different kinds of features. For example in an image one filter will specialize to catch vertical lines, the other obliques ones, and maybe another filter different colours.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"(Image: Set of different convolutional filters outputs)","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"Convolutional filters outputs on the first layer (filters are of size 11x11x3 and are applied across input images of size 224x224x3). Source: Krizhevsky et Oth. (2012), \"ImageNet Classification with Deep Convolutional Neural Networks\"","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"So in each layer we map the output of the previous layer (or the original image in case of the first layer) into multiple feature maps where each feature map is generated by a little weight matrix, the filter, that defines the little classifier that's run through the original image to get the associated feature map. Each of these feature maps defines a channel for information and we can represent it as a third dimension to form a \"volume\", where the depth is given by the different filters:","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"(Image: Convolutional layer)","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"In the image above the input layer has size (4,4,4) and the output layer has size (3,3,2), i.e. 2 \"independent\" filters of size (2,2).","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"For square layers, each filter has F^2 times D_l-1 + 1 parameters where D_l-1 is the dimensions (\"depth\") of the previous layer, so the total number of parameters per layer is (F^2 times D_l-1 + 1) * D_l.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"For computational reasons, the number of filters per layer D_l is normally a power of 2. ","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"This representation allows remaining consistent with the input that can as well be represented as a volume. For images, the depth is usually given by 3 layers representing the values in terms of RGB colours.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html#Pool-layers","page":"0401 NeuralNetworksTheory","title":"Pool layers","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"A further way to improve translational invariance, but also have some dimensionality reduction, is called pooling and is implemented by adding a layer with a filter whose output is the max of the corresponding area in the input (or, more rarely, the average). Note that this layer would have no weights to learn! With pooling we start separating what is in the image from where it is in the image, that is, pooling does a fine-scale, local translational invariance, while convolution does more a large-scale one.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"Keeping the output of the above example as input, a pooling layer with a 2 times 2 filter and a stride of 1 would result in beginbmatrix  8  6 \n 5  5 \nendbmatrix.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html#Convolutional-networks-conclusions","page":"0401 NeuralNetworksTheory","title":"Convolutional networks conclusions","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"We can then combine these convolutions, looking for features, and pooling, compressing the image a little bit, forgetting the information of where things are, but maintaining what is there.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"In a typical CNN, these convolutional and pooling layers are repeated several times, where the initial few layers typically would capture the simpler and smaller features, whereas the later layers would use information from these low-level features to identify more complex and sophisticated features, like characterisations of a scene. The learned weights would hence specialise across the layers in a sequence like  edges -> simple parts-> parts -> objects -> scenes.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"These layers are finally followed by some \"normal\", \"fully connected\" layers (like in \"normal\" feed-forward neural networks) and a final softmax layer indicating the probability that each image represents one of the possible categories (there could be thousands of them).","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"The best network implementations are tested in so-called \"competitions\", like the yearly ImageNet context.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"Note that we can train these networks exactly like for feedforward NN, defining a loss function and finding the weights that minimise the loss function. In particular, we can apply the stochastic gradient descendent algorithm (with a few tricks based on getting pairs of image and the corresponding label), where the gradient with respect to the various parameters (weights) is obtained by backpropagation.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html#Recurrent-Neural-Networks-(RNNs)","page":"0401 NeuralNetworksTheory","title":"Recurrent Neural Networks (RNNs)","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html#Motivations-2","page":"0401 NeuralNetworksTheory","title":"Motivations","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"Recurrent neural networks are used to learn sequences of data. A \"sequence\" is characterised by the fact that each element may depend not only on the features in place at time t, but also from lagged features or lagged values of the sequence (we use here the time dimension just for simplicity. Of course, a sequence can be defined on any dimension). And here comes the problem: we could always consider lagged features or sequence values as further dimensions at time t and use a \"standard\" feed-forward network. For example we could consider values at time t-1, those at time t-2 and those at time t-3. But, again, we would be doing \"manual\" feature engineering, similar to the way we can introduce non-linear feature transformation and use linear classifiers. But we want this to be learned by the algorithm. We want the model to learn how much of the history retain to predict the next element of the sequence, and which elements \"deserve\" to be kept in memory (to be used for predictions) even if far away in the sequence steps.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html#Description-3","page":"0401 NeuralNetworksTheory","title":"Description","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"There are a few differences with feed-forward neural networks:","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"the input doesn't arrive only at the beginning of the chain, but at each layer (each input being an element of the sequence)\neach RNN layer processes, using learnable parameters, the input corresponding to its layer, together the input coming from the previous layers (called the state)\nthese weights are shared for the various RNN layers across the sequence","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"Note that you can interpret a recurrent network equivalently like being formed by different layers on each element of the sequence (but with shared weights) or like a single, evolving, layer that calls itself recursively. Note also the similarities with convolutional networks: there we have a filter than convolves along the image, keeping the weigths constant across the convolution, here we have a recurrent network that also \"filter\" the whole sequence and learn some shared weigths.  ","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"To implement a recurrent neural network we can adapt our code above to include the state: ","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"mutable struct RNNLayer\n    wb::Array{Float64,1} # weights with reference to the bias\n    wi::Array{Float64,2} # weigths with reference to the input\n    ws::Array{Float64,2} # weigths with reference to the state\n    f::Function\nend\n\n(nI,nO)  = 3,2\nrelu(x)  = max(0,x)\nrnnLayer = RNNLayer(rand(nO),rand(nO,nI),rand(nO,nO),relu)\nfunction forward(m,x,s)\n    return m.f.(m.wb .+ m.wi * x .+ m.ws * s)\nend\nx,s = zeros(nI),zeros(nO)\ns = forward(rnnLayer,x,s)\ns = forward(rnnLayer,x,s)  # The state change even if x remains constant","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"The code above is the simplest implementation of a Recurrent Neural Network (or at least of its forward passage). In practice, the state is often memorised as part of the layer structure so its usage in most neural network libraries is similar to a \"normal\" feed-forward layer forward(layer,x).","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html#Usage:-sequence-to-one","page":"0401 NeuralNetworksTheory","title":"Usage: sequence-to-one","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"RNNs can be used to characterise a sequence, like in sentiment analysis to predict the overall attitude (positive or negative) of a text or the language in which the text is written. In these cases, the RNN task is to encode the sequence in a vector format (the final state) and this is fed to a further part of the chain whose task is to decode according to the task required. Note that the parameters for both tasks are learned jointly. The scheme is as follow:","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"(Image: Sequence-to-one scheme)","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"Training in this scenario implies starting the model from an initial state (normally a zero-vector) and some random weights,  and  \"feeding\" the model with one item at a time until the sequence ends. At this time the final state is decoded to an overall output that is compared to the \"true\" y.  From here the backward passage is made in a similar way that in feed-forward networks so that the \"contribution\" of each weight to the errors can be assessed and the weights adjusted","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"warning: Warning\nWhile weights are progressively adjusted across the training samples, the state of the network should be reset at each new sequence sample.","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html#Usage:-sequence-to-sequence","page":"0401 NeuralNetworksTheory","title":"Usage: sequence-to-sequence","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"Another scenario is when we want the RNN to replicate some sequence pattern, like in next word, next note or next price predictions. In this case, we are interested in all the elements of the sequence and not only in the final state of the sequence.  The decoding part happens hence at each step of the sequence and the resulting hat y_i is compared with the true y_i, with the resulting loss used to train the weights:","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"(Image: Sequence-to-sequence scheme)","category":"page"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html#Gated-networks","page":"0401 NeuralNetworksTheory","title":"Gated networks","text":"","category":"section"},{"location":"04_-_NN_-_Neural_Networks/0401_NeuralNetworksTheory.html","page":"0401 NeuralNetworksTheory","title":"0401 NeuralNetworksTheory","text":"While theoretically RNN can \"learn\" the importance of features across indeterminately long sequence steps, in practice the fact of continuing multiplicating the status across the varius elements of the sequence makes the problem of vanishing gradient even stronger for them. New contributions have hence been proposed with a \"gating\" system that \"learns\" what to store in memory (in the sequence state) and what to \"forget\". At the time of writing the most used approach is the Long short-term memory (LSTM). While internally more complex due to the presence of the gates and of several different states (hidden and visible in LSTM), LSTM networks are operationally used exactly in the same ways as the RNN networks described above.","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0004_-_Introduction_to_ML.html","page":"0004 - Introduction to ML","title":"0004 - Introduction to ML","text":"TODO. Please refer to the videos.","category":"page"},{"location":"index.html#Introduction-to-Scientific-Programming-and-Machine-Learning-with-Julia","page":"Index","title":"Introduction to Scientific Programming and Machine Learning with Julia","text":"","category":"section"},{"location":"index.html","page":"Index","title":"Index","text":"Except for the introductions and this page, the course is completed, please use the menu to access a particular section.","category":"page"},{"location":"index.html","page":"Index","title":"Index","text":"GitHub repository","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0002_-_Program.html#Program","page":"0002 - Program","title":"Program","text":"","category":"section"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0002_-_Program.html","page":"0002 - Program","title":"0002 - Program","text":"The following videos (15h:2':30'') are available. All except the introduction follow very close the pages in this site.","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0002_-_Program.html","page":"0002 - Program","title":"0002 - Program","text":"Videos are hosted on YouTube.","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0002_-_Program.html#KOM:-Kick-off-meeting-(2h:44:54)","page":"0002 - Program","title":"00 KOM: Kick-off meeting (2h:44:54)","text":"","category":"section"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0002_-_Program.html","page":"0002 - Program","title":"0002 - Program","text":"Note that this introduction has been recorded before the rest of the course has been implemented, so that the organisation of the course, and the way it is delivered, are not exactly as described in the videos below.","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0002_-_Program.html","page":"0002 - Program","title":"0002 - Program","text":"Take-home tip: in your projects, implement the introduction and the conclusions as the last elements ;-)","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0002_-_Program.html","page":"0002 - Program","title":"0002 - Program","text":"The slides used in the videos below are available here.","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0002_-_Program.html","page":"0002 - Program","title":"0002 - Program","text":"Course introduction (16:11)\nJulia overview (36:25)\nML Terminology (21:19)\nA first ML Example (7:00)\nML application areas (14:24)\nHands on (42:09)\nPart A (20:15)\nPart B (21:54)\nPkgs, modules and environments (20:56)\nFurther ML Examples (6:34)","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0002_-_Program.html#JULIA1:-Basic-Julia-programming-(5h:52:33)","page":"0002 - Program","title":"01 JULIA1: Basic Julia programming (5h:52:33)","text":"","category":"section"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0002_-_Program.html","page":"0002 - Program","title":"0002 - Program","text":"Basic syntax elements (46:45)\nPart A - Introduction and setup of the environment (8:37)\nPart B - Comments, code organsation, Unicode support, broadcasting (12:04)\nPart C - Math operators, quotation marks (6:49)\nPart D - Missing values (10:04)\nPart E - Stochasticity in programming (9:14)\nTypes and objects (26:38)\nPart A - Types, objects, variables and operators (13:05)\nPart B - Object mutability and effects on copying objects (13:34)      \nPredefined types (1h:39:50)\nPart A - Primitive types, char and strings (9:37)\nPart B - One dimensional arrays (30:42)\nPart C - Multidimensional arrays (23:37)\nPart D - Tuples and named tuples (7:50)\nPart E - Dictionaries and sets (8:57)\nPart F - Date and times (19:11)\nControl flow and functions (44:47)\nPart A - Variables scope (9:47)\nPart B - Loops and conditional statements (9:2)   \nPart C - Functions (25:57)\nCustom Types (40:02)\nPart A - Types of types, composite types (17:56)\nPart B - Parametric types (7:37)\nPart C - Inheritance and composition OO paradigms (14:28)  \nFurther Topics (1:34:30)\nPart A - Metaprogramming and macros (23:46)\nPart B - Interoperability with other languages (23:6)\nPart C - Performances and errors: profiling, debugging, introspection and exceptions(27:33)\nPart D - Parallel computation: multithreading, multiprocessing (20:3)","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0002_-_Program.html#JULIA2:-Scientific-Julia-programming-(2h:39:34)","page":"0002 - Program","title":"02 JULIA2: Scientific Julia programming (2h:39:34)","text":"","category":"section"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0002_-_Program.html","page":"0002 - Program","title":"0002 - Program","text":"Data Wrangling (1h:31:15)\nPart A - Introduction and data import (18:28)\nPart B - Getting insights of the data (25:26)\nPart C - Edit data and dataframe structure (23:40)\nPart D - Pivot, Split-Apply-Combine and data export (23:39)\nFurther topics (1h:08:19)\nPart A - Plotting (15:18)\nPart B - Probability distributions and data fitting (11:55)\nPart C - Constrained optimisation, the transport problem (24:59)\nPart D - Nonlinear constrained optimisation, the optimal portfolio allocation (16:04)","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0002_-_Program.html#ML1:-Introduction-to-Machine-Learning-(1h:29:43)","page":"0002 - Program","title":"03 ML1: Introduction to Machine Learning (1h:29:43)","text":"","category":"section"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0002_-_Program.html","page":"0002 - Program","title":"0002 - Program","text":"Main concepts in Machine Learning(44:45)\nPart A - Introduction, perceptron overall idea (11:23)\nPart B - Hyperparameters and cross-validation (15:18)\nPart C - The perceptron algorithm (9:53)\nPart D - SVM and non-linear classification with linear classifiers (8:9)\nThe Perceptron algorithm for linear classification (44:58)\nPart A - A first version (13:22)\nPart B - A better version (10:28)\nPart C - Cross-validation implementation (21:7)","category":"page"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0002_-_Program.html#NN:-Neural-Networks-(2h:15:36)","page":"0002 - Program","title":"03 NN: Neural Networks (2h:15:36)","text":"","category":"section"},{"location":"00_-_INTRO_-_Introduction_julia_ml/0002_-_Program.html","page":"0002 - Program","title":"0002 - Program","text":"Introduction to Neural Networks (1h:25:17)\nPart A - Introduction and motivations (5:32)\nPart B - Feed-forward neural networks (18:57)\nPart C - How to train a neural network (18:4)\nPart D - Convolutional neural networks (13:21)\nPart E - Multiple layers in convolutional neural networks (10:33)\nPart F - Recurrent neural networks (17:49)\nNeural Network workflows in Julia (50:18)\nPart A - Binary classification (15:54)\nPart B - Multinomial classification (15:1)\nPart C - Regression (6:3)\nPart D - Convolutional neural network (13:19)","category":"page"}]
}
